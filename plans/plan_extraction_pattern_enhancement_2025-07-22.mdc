# SOTD Pipeline - Extraction Pattern Enhancement Plan

**Date**: 2025-07-22  
**Status**: TODO  
**Type**: Feature Implementation  
**Priority**: Medium  

## üìò Project Summary

Enhance the SOTD pipeline's extraction phase to support two high-value patterns identified through data-driven analysis:

1. **Checkmark Format** (28 occurrences) - `‚úìField: Value`
2. **Emoji Bold Format** (168 occurrences) - `* **Field** Value`

These patterns represent clear, unambiguous field identification that can reliably extract core products (razor, blade, brush, soap) with high confidence. The analysis showed these patterns are significantly more valuable than implicit product extraction or international patterns.

## üß© Component Steps

### Phase 1: Test Infrastructure
- [x] **Step 1.1**: Add test data for checkmark and emoji bold patterns
- [x] **Step 1.2**: Create unit tests for new regex patterns
- [ ] **Step 1.3**: Create integration tests with real examples

### Phase 2: Pattern Implementation  
- [ ] **Step 2.1**: Implement checkmark format regex patterns
- [ ] **Step 2.2**: Implement emoji bold format regex patterns
- [ ] **Step 2.3**: Add field mapping logic for new patterns

### Phase 3: Integration and Validation
- [ ] **Step 3.1**: Integrate new patterns into extraction pipeline
- [ ] **Step 3.2**: Validate against existing test suite
- [ ] **Step 3.3**: Test with real data samples

### Phase 4: Quality Assurance
- [ ] **Step 4.1**: Performance testing with large datasets
- [ ] **Step 4.2**: Edge case validation
- [ ] **Step 4.3**: Documentation updates

## üîÅ Implementation Prompts

### Step 1.1: Add Test Data for New Patterns

```text
Create comprehensive test data for the two new extraction patterns identified in the analysis.

Requirements:
1. Checkmark Format Test Data:
   - Valid examples: `‚úìBrush: Kent Infinity`, `‚úìRazor: Kopparkant +`, `‚úìBlade: feather (1)`, `‚úìLather: Cremo Citrus`
   - Edge cases: `‚úì Brush: Kent Infinity` (space after checkmark), `‚úìRazor: Kopparkant +` (special chars)
   - Invalid examples: `‚úìBrush Kent Infinity` (no colon), `Brush: Kent Infinity` (no checkmark)

2. Emoji Bold Format Test Data:
   - Valid examples: `* **Straight Razor** - Fontani Scarperia`, `* **Shaving Brush** - Leonidam`, `* **Shaving Soap** - Saponificio Varesino`
   - Edge cases: `* **Straight Razor** Fontani Scarperia` (no dash), `* **Shaving Brush** - Leonidam - 26mm Fan`
   - Invalid examples: `* Straight Razor - Fontani Scarperia` (no bold), `**Straight Razor** - Fontani Scarperia` (no asterisk)

3. Field Mapping Validation:
   - Map "Lather" ‚Üí "soap"
   - Map "Straight Razor" ‚Üí "razor" 
   - Map "Shaving Brush" ‚Üí "brush"
   - Map "Shaving Soap" ‚Üí "soap"

Create test files in `tests/extract/test_new_patterns.py` with comprehensive test cases covering all scenarios.
```

### Step 1.2: Create Unit Tests for Regex Patterns

```text
Implement unit tests for the new regex patterns in the extraction phase.

Requirements:
1. Test Checkmark Pattern Regex:
   - Pattern: `^‚úì\s*(\w+(?:\s+\w+)*)\s*[-:]\s*(.+)$`
   - Test field extraction: `‚úìBrush: Kent Infinity` ‚Üí field="Brush", value="Kent Infinity"
   - Test optional space: `‚úì Brush: Kent Infinity` ‚Üí field="Brush", value="Kent Infinity"
   - Test special characters: `‚úìRazor: Kopparkant +` ‚Üí field="Razor", value="Kopparkant +"

2. Test Emoji Bold Pattern Regex:
   - Pattern: `^\*\s*\*\*(\w+(?:\s+\w+)*)\*\*\s*[-:]\s*(.+)$`
   - Test field extraction: `* **Straight Razor** - Fontani Scarperia` ‚Üí field="Straight Razor", value="Fontani Scarperia"
   - Test multi-word fields: `* **Shaving Brush** - Leonidam` ‚Üí field="Shaving Brush", value="Leonidam"
   - Test without dash: `* **Shaving Soap** Saponificio Varesino` ‚Üí field="Shaving Soap", value="Saponificio Varesino"

3. Test Field Mapping Logic:
   - "Lather" ‚Üí "soap"
   - "Straight Razor" ‚Üí "razor"
   - "Shaving Brush" ‚Üí "brush" 
   - "Shaving Soap" ‚Üí "soap"
   - Unknown fields ‚Üí skip

Create comprehensive unit tests in `tests/extract/test_new_patterns.py` with 100% coverage of edge cases.
```

### Step 1.3: Create Integration Tests

```text
Create integration tests using real examples from the analysis data.

Requirements:
1. Real Data Integration Tests:
   - Use actual examples from `skipped_patterns_analysis.json`
   - Test checkmark format: `‚úìBrush: Kent Infinity`, `‚úìRazor: Kopparkant +`, `‚úìBlade: feather (1)`, `‚úìLather: Cremo Citrus`
   - Test emoji bold format: `* **Straight Razor** - Fontani Scarperia`, `* **Shaving Brush** - Leonidam`, `* **Shaving Soap** - Saponificio Varesino`

2. End-to-End Pipeline Tests:
   - Test complete extraction ‚Üí match ‚Üí enrich flow with new patterns
   - Verify extracted data structure matches existing format
   - Ensure no regression in existing extraction patterns

3. Performance Tests:
   - Test with large comment datasets
   - Verify extraction speed remains acceptable (<5s for 1000 comments)
   - Memory usage validation

Create integration tests in `tests/extract/test_integration_new_patterns.py` using pytest fixtures and real data samples.
```

### Step 2.1: Implement Checkmark Format Patterns

```text
Add checkmark format regex patterns to the extraction phase.

Requirements:
1. Update `sotd/extract/fields.py`:
   - Add checkmark pattern to `get_patterns()` function
   - Pattern: `^‚úì\s*(\w+(?:\s+\w+)*)\s*[-:]\s*(.+)$`
   - Handle optional space after checkmark
   - Extract field name and value separately

2. Update `sotd/extract/comment.py`:
   - Add checkmark pattern detection in `parse_comment()`
   - Map extracted fields to standard field names
   - Preserve original text in output structure

3. Field Mapping:
   - "Lather" ‚Üí "soap"
   - "Razor" ‚Üí "razor"
   - "Blade" ‚Üí "blade"
   - "Brush" ‚Üí "brush"
   - Unknown fields ‚Üí skip

4. Error Handling:
   - Graceful handling of malformed checkmark patterns
   - Log warnings for unrecognized field names
   - Maintain backward compatibility

Implement with comprehensive error handling and logging. Ensure all existing tests continue to pass.
```

### Step 2.2: Implement Emoji Bold Format Patterns

```text
Add emoji bold format regex patterns to the extraction phase.

Requirements:
1. Update `sotd/extract/fields.py`:
   - Add emoji bold pattern to `get_patterns()` function
   - Pattern: `^\*\s*\*\*(\w+(?:\s+\w+)*)\*\*\s*[-:]\s*(.+)$`
   - Handle multi-word field names (e.g., "Straight Razor", "Shaving Brush")
   - Extract field name between `**` markers and value separately

2. Update `sotd/extract/comment.py`:
   - Add emoji bold pattern detection in `parse_comment()`
   - Map extracted fields to standard field names
   - Preserve original text in output structure

3. Field Mapping:
   - "Straight Razor" ‚Üí "razor"
   - "Shaving Brush" ‚Üí "brush"
   - "Shaving Soap" ‚Üí "soap"
   - Unknown fields ‚Üí skip

4. Edge Case Handling:
   - Handle patterns without dash separator
   - Handle patterns with extra whitespace
   - Handle patterns with special characters in values

Implement with comprehensive error handling and logging. Ensure all existing tests continue to pass.
```

### Step 2.3: Add Field Mapping Logic

```text
Implement robust field mapping logic for the new patterns.

Requirements:
1. Create Field Mapping Function:
   - Function: `map_field_name(field_name: str) -> Optional[str]`
   - Map checkmark fields: "Lather" ‚Üí "soap", "Razor" ‚Üí "razor", etc.
   - Map emoji bold fields: "Straight Razor" ‚Üí "razor", "Shaving Brush" ‚Üí "brush", etc.
   - Return None for unrecognized fields

2. Update `sotd/extract/comment.py`:
   - Integrate field mapping into `parse_comment()`
   - Skip lines with unrecognized field names
   - Log warnings for unmapped fields

3. Field Mapping Rules:
   - Case-insensitive matching
   - Handle variations: "Lather"/"lather" ‚Üí "soap"
   - Handle multi-word fields: "Straight Razor" ‚Üí "razor"
   - Preserve original field name in output for debugging

4. Validation:
   - Ensure mapped fields are valid core fields (razor, blade, brush, soap)
   - Prevent duplicate field extraction
   - Maintain field order consistency

Implement with comprehensive logging and validation. Add unit tests for field mapping logic.
```

### Step 3.1: Integrate New Patterns into Pipeline

```text
Integrate the new extraction patterns into the main extraction pipeline.

Requirements:
1. Update `sotd/extract/run.py`:
   - Ensure new patterns are included in extraction process
   - Add logging for new pattern matches
   - Update progress reporting to include new patterns

2. Update `sotd/extract/comment.py`:
   - Integrate checkmark and emoji bold patterns into main parsing logic
   - Ensure proper field ordering (razor, blade, brush, soap)
   - Maintain existing output format compatibility

3. Performance Optimization:
   - Compile regex patterns once at module level
   - Optimize field mapping lookups
   - Minimize memory allocations

4. Error Handling:
   - Graceful handling of malformed patterns
   - Detailed logging for debugging
   - Maintain pipeline stability

Ensure all existing functionality remains intact and performance is acceptable.
```

### Step 3.2: Validate Against Existing Test Suite

```text
Run comprehensive validation against the existing test suite.

Requirements:
1. Run All Existing Tests:
   - `make test` - ensure all existing tests pass
   - `make test-extract` - focus on extraction tests
   - `make test-integration` - integration tests

2. Performance Validation:
   - Test extraction speed with large datasets
   - Verify memory usage remains acceptable
   - Check for any performance regressions

3. Backward Compatibility:
   - Ensure existing extraction patterns still work
   - Verify output format remains unchanged
   - Test with existing data files

4. Quality Checks:
   - `make format` - code formatting
   - `make lint` - linting rules
   - `make typecheck` - type checking

Fix any issues found and ensure all quality checks pass before proceeding.
```

### Step 3.3: Test with Real Data Samples

```text
Test the new extraction patterns with real data samples from the analysis.

Requirements:
1. Real Data Testing:
   - Use actual examples from `skipped_patterns_analysis.json`
   - Test checkmark format examples: `‚úìBrush: Kent Infinity`, `‚úìRazor: Kopparkant +`
   - Test emoji bold format examples: `* **Straight Razor** - Fontani Scarperia`

2. End-to-End Testing:
   - Test complete pipeline: extract ‚Üí match ‚Üí enrich
   - Verify extracted data flows correctly through all phases
   - Check that matched products are correctly identified

3. Validation:
   - Verify field mapping works correctly
   - Check that product types are correctly identified
   - Ensure no false positives or negatives

4. Documentation:
   - Update extraction phase documentation
   - Add examples of new patterns
   - Document field mapping rules

Create test scripts to validate real data processing and document results.
```

### Step 4.1: Performance Testing

```text
Conduct comprehensive performance testing with large datasets.

Requirements:
1. Large Dataset Testing:
   - Test with 10,000+ comment samples
   - Measure extraction time per comment
   - Monitor memory usage during processing

2. Performance Benchmarks:
   - Baseline: existing extraction patterns only
   - Enhanced: with new checkmark and emoji bold patterns
   - Compare performance impact

3. Optimization:
   - Profile regex pattern performance
   - Optimize field mapping lookups
   - Minimize memory allocations

4. Thresholds:
   - Extraction time: <5ms per comment
   - Memory usage: <100MB for 10,000 comments
   - No more than 10% performance regression

Create performance test scripts and document results with benchmarks.
```

### Step 4.2: Edge Case Validation

```text
Validate edge cases and error conditions for the new patterns.

Requirements:
1. Edge Case Testing:
   - Malformed checkmark patterns: `‚úìBrush Kent Infinity` (no colon)
   - Malformed emoji bold patterns: `* **Straight Razor** Fontani Scarperia` (no separator)
   - Mixed patterns: `‚úìBrush: Kent Infinity * **Razor** - Kopparkant`

2. Error Handling:
   - Graceful handling of regex failures
   - Proper logging of parsing errors
   - No pipeline crashes on malformed input

3. Boundary Conditions:
   - Very long field names or values
   - Special characters in field names or values
   - Unicode characters and emojis

4. Stress Testing:
   - High-frequency pattern matching
   - Memory pressure scenarios
   - Concurrent processing

Create comprehensive edge case tests and ensure robust error handling.
```

### Step 4.3: Documentation Updates

```text
Update all relevant documentation to reflect the new extraction patterns.

Requirements:
1. Update Extraction Phase Documentation:
   - Document new checkmark format: `‚úìField: Value`
   - Document new emoji bold format: `* **Field** Value`
   - Add examples and field mapping rules

2. Update API Documentation:
   - Document new regex patterns
   - Update field mapping function documentation
   - Add performance characteristics

3. Update User Documentation:
   - Add examples of supported formats
   - Document field mapping rules
   - Provide troubleshooting guide

4. Update Development Documentation:
   - Update extraction phase specification
   - Document testing approach
   - Add performance benchmarks

Ensure all documentation is clear, accurate, and helpful for future development.
```

## üß† Critical Analysis

### Design Decisions

**Pattern Selection**: The data-driven analysis clearly identified checkmark and emoji bold formats as the highest-value patterns to implement. These patterns have:
- **Clear field identification** (28 + 168 = 196 total occurrences)
- **High confidence mapping** to core products
- **Consistent structure** that can be reliably parsed

**Rejection of Alternatives**: The analysis correctly rejected:
- **Implicit product extraction** (only 1 successful match in 10+ years)
- **International patterns** (only 1 French example found)
- **Other ambiguous patterns** (mostly pre/post-shave products)

### Implementation Strategy

**Incremental Approach**: The plan follows TDD principles with:
- **Test-first development** for each pattern
- **Comprehensive test coverage** including edge cases
- **Integration testing** with real data samples
- **Performance validation** to ensure no regressions

**Risk Mitigation**: The implementation minimizes risk by:
- **Maintaining backward compatibility** with existing patterns
- **Comprehensive error handling** for malformed input
- **Performance monitoring** to prevent regressions
- **Gradual rollout** with extensive testing

### Success Criteria

**Functional Requirements**:
- ‚úÖ Checkmark format extraction works correctly
- ‚úÖ Emoji bold format extraction works correctly  
- ‚úÖ Field mapping to core products is accurate
- ‚úÖ No regression in existing extraction patterns

**Performance Requirements**:
- ‚úÖ Extraction time remains <5ms per comment
- ‚úÖ Memory usage remains acceptable
- ‚úÖ No more than 10% performance regression

**Quality Requirements**:
- ‚úÖ All existing tests continue to pass
- ‚úÖ New tests provide comprehensive coverage
- ‚úÖ Code quality standards maintained
- ‚úÖ Documentation is complete and accurate

### Expected Impact

**Data Quality Improvement**: The new patterns should capture an additional 196 high-confidence product mentions across 10+ years of data, representing a meaningful improvement in extraction coverage.

**Maintainability**: The implementation follows established patterns and maintains code quality standards, ensuring long-term maintainability.

**Future Extensibility**: The field mapping approach provides a foundation for adding additional patterns in the future if needed.

## üìã Success Criteria

- [ ] Checkmark format extraction works for all test cases
- [ ] Emoji bold format extraction works for all test cases  
- [ ] Field mapping correctly identifies core products
- [ ] No regression in existing extraction patterns
- [ ] Performance remains within acceptable thresholds
- [ ] All quality checks pass (format, lint, typecheck, test)
- [ ] Documentation is complete and accurate
- [ ] Real data validation shows expected improvements

## üìù Session Notes

*To be updated during implementation*

---

**Next Steps**: Begin with Step 1.1 (Add Test Data for New Patterns) and proceed incrementally through each step, running quality checks before each commit.
