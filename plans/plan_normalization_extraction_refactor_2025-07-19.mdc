# Normalization Extraction Refactor Plan
## Move Normalization from Matching to Extraction Phase

**Date**: 2025-07-19  
**Goal**: Move normalization entirely from matching to extraction phase, eliminating all normalization logic from matching and downstream phases.

---

## üìò Project Summary

Currently, normalization happens in multiple places:
- **Match phase**: Normalizes original text and stores both original/normalized
- **Analysis tools**: Re-normalize data when loading matched files
- **Downstream phases**: May re-normalize data again

**Target Architecture**:
- **Extraction phase**: Normalizes text once, stores both original/normalized
- **Match phase**: Uses pre-normalized text for matching, preserves both original/normalized
- **Analysis tools**: Use normalized field as primary data, original for debugging only
- **Downstream phases**: Use normalized field as primary data, original for debugging only

**Benefits**:
- Single source of truth for normalization
- Better performance (normalize once vs. multiple times)
- Cleaner architecture
- Eliminates debug spam from analysis tools
- Consistent data across all phases

---

## üß© Component Steps

### Phase 1: Extraction Phase Updates
1. **Update extraction data structure** - Change from simple strings to structured format with original/normalized
2. **Add normalization to extraction** - Normalize text during extraction process using normalize_for_matching
3. **Update extraction tests** - Test new structured format with original/normalized fields
4. **Update extraction CLI** - Ensure CLI handles structured format

### Phase 2: Match Phase Updates  
5. **Remove normalization from match phase** - Remove normalize_for_matching calls from match_record function
6. **Update match phase to use pre-normalized** - Use normalized field from extraction for matching operations
7. **Update match phase tests** - Test using pre-normalized text from extraction
8. **Preserve both fields in match output** - Match phase preserves both original/normalized from extraction

### Phase 3: Analysis Tools Updates
9. **Remove normalization from analysis tools** - Remove re-normalization logic
10. **Update analysis tools to use normalized as primary** - Use normalized field as primary data
11. **Update analysis tool tests** - Test using normalized field as primary data
12. **Remove debug normalization messages** - Eliminate debug spam

### Phase 4: Downstream Phase Updates
13. **Update enrich phase** - Use original for metadata extraction, matched data for enrichment
14. **Update aggregate phase** - Use matched data (includes both original/normalized)  
15. **Update report phase** - Use matched data (includes both original/normalized)
16. **Update all phase tests** - Test using matched data structure

### Phase 5: Integration and Validation
17. **End-to-end testing** - Test full pipeline with new architecture
18. **Performance validation** - Verify performance improvements
19. **Data validation** - Ensure data integrity across phases
20. **Documentation updates** - Update all relevant documentation

---

## üîÅ Implementation Prompts

### Step 1: Update Extraction Data Structure

```text
Update the extraction phase to store both original and normalized text for each product field.

**Context**: Currently extraction stores only the original text extracted from Reddit comments. We need to add a "normalized" field alongside "original" for each product field (razor, blade, brush, soap).

**Requirements**:
- Add "normalized" field to extraction output structure
- Use the canonical normalize_for_matching function from sotd.utils.match_filter_utils
- Preserve existing "original" field structure
- Maintain backward compatibility for existing extraction data

**Files to modify**:
- sotd/extract/comment.py - Update parse_comment to create structured format
- sotd/extract/run.py - Update extraction logic to handle structured format
- sotd/extract/save.py - Update save logic to handle structured format
- tests/extract/test_comment.py - Add tests for structured format
- tests/extract/test_run.py - Add tests for structured format
- tests/extract/test_save.py - Add tests for structured format

**Expected output structure**:
```json
{
  "razor": {
    "original": "Karve Overlander Nickel Plated Brass w/ 90mm Overlander handle",
    "normalized": "Karve Overlander Nickel Plated Brass"
  },
  "blade": {
    "original": "Gillette Nacet (5)",
    "normalized": "Gillette Nacet"
  }
}
```

**Current vs Target**:
- **Current**: `"razor": "Merkur 37c $ZAMAC $SLANT"` (simple string)
- **Target**: `"razor": {"original": "...", "normalized": "..."}` (structured)

**Implementation approach**:
1. Import normalize_for_matching in extraction modules
2. Change extraction output from simple strings to structured format
3. Normalize each product field during extraction processing
4. Store both original and normalized in extraction output
5. Update save logic to handle new structure
6. Add comprehensive tests for structured format functionality
```

### Step 2: Add Normalization to Extraction Process

```text
Implement normalization logic in the extraction phase to normalize text during the extraction process.

**Context**: We need to add normalization calls to the extraction phase where product fields are processed. This should happen after text extraction but before saving.

**Requirements**:
- Change extraction output from simple strings to structured format with original/normalized
- Normalize each product field (razor, blade, brush, soap) during extraction
- Use the same normalize_for_matching function used throughout the pipeline
- Handle edge cases (empty text, None values, etc.)
- Add debug logging for normalization (only when debug flag is set)

**Files to modify**:
- sotd/extract/comment.py - Update parse_comment to create structured format with normalization
- sotd/extract/run.py - Update extraction logic to handle structured format
- tests/extract/test_comment.py - Test structured format with normalization
- tests/extract/test_run.py - Test normalization during extraction

**Implementation approach**:
1. Import normalize_for_matching in extraction modules
2. Update parse_comment to create structured format with original/normalized
3. Add normalization calls after text extraction for each product field
4. Store normalized text alongside original text in structured format
5. Add debug logging for normalization operations
6. Add comprehensive tests for structured format functionality
7. Handle edge cases gracefully (empty strings, None values, etc.)

**Test cases to include**:
- Normal text with competition tags
- Text with usage counts
- Empty or None text
- Text with special characters
- Text that doesn't need normalization
```

### Step 3: Update Extraction Tests

```text
Add comprehensive tests for the new normalized field functionality in extraction phase.

**Context**: We've added normalization to the extraction phase and need to ensure it works correctly with comprehensive test coverage.

**Requirements**:
- Test structured format is created correctly with original/normalized fields
- Test normalization works correctly for all product fields
- Test edge cases (empty text, None values, etc.)
- Test backward compatibility with existing extraction data
- Test debug logging for normalization

**Files to modify**:
- tests/extract/test_comment.py - Add tests for structured format
- tests/extract/test_run.py - Add tests for structured format
- tests/extract/test_save.py - Add tests for saving structured data
- tests/extract/test_cli_extract.py - Add CLI tests for structured format

**Test cases to include**:
- Structured format creation with original/normalized fields
- Normalization of competition tags ($DOORKNOB, etc.)
- Normalization of usage counts ([5], (3), etc.)
- Normalization of special characters and formatting
- Empty string handling
- None value handling
- Backward compatibility with existing data
- Debug logging functionality
- CLI integration with structured format

**Implementation approach**:
1. Add test fixtures with various text formats
2. Test normalization for each product field type
3. Test edge cases and error conditions
4. Test backward compatibility
5. Test debug logging functionality
6. Ensure all tests pass with new normalized field
```

### Step 4: Update Extraction CLI

```text
Update the extraction CLI to handle the new normalized field and ensure proper integration.

**Context**: The extraction CLI needs to be updated to work with the new normalized field structure and ensure proper command-line functionality.

**Requirements**:
- Ensure CLI properly handles normalized field in output
- Add debug option for normalization logging
- Update help text to mention normalized field
- Test CLI integration with normalized data

**Files to modify**:
- sotd/extract/cli.py - Update CLI to handle normalized field
- tests/extract/test_cli_extract.py - Add CLI tests for normalized field
- docs/extract_phase_spec.md - Update documentation

**Implementation approach**:
1. Update CLI argument parsing if needed
2. Add debug option for normalization logging
3. Update help text and documentation
4. Add CLI tests for normalized field functionality
5. Test CLI integration end-to-end
6. Update documentation to reflect new structure
```

### Step 5: Remove Normalization from Match Phase

```text
Remove all normalization logic from the match phase since normalization now happens in extraction.

**Context**: The match phase currently normalizes text and adds a "normalized" field to output. We need to remove this since normalization now happens in extraction.

**Requirements**:
- Remove normalize_for_matching calls from match phase
- Remove "normalized" field from match phase output
- Update match phase to use pre-normalized text from extraction
- Maintain existing match functionality

**Files to modify**:
- sotd/match/run.py - Remove normalization logic
- sotd/match/base_matcher.py - Update to use pre-normalized text
- sotd/match/brush_matcher.py - Update to use pre-normalized text
- sotd/match/razor_matcher.py - Update to use pre-normalized text
- sotd/match/blade_matcher.py - Update to use pre-normalized text
- sotd/match/soap_matcher.py - Update to use pre-normalized text
- tests/match/test_run.py - Update tests for removed normalization
- tests/match/test_base_matcher.py - Update tests for pre-normalized text

**Implementation approach**:
1. Remove normalize_for_matching imports from match modules
2. Remove normalization calls from match_record function
3. Update matchers to use pre-normalized text from extraction
4. Remove "normalized" field from match output structure
5. Update all match phase tests
6. Ensure match functionality still works correctly
```

### Step 6: Update Match Phase to Use Pre-Normalized Text

```text
Update the match phase to use the pre-normalized text from extraction instead of normalizing during matching.

**Context**: The match phase needs to be updated to use the "normalized" field from extraction data instead of normalizing text during the match process.

**Requirements**:
- Update match phase to read "normalized" field from extraction data
- Use pre-normalized text for matching operations
- Maintain existing match functionality and accuracy
- Update all matchers to use pre-normalized text

**Files to modify**:
- sotd/match/run.py - Update to use pre-normalized text
- sotd/match/base_matcher.py - Update to use pre-normalized text
- sotd/match/brush_matcher.py - Update to use pre-normalized text
- sotd/match/razor_matcher.py - Update to use pre-normalized text
- sotd/match/blade_matcher.py - Update to use pre-normalized text
- sotd/match/soap_matcher.py - Update to use pre-normalized text
- tests/match/test_run.py - Update tests for pre-normalized text
- tests/match/test_base_matcher.py - Update tests for pre-normalized text

**Implementation approach**:
1. Update match_record function to use pre-normalized text
2. Update base matcher to use pre-normalized text
3. Update all specific matchers to use pre-normalized text
4. Ensure match accuracy is maintained
5. Update all match phase tests
6. Test with real extraction data
```

### Step 7: Update Match Phase Tests

```text
Update all match phase tests to work with pre-normalized text from extraction.

**Context**: The match phase tests need to be updated since we're now using pre-normalized text from extraction instead of normalizing during matching.

**Requirements**:
- Update test fixtures to include normalized field from extraction
- Test match phase with pre-normalized text
- Ensure all existing match functionality still works
- Test edge cases with pre-normalized text

**Files to modify**:
- tests/match/test_run.py - Update tests for pre-normalized text
- tests/match/test_base_matcher.py - Update tests for pre-normalized text
- tests/match/test_brush_matcher.py - Update tests for pre-normalized text
- tests/match/test_razor_matcher.py - Update tests for pre-normalized text
- tests/match/test_blade_matcher.py - Update tests for pre-normalized text
- tests/match/test_soap_matcher.py - Update tests for pre-normalized text

**Implementation approach**:
1. Update test fixtures to include normalized field
2. Update test cases to use pre-normalized text
3. Ensure all existing functionality still works
4. Test edge cases and error conditions
5. Test with real extraction data
6. Ensure all tests pass with new architecture
```

### Step 8: Preserve Normalized Field in Match Output

```text
Preserve the "normalized" field from extraction in match phase output since normalization now happens in extraction.

**Context**: The match phase should preserve the "normalized" field from extraction and use it for matching operations, while also preserving the "original" field for debugging.

**Requirements**:
- Preserve "normalized" field from extraction in match output
- Keep "original" field in match output (for debugging)
- Use "normalized" field for matching operations
- Update match output structure to preserve both fields

**Files to modify**:
- sotd/match/run.py - Preserve normalized field from extraction
- sotd/match/save.py - Update save logic to preserve both fields
- tests/match/test_run.py - Update tests for preserved fields
- tests/match/test_save.py - Update tests for preserved fields

**Implementation approach**:
1. Preserve normalized field from extraction in match output
2. Use normalized field for matching operations
3. Keep original field for debugging
4. Update all tests for preserved fields
5. Ensure backward compatibility where needed
6. Update documentation for new structure
```

### Step 9: Remove Normalization from Analysis Tools

```text
Remove all normalization logic from analysis tools since data is now pre-normalized from extraction.

**Context**: Analysis tools currently re-normalize data when loading matched files. Since data is now pre-normalized from extraction, we can remove this re-normalization logic.

**Requirements**:
- Remove normalize_for_matching calls from analysis tools
- Remove debug normalization messages
- Update analysis tools to use pre-normalized text
- Maintain existing analysis functionality

**Files to modify**:
- sotd/match/tools/utils/analysis_base.py - Remove normalization logic
- sotd/match/tools/analyzers/unmatched_analyzer.py - Remove normalization logic
- sotd/match/tools/analyzers/mismatch_analyzer.py - Remove normalization logic
- tests/match/tools/test_analysis_base.py - Update tests
- tests/match/tools/analyzers/test_unmatched_analyzer.py - Update tests

**Implementation approach**:
1. Remove normalize_for_matching imports from analysis modules
2. Remove normalization calls from analysis tools
3. Update analysis tools to use pre-normalized text
4. Remove debug normalization messages
5. Update all analysis tool tests
6. Ensure analysis functionality still works correctly
```

### Step 10: Update Analysis Tools to Use Normalized as Primary

```text
Update analysis tools to use the normalized field as primary data instead of re-normalizing data.

**Context**: Analysis tools need to be updated to use the "normalized" field as the primary data source, with "original" field only used for debugging.

**Requirements**:
- Update analysis tools to use "normalized" field as primary data
- Use normalized text for all analysis operations
- Keep original field only for debugging purposes
- Remove all re-normalization logic

**Files to modify**:
- sotd/match/tools/utils/analysis_base.py - Update to use normalized as primary
- sotd/match/tools/analyzers/unmatched_analyzer.py - Update to use normalized as primary
- sotd/match/tools/analyzers/mismatch_analyzer.py - Update to use normalized as primary
- tests/match/tools/test_analysis_base.py - Update tests
- tests/match/tools/analyzers/test_unmatched_analyzer.py - Update tests

**Implementation approach**:
1. Update analysis tools to use normalized field as primary data
2. Remove all re-normalization logic
3. Update test fixtures to use normalized field as primary
4. Ensure all analysis functionality still works
5. Test with real extraction data
6. Update all analysis tool tests
```

### Step 11: Update Analysis Tool Tests

```text
Update all analysis tool tests to work with pre-normalized text from extraction.

**Context**: Analysis tool tests need to be updated since we're now using pre-normalized text from extraction instead of re-normalizing during analysis.

**Requirements**:
- Update test fixtures to include normalized field from extraction
- Test analysis tools with pre-normalized text
- Ensure all existing analysis functionality still works
- Test edge cases with pre-normalized text

**Files to modify**:
- tests/match/tools/test_analysis_base.py - Update tests for pre-normalized text
- tests/match/tools/analyzers/test_unmatched_analyzer.py - Update tests for pre-normalized text
- tests/match/tools/analyzers/test_mismatch_analyzer.py - Update tests for pre-normalized text

**Implementation approach**:
1. Update test fixtures to include normalized field
2. Update test cases to use pre-normalized text
3. Ensure all existing functionality still works
4. Test edge cases and error conditions
5. Test with real extraction data
6. Ensure all tests pass with new architecture
```

### Step 12: Remove Debug Normalization Messages

```text
Remove all debug normalization messages from analysis tools since normalization now happens in extraction.

**Context**: Analysis tools currently print debug messages when normalizing text. Since normalization now happens in extraction, these debug messages are no longer needed and should be removed.

**Requirements**:
- Remove all debug normalization print statements
- Clean up debug logging related to normalization
- Maintain other debug functionality where needed
- Update tests to reflect removed debug messages

**Files to modify**:
- sotd/match/tools/utils/analysis_base.py - Remove debug normalization messages
- sotd/match/tools/analyzers/unmatched_analyzer.py - Remove debug normalization messages
- sotd/match/tools/analyzers/mismatch_analyzer.py - Remove debug normalization messages
- tests/match/tools/test_analysis_base.py - Update tests for removed debug messages

**Implementation approach**:
1. Remove all debug normalization print statements
2. Clean up debug logging related to normalization
3. Maintain other debug functionality
4. Update tests to reflect removed debug messages
5. Test that other debug functionality still works
```

### Step 13: Update Enrich Phase

```text
Update the enrich phase to use original text for metadata extraction and matched data for enrichment.

**Context**: The enrich phase operates on original text to extract usage counts and metadata, while using the matched data from the match phase for enrichment.

**Requirements**:
- Use original field for extracting usage counts and metadata
- Use matched data from match phase for enrichment
- Remove any normalization logic from enrich phase
- Maintain existing enrichment functionality
- Update enrich phase tests

**Files to modify**:
- sotd/enrich/run.py - Update to use original field for metadata extraction
- sotd/enrich/enrichers/*.py - Update enrichers to use original field appropriately
- tests/enrich/test_run.py - Update tests for original field usage
- tests/enrich/test_enrichers.py - Update tests for original field usage

**Implementation approach**:
1. Update enrich phase to use original field for metadata extraction
2. Use matched data from match phase for enrichment
3. Remove any normalization logic from enrich phase
4. Update all enrichers to use original field appropriately
5. Update all enrich phase tests
6. Ensure enrichment functionality still works correctly

**Example usage**:
- Use original "Gillette Nacet (5)" for extracting use count of 5
- Use matched data for blade specifications and enrichment
```

### Step 14: Update Aggregate Phase

```text
Update the aggregate phase to use pre-normalized text from extraction instead of normalizing during aggregation.

**Context**: The aggregate phase may be normalizing text during aggregation. Since normalization now happens in extraction, we need to update the aggregate phase to use pre-normalized text.

**Requirements**:
- Update aggregate phase to use pre-normalized text from extraction
- Remove any normalization logic from aggregate phase
- Maintain existing aggregation functionality
- Update aggregate phase tests

**Files to modify**:
- sotd/aggregate/run.py - Update to use pre-normalized text
- sotd/aggregate/aggregators/*.py - Update aggregators to use pre-normalized text
- tests/aggregate/test_run.py - Update tests for pre-normalized text
- tests/aggregate/test_aggregators.py - Update tests for pre-normalized text

**Implementation approach**:
1. Update aggregate phase to use pre-normalized text
2. Remove any normalization logic from aggregate phase
3. Update all aggregators to use pre-normalized text
4. Update all aggregate phase tests
5. Ensure aggregation functionality still works correctly
```

### Step 15: Update Report Phase

```text
Update the report phase to use pre-normalized text from extraction instead of normalizing during reporting.

**Context**: The report phase may be normalizing text during reporting. Since normalization now happens in extraction, we need to update the report phase to use pre-normalized text.

**Requirements**:
- Update report phase to use pre-normalized text from extraction
- Remove any normalization logic from report phase
- Maintain existing reporting functionality
- Update report phase tests

**Files to modify**:
- sotd/report/run.py - Update to use pre-normalized text
- sotd/report/generators/*.py - Update generators to use pre-normalized text
- tests/report/test_run.py - Update tests for pre-normalized text
- tests/report/test_generators.py - Update tests for pre-normalized text

**Implementation approach**:
1. Update report phase to use pre-normalized text
2. Remove any normalization logic from report phase
3. Update all generators to use pre-normalized text
4. Update all report phase tests
5. Ensure reporting functionality still works correctly
```

### Step 16: Update All Phase Tests

```text
Update all phase tests to work with pre-normalized text from extraction.

**Context**: All phase tests need to be updated since we're now using pre-normalized text from extraction instead of normalizing during each phase.

**Requirements**:
- Update test fixtures to include normalized field from extraction
- Test all phases with pre-normalized text
- Ensure all existing functionality still works
- Test edge cases with pre-normalized text

**Files to modify**:
- All test files in tests/enrich/, tests/aggregate/, tests/report/
- Update test fixtures to include normalized field
- Update test cases to use pre-normalized text

**Implementation approach**:
1. Update all test fixtures to include normalized field
2. Update all test cases to use pre-normalized text
3. Ensure all existing functionality still works
4. Test edge cases and error conditions
5. Test with real extraction data
6. Ensure all tests pass with new architecture
```

### Step 17: End-to-End Testing

```text
Perform comprehensive end-to-end testing of the entire pipeline with the new normalization architecture.

**Context**: We need to test the entire pipeline from extraction through reporting to ensure the new normalization architecture works correctly end-to-end.

**Requirements**:
- Test full pipeline with real data
- Verify normalization happens only in extraction
- Verify all phases work correctly with pre-normalized text
- Test performance improvements
- Test data integrity across all phases

**Test scenarios**:
- Run full pipeline on test data
- Verify extraction produces normalized field
- Verify match phase uses pre-normalized text
- Verify analysis tools use pre-normalized text
- Verify enrich/aggregate/report phases use pre-normalized text
- Test performance improvements
- Test data integrity

**Implementation approach**:
1. Create test data with various text formats
2. Run full pipeline on test data
3. Verify normalization happens only in extraction
4. Verify all phases work correctly
5. Test performance improvements
6. Test data integrity
7. Document any issues found
```

### Step 18: Performance Validation

```text
Validate that the new normalization architecture provides the expected performance improvements.

**Context**: One of the main benefits of moving normalization to extraction is performance improvement. We need to validate that this improvement is actually achieved.

**Requirements**:
- Measure performance before and after refactor
- Test normalization performance in extraction vs. multiple phases
- Verify elimination of duplicate normalization
- Document performance improvements

**Test scenarios**:
- Measure extraction phase performance
- Measure match phase performance
- Measure analysis tool performance
- Compare before/after performance
- Test with large datasets

**Implementation approach**:
1. Create performance test scripts
2. Measure performance before refactor
3. Measure performance after refactor
4. Compare results
5. Document improvements
6. Test with various data sizes
```

### Step 19: Data Validation

```text
Validate that data integrity is maintained across all phases with the new normalization architecture.

**Context**: We need to ensure that moving normalization to extraction doesn't affect data integrity or accuracy across the pipeline.

**Requirements**:
- Verify data integrity across all phases
- Test with various text formats and edge cases
- Ensure no data loss or corruption
- Validate normalization accuracy

**Test scenarios**:
- Test with competition tags
- Test with usage counts
- Test with special characters
- Test with edge cases
- Test with large datasets
- Compare before/after data accuracy

**Implementation approach**:
1. Create comprehensive test datasets
2. Run before/after comparisons
3. Verify data integrity
4. Test edge cases
5. Validate normalization accuracy
6. Document any issues found
```

### Step 20: Documentation Updates

```text
Update all relevant documentation to reflect the new normalization architecture.

**Context**: The normalization architecture has changed significantly. All documentation needs to be updated to reflect these changes.

**Requirements**:
- Update phase specifications
- Update API documentation
- Update user guides
- Update developer documentation
- Update architecture documentation

**Files to modify**:
- docs/extract_phase_spec.md - Update extraction specification
- docs/match_phase_spec.md - Update match specification
- docs/enrich_phase_spec.md - Update enrich specification
- docs/aggregate_phase_spec.md - Update aggregate specification
- docs/report_phase_spec.md - Update report specification
- README.md - Update main documentation
- All other relevant documentation files

**Implementation approach**:
1. Update all phase specifications
2. Update API documentation
3. Update user guides
4. Update developer documentation
5. Update architecture documentation
6. Ensure all documentation is consistent
```

---

## üß† Critical Analysis

### Architecture Benefits
- **Single source of truth**: Normalization happens once in extraction
- **Better performance**: Eliminates duplicate normalization across phases
- **Cleaner architecture**: Clear separation of concerns
- **Reduced complexity**: Each phase focuses on its core responsibility

### Risk Mitigation
- **Backward compatibility**: Maintain existing data structures where possible
- **Incremental approach**: Update one phase at a time
- **Comprehensive testing**: Test each phase thoroughly before moving to next
- **Data validation**: Ensure no data loss or corruption

### Implementation Strategy
- **Phase-by-phase approach**: Update extraction first, then match, then analysis, then downstream
- **Test-driven development**: Write tests first, then implement
- **Incremental validation**: Test each phase after updates
- **Performance monitoring**: Measure improvements throughout

### Success Criteria
- ‚úÖ No normalization happens outside extraction phase
- ‚úÖ All phases use pre-normalized text from extraction
- ‚úÖ Performance improvements achieved
- ‚úÖ Data integrity maintained
- ‚úÖ All tests pass
- ‚úÖ Documentation updated
- ‚úÖ Debug spam eliminated

### Potential Challenges
- **Breaking changes**: Some phases may need significant updates
- **Test complexity**: Need to update many test fixtures
- **Performance regression**: Need to ensure no performance degradation
- **Data migration**: May need to handle existing data

This plan provides a comprehensive, incremental approach to moving normalization from matching to extraction while maintaining data integrity and improving performance.

Model: Claude-3.5-Sonnet
description:
globs:
alwaysApply: false
---
