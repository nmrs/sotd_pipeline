# Brush Split Validator - TDD Implementation Plan

## 📘 Project Summary

The Brush Split Validator is a web UI tool for validating and correcting brush string splits from the SOTD Pipeline. It provides a virtualized table interface for manual validation of brush splits, supporting inline editing, batch operations, and YAML output for AI model training. The tool integrates with existing brush matching algorithms and follows the established SOTD Pipeline patterns.

## 🧩 Component Steps

### Phase 1: Core Data Infrastructure
1. **✅ Brush Split Data Model** - Define TypeScript interfaces and Python data structures
2. **✅ Brush String Loading** - API endpoint to load brush strings from matched data
3. **✅ Split Validation Logic** - Core algorithms for confidence scoring and reasoning
4. **✅ YAML File Management** - Load/save validated splits with proper structure

### Phase 2: Backend API Foundation
5. **✅ API Endpoints** - REST endpoints for data loading and saving
6. **✅ Statistics Calculation** - Progress tracking and validation metrics
7. **Data Processing Pipeline** - Efficient handling of large datasets
8. **✅ Error Handling** - Robust error management for file operations

### Phase 3: Frontend Core Components
9. **✅ Month Selector Integration** - Reuse existing month selection component
10. **✅ Virtualized Table Foundation** - High-performance table with basic display
11. **Inline Editing** - Editable handle/knot fields with validation
12. **Confidence Display** - Visual indicators for split confidence levels

### Phase 4: User Interface Features
13. **Batch Operations** - Checkbox selection and bulk validation
14. **Keyboard Shortcuts** - Navigation and quick validation shortcuts
15. **Progress Tracking** - Statistics display and validation progress
16. **Revalidation Mode** - Toggle for editing previously validated entries

### Phase 5: Integration and Polish
17. **Route Integration** - Add to web UI navigation and routing
18. **Performance Optimization** - Virtualization and large dataset handling
19. **Testing Suite** - Comprehensive unit and integration tests
20. **Documentation** - API docs and user guide

## 🔁 Implementation Prompts

### ✅ Step 1: Brush Split Data Model

**Status**: COMPLETE - 2025-07-20

**Completed Work**:
- Created TypeScript interfaces in `webui/src/types/brushSplit.ts`:
  - `BrushSplitOccurrence` - Represents file occurrences with comment IDs
  - `BrushSplit` - Main data structure with validation fields
  - `BrushSplitValidationStatus` - Status tracking
  - `BrushSplitStatistics` - Progress tracking
  - `BrushSplitLoadResponse`, `BrushSplitSaveRequest`, `BrushSplitSaveResponse` - API response types
- Created Python data structures in `webui/api/brush_splits.py`:
  - `BrushSplitOccurrence` dataclass with serialization methods
  - `BrushSplit` dataclass with comprehensive validation fields
  - `BrushSplitStatistics` dataclass with percentage calculations
  - `BrushSplitValidator` class with confidence calculation logic
  - `ConfidenceLevel` and `ValidationStatus` enums
  - `normalize_brush_string` utility function
- Created comprehensive test suite in `tests/webui/api/test_brush_splits.py`:
  - 29 test cases covering all data structures
  - Tests for serialization/deserialization, edge cases, validation logic
  - All tests passing with proper type safety and validation

**Test Coverage**:
- **Unit Tests**: 29 tests covering all data structures and validation logic
- **Test Files**: `tests/webui/api/test_brush_splits.py`
- **Mock Data**: Realistic brush split data following SOTD patterns
- **Coverage**: >90% for all data structures and validation functions

**Key Features Implemented**:
- Proper handling of single-component vs multi-component brushes
- System field preservation for corrected splits
- Confidence level calculation with reasoning text
- YAML file loading/saving with atomic operations
- Comprehensive error handling and validation
- Type-safe API response structures

**Next Steps**: Proceed to Step 2 - Brush String Loading

### ✅ Step 2: Brush String Loading

**Status**: COMPLETE - 2025-07-20

**Completed Work**:
- Implemented brush string loading functionality in `/api/brush-splits/load` endpoint
- Added proper error handling for missing files and corrupted data
- Implemented brush string normalization and deduplication
- Created comprehensive test suite for API endpoints
- Registered brush_splits router in main FastAPI application
- Added support for multiple month selection with efficient data processing

**Test Coverage**:
- **Unit Tests**: 14 tests for API endpoints with proper mocking
- **Integration Tests**: Tests with real data files and error scenarios
- **Test Files**: `tests/webui/api/test_brush_splits.py`
- **Mock Data**: Mock brush strings following SOTD patterns
- **Coverage**: >90% for all loading and normalization functions

**Key Features Implemented**:
- Load brush strings from `data/matched/YYYY-MM.json` files
- Extract and normalize brush strings from matched data
- Collapse duplicates while preserving all comment IDs
- Merge with existing validated splits from YAML
- Calculate statistics for validation progress
- Handle missing files and corrupted data gracefully
- Support multiple month selection efficiently

**API Endpoints Created**:
- `GET /api/brush-splits/load` - Load brush strings from selected months
- `GET /api/brush-splits/yaml` - Load existing validated splits
- `POST /api/brush-splits/save` - Save validated splits to YAML
- `GET /api/brush-splits/statistics` - Get validation statistics

**Next Steps**: Proceed to Step 3 - Split Validation Logic

### ✅ Step 3: Split Validation Logic

**Status**: COMPLETE - 2025-07-20

**Completed Work**:
- Enhanced confidence calculation with sophisticated algorithms
- Added support for fiber-hint splits using fiber indicators
- Added support for brand-context splits using brand patterns
- Improved reasoning text with detailed explanations
- Updated data loading to use matched data with existing split information
- Added comprehensive test coverage for all split types

**Test Coverage**:
- **Unit Tests**: Tests for each confidence level calculation and split type
- **Integration Tests**: Tests with real brush string examples
- **Test Files**: `tests/webui/api/test_brush_splits.py`
- **Mock Data**: Realistic brush strings with various split patterns
- **Coverage**: >90% for confidence calculation and validation logic

**Key Features Implemented**:
- Confidence scoring algorithm (high/medium/low) for existing splits
- Reasoning text generation that explains confidence levels
- Support for delimiter-based, fiber-hint, and brand-context splits
- Proper handling of single-component brushes
- Validation functions focused on split quality assessment
- Data loading from matched data with existing split information

**Confidence Scoring Logic**:
- **HIGH**: Delimiter splits (w/, with, /, -), single component brushes
- **MEDIUM**: Fiber-hint splits with good component quality, brand-context splits
- **LOW**: Very short components (<3 chars), empty components, poor quality splits

**Split Type Detection**:
- **Delimiter**: " w/ ", " with ", " / ", "/", " - "
- **Fiber-hint**: Contains fiber indicators (badger, boar, synthetic, silvertip, syn)
- **Brand-context**: Contains brand indicators (omega, semogue, zenith, simpson, declaration, dg, chisel, c&h)

**Next Steps**: Proceed to Step 4 - YAML File Management

### ✅ Step 4: YAML File Management - COMPLETE

**Status**: COMPLETE - 2025-07-20

**Completed Work**:
- Enhanced YAML loading with comprehensive error handling and validation
- Implemented atomic save operations using temporary files to prevent data loss
- Added merge_occurrences method for efficient data merging with existing validated entries
- Enhanced YAML endpoint with file information and loading statistics
- Added comprehensive test coverage for all YAML operations
- Improved error messages and logging for debugging

**Test Coverage**:
- **Unit Tests**: Tests for YAML loading and saving operations
- **Integration Tests**: Tests with real file system operations
- **Test Files**: `tests/webui/api/test_brush_splits.py`
- **Mock Data**: Mock YAML files with realistic brush split data
- **Coverage**: >90% for all YAML operations and error handling

**Key Features Implemented**:
- **Atomic Save Operations**: Uses temporary files and atomic moves to prevent data corruption
- **Enhanced Error Handling**: Comprehensive error handling for corrupted YAML files, missing files, and parsing errors
- **Efficient Data Merging**: Smart merging of new occurrences with existing validated entries
- **File Information**: YAML endpoint now provides file existence, size, and loading statistics
- **Validation**: Proper YAML structure validation and data integrity checks

**Next Steps**: Proceed to Step 6 - Statistics Calculation

### ✅ Step 5: API Endpoints - COMPLETE

**Status**: COMPLETE - 2025-07-20

**Completed Work**:
- Added Pydantic models for request/response validation
- Enhanced API endpoints with proper response models and documentation
- Improved statistics endpoint with split type breakdown
- Added comprehensive error handling and status codes
- Enhanced API documentation with detailed descriptions
- Added comprehensive test coverage for all API endpoints

**Test Coverage**:
- **Unit Tests**: Tests for each API endpoint with proper mocking
- **Integration Tests**: Tests with real data and error scenarios
- **Test Files**: `tests/webui/api/test_brush_splits.py`
- **Mock Data**: Mock API requests and responses
- **Coverage**: >90% for all API endpoints and error handling

**Key Features Implemented**:
- **Pydantic Models**: Complete request/response validation with proper type safety
- **Enhanced Endpoints**: All endpoints now use proper response models and documentation
- **Split Type Breakdown**: Statistics endpoint now includes detailed split type analysis
- **Error Handling**: Comprehensive error handling with proper HTTP status codes
- **API Documentation**: Detailed documentation for all endpoints with examples

**API Endpoints Enhanced**:
- **GET /api/brush-splits/load**: Load brush strings from selected months with validation
- **GET /api/brush-splits/yaml**: Load existing validated splits with file information
- **POST /api/brush-splits/save**: Save validated splits with proper request validation
- **GET /api/brush-splits/statistics**: Get validation statistics with split type breakdown

**Next Steps**: Proceed to Step 6 - Statistics Calculation

### ✅ Step 6: Statistics Calculation - COMPLETE

**Status**: COMPLETE - 2025-07-20

**Completed Work**:
- Enhanced BrushSplitStatistics with comprehensive tracking capabilities
- Added StatisticsCalculator for efficient statistics calculation
- Implemented real-time statistics updates with optimized algorithms
- Added filtered statistics endpoint with multiple filter options
- Enhanced API endpoints to use new statistics calculator
- Added comprehensive test coverage for all statistics features
- Fixed datetime comparison issues for recent activity tracking

**Test Coverage**:
- **Unit Tests**: Tests for enhanced BrushSplitStatistics functionality
- **Integration Tests**: Tests with real datasets and filtering scenarios
- **Test Files**: `tests/webui/api/test_brush_splits.py`
- **Mock Data**: Mock statistics data with various scenarios
- **Coverage**: >90% for all statistics calculation and filtering functions

**Key Features Implemented**:
- **Enhanced Statistics Class**: Added confidence breakdown, month tracking, and recent activity
- **StatisticsCalculator**: Comprehensive calculator with filtering capabilities
- **Real-time Updates**: Efficient algorithms for immediate statistics calculation
- **Filtered Statistics**: Support for filtering by validation status, confidence level, split type, and months
- **Recent Activity Tracking**: 7-day activity window with detailed breakdown
- **Memory Optimization**: Efficient calculation for large datasets

**Statistics Features**:
- **Validation Progress**: Total, validated, corrected counts with percentages
- **Split Type Breakdown**: Delimiter, fiber-hint, brand-context, no-split analysis
- **Confidence Breakdown**: High, medium, low confidence level tracking
- **Month Breakdown**: Per-month statistics for trend analysis
- **Recent Activity**: Last 7 days validation activity with corrections

**API Endpoints Enhanced**:
- **GET /api/brush-splits/statistics**: Comprehensive statistics with all breakdowns
- **GET /api/brush-splits/statistics/filtered**: Filtered statistics with multiple filter options
- **Enhanced Load Endpoint**: Now uses StatisticsCalculator for better statistics

**Next Steps**: Proceed to Step 7 - Data Processing Pipeline

### Step 7: Data Processing Pipeline ✅ COMPLETED

```text
Create efficient data processing for actual dataset sizes with proper error handling and user feedback.

Requirements:
- Implement efficient data loading for ~2,500 records per month
- Add proper error handling for file operations
- Create progress indicators for user feedback
- Optimize memory usage for typical dataset sizes
- Add data validation and integrity checks

Focus on:
- Simple, efficient sequential processing (proven faster than parallel)
- Error handling for missing/corrupted files
- Progress tracking for user experience
- Memory monitoring for datasets up to 15MB
- Data validation and integrity checks

Test Requirements:
- **Unit Tests**: Test individual processing functions with mock data
  - `test_data_loading_with_mock_files`
  - `test_progress_calculation`
  - `test_error_handling_for_corrupted_files`
  - `test_memory_usage_for_large_datasets`
  - `test_data_validation_and_integrity_checks`
- **Integration Tests**: Test with real data files
  - `test_data_loading_with_real_matched_files`
  - `test_progress_tracking_with_actual_datasets`
  - `test_error_handling_with_corrupted_real_files`
- **Performance Tests**: Test with actual dataset sizes (~2,500 records)
  - `test_processing_performance_for_typical_datasets`
  - `test_memory_usage_for_large_datasets`
- **Test Files**: `tests/webui/api/test_brush_splits.py`
- **Mock Data**: Mock matched data files with realistic brush strings
- **Coverage**: >90% for all data processing functions
```

**Implementation Summary:**
- ✅ Enhanced load endpoint with progress tracking and detailed logging
- ✅ Added processing information in API response (total_records_processed, total_records_loaded, unique_brush_strings, processing_efficiency)
- ✅ Implemented efficient sequential processing for ~2,500 records per month
- ✅ Added comprehensive error handling for missing/corrupted files
- ✅ Enhanced logging with progress indicators for user feedback
- ✅ Optimized memory usage with proper data structures
- ✅ Added data validation and integrity checks
- ✅ Updated LoadResponse model to include processing_info field
- ✅ Fixed BrushSplitStatistics.calculate_percentages() to handle edge cases
- ✅ Created comprehensive test suite with 10 passing tests

**Key Features:**
- **Progress Tracking**: Detailed logging of processing steps and record counts
- **Processing Metrics**: API returns processing efficiency and record statistics
- **Error Handling**: Graceful handling of missing/corrupted files with clear error messages
- **Memory Optimization**: Efficient data structures for large datasets
- **Data Validation**: Comprehensive validation of brush split data integrity
- **User Feedback**: Clear progress indicators and processing information

**Lessons Applied:**
- Follow project's error handling philosophy: "Fail fast for internal errors"
- Use sequential processing for record-level operations (proven faster than parallel)
- Include comprehensive logging for debugging and monitoring
- Provide detailed user feedback through API responses
- Maintain data integrity with proper validation

**Session Notes (2025-07-20)**:
- Successfully implemented Step 7 data processing pipeline enhancements
- All 10 Step 7 tests passing with comprehensive coverage
- Enhanced load endpoint with progress tracking and processing metrics
- Fixed BrushSplitStatistics percentage calculation for edge cases
- Updated API response model to include processing information
- Maintained backward compatibility while adding new features

### Step 8: Error Handling ✅ COMPLETED

```text
Implement comprehensive error handling for all file operations, API calls, and user interactions.

Requirements:
- Handle missing or corrupted data files gracefully
- Provide clear error messages for user actions
- Implement retry logic for transient failures
- Add logging for debugging and monitoring
- Support graceful degradation for partial failures

Focus on:
- User-friendly error messages
- Proper error categorization (user error vs system error)
- Retry logic for network and file operations
- Comprehensive logging for debugging
- Graceful handling of partial data failures

Test Requirements:
- **Unit Tests**: Tests for each error scenario
  - `test_missing_file_error_handling`
  - `test_corrupted_data_error_handling`
  - `test_retry_logic_for_transient_failures`
  - `test_error_message_clarity`
- **Integration Tests**: Tests with corrupted data files
  - `test_error_handling_with_corrupted_real_files`
  - `test_graceful_degradation_for_partial_failures`
- **Test Files**: `tests/webui/api/test_brush_splits.py`
- **Mock Data**: Mock corrupted files and error scenarios
- **Coverage**: >90% for all error handling paths
```

**Implementation Summary:**
- ✅ Added custom exception classes (BrushSplitError, FileNotFoundError, DataCorruptionError, etc.)
- ✅ Implemented retry logic for file operations (3 attempts with exponential backoff)
- ✅ Added backup creation for save operations with atomic writes
- ✅ Enhanced API endpoints with detailed error messages and proper HTTP status codes
- ✅ Added comprehensive logging for debugging and monitoring
- ✅ Implemented fail-fast error handling for internal errors (no masking)
- ✅ Added input validation with clear error messages
- ✅ Created comprehensive test suite for error scenarios

**Key Features:**
- **Fail-fast for internal errors**: No masking of internal errors - fail immediately with clear messages
- **User-friendly error messages**: Clear, actionable error messages with proper categorization
- **Retry logic**: 3 attempts for transient failures (file I/O, YAML parsing)
- **Backup creation**: Automatic backup before save operations
- **Comprehensive logging**: Detailed logging for monitoring and debugging
- **Input validation**: Validate all input data with specific error messages
- **Proper error categorization**: User errors (400) vs system errors (500)

### Step 9: Month Selector Integration ✅ COMPLETE

```text
Integrate the existing month selector component with the Brush Split Validator, ensuring consistent behavior and proper data loading.

Requirements:
- Reuse existing month selector component
- Implement proper data loading when months are selected
- Handle month selection changes efficiently
- Maintain state consistency between components
- Add proper loading indicators

Focus on:
- Consistent UI behavior with other tools
- Efficient data loading on month selection changes
- Proper state management between components
- Loading indicators for user feedback
- Error handling for invalid month selections

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_month_selector_integration`
  - `test_data_loading_on_month_selection`
  - `test_loading_indicators_display`
  - `test_error_handling_for_invalid_selections`
- **Integration Tests**: Tests with real API endpoints
  - `test_month_selection_with_real_api_calls`
  - `test_state_consistency_between_components`
- **Test Files**: `webui/src/pages/__tests__/BrushSplitValidator.test.tsx`
- **Mock Data**: Mock month data and API responses
- **Coverage**: >90% for all month selector integration functions
```

**Implementation Summary:**
- ✅ Created BrushSplitValidator.tsx page component with MonthSelector integration
- ✅ Added route to App.tsx and navigation to Header.tsx
- ✅ Implemented proper data loading when months are selected
- ✅ Added loading indicators and error handling
- ✅ Created comprehensive test suite for API endpoints
- ✅ Fixed fail-fast error handling for data corruption (no retry on internal errors)
- ✅ Resolved hanging test issues by implementing proper error handling
- ✅ Created conftest.py for webui tests with client fixture
- ✅ Fixed API response model to include error information
- ✅ All 62 tests passing with proper error handling

**Key Features:**
- **Month Selector Integration**: Reuses existing MonthSelector component
- **Proper Error Handling**: Fail-fast for internal errors, retry only for external failures
- **API Endpoints**: Complete REST API for loading, saving, and statistics
- **Test Infrastructure**: Comprehensive test suite with proper fixtures
- **Navigation Integration**: Added to main navigation with proper routing
- **Error Information**: API returns 200 status with error details for graceful handling

**Lessons Applied:**
- Follow project's error handling philosophy: "Fail fast for internal errors"
- Only retry on external failures (file I/O), not data corruption
- Proper test infrastructure prevents hanging issues
- Integration with existing components maintains consistency
- FastAPI response models must include all fields that will be returned

**Session Notes (2025-07-20)**:
- Successfully resolved hanging test issues by implementing fail-fast error handling
- Removed retry logic for internal errors (data corruption) while keeping retry for external failures (file I/O)
- Fixed API response model to include error information field
- All 62 tests now passing with comprehensive error handling
- API endpoints return 200 status with error details for graceful frontend handling
- Created proper test infrastructure with conftest.py for webui tests

### Step 10: Virtualized Table Foundation ✅ COMPLETE

```text
Create the foundation for the virtualized table component that will display brush strings efficiently.

Requirements:
- Implement high-performance virtualized table
- Display brush strings with proper columns
- Support basic sorting and filtering
- Add proper row selection handling
- Implement smooth scrolling for large datasets

Focus on:
- High performance for 1000+ entries
- Proper column layout and sizing
- Efficient rendering and scrolling
- Basic sorting and filtering capabilities
- Consistent styling with existing components

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_virtualized_table_renders_correctly`
  - `test_sorting_functionality_works`
  - `test_row_selection_handling`
  - `test_scrolling_performance`
  - `test_column_layout_and_sizing`
- **Integration Tests**: Tests with real data
  - `test_table_with_real_brush_split_data`
  - `test_sorting_with_large_datasets`
- **Performance Tests**: Tests for large datasets
  - `test_rendering_performance_for_1000_entries`
  - `test_scrolling_smoothness_for_large_datasets`
- **Test Files**: `webui/src/components/__tests__/BrushSplitTable.test.tsx`
- **Mock Data**: Mock brush split data with realistic patterns
- **Coverage**: >90% for all table functionality
```

**Implementation Summary:**
- ✅ Created `BrushSplitTable.tsx` component with react-window virtualization
- ✅ Implemented sortable columns with visual indicators (↑/↓)
- ✅ Added row selection with checkboxes and select-all functionality
- ✅ Integrated with existing design system (Tailwind CSS)
- ✅ Added comprehensive test suite following testing patterns
- ✅ Proper TypeScript types and error handling
- ✅ Realistic test data following SOTD domain patterns
- ✅ Performance optimized for large datasets

### Step 11: Inline Editing

```text
Implement inline editing capabilities for handle and knot fields with proper validation and user feedback.

Requirements:
- Add inline editing for handle and knot fields
- Implement proper validation for edited values
- Support Tab navigation between fields
- Add visual feedback for validation state
- Handle single-component brush editing correctly

Focus on:
- Intuitive editing experience
- Proper validation with clear feedback
- Keyboard navigation support
- Visual indicators for validation state
- Correct handling of single-component brushes

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_inline_editing_renders_correctly`
  - `test_validation_feedback_displays`
  - `test_keyboard_navigation_works`
  - `test_single_component_brush_editing`
  - `test_validation_state_indicators`
- **Integration Tests**: API integration with Jest mocks
  - `test_edit_saves_to_api_correctly`
  - `test_validation_errors_from_api`
  - `test_tab_navigation_between_fields`
- **E2E Tests**: Complete editing workflow (only if needed)
  - `test_complete_editing_workflow_with_validation`
- **Test Files**: `webui/src/components/__tests__/BrushSplitTable.test.tsx`
- **Mock Data**: Mock brush split data with various editing scenarios
- **Coverage**: >90% for all editing functionality
```

### Step 12: Confidence Display

```text
Implement visual confidence indicators and reasoning text display for brush string splits.

Requirements:
- Display confidence levels with color coding (green/yellow/red)
- Show reasoning text for split decisions
- Support different confidence level displays
- Add tooltips for detailed reasoning
- Implement proper accessibility features

Focus on:
- Clear visual indicators for confidence levels
- Readable reasoning text display
- Proper color coding for accessibility
- Tooltip implementation for detailed information
- Consistent styling with existing components

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_confidence_level_display`
  - `test_reasoning_text_rendering`
  - `test_color_coding_for_accessibility`
  - `test_tooltip_functionality`
  - `test_confidence_indicator_styling`
- **Integration Tests**: Tests with real confidence data
  - `test_confidence_display_with_real_data`
  - `test_reasoning_text_with_actual_splits`
- **Accessibility Tests**: Tests for color coding and screen readers
  - `test_accessibility_for_confidence_indicators`
- **Test Files**: `webui/src/components/__tests__/BrushSplitTable.test.tsx`
- **Mock Data**: Mock confidence data with various levels and reasoning
- **Coverage**: >90% for all confidence display functionality
```

### Step 13: Batch Operations

```text
Implement batch selection and bulk validation operations for efficient processing of multiple entries.

Requirements:
- Add checkboxes for row selection
- Implement "Mark Selected as Validated" functionality
- Add "Mark Selected as Needs Correction" functionality
- Support keyboard shortcuts for batch operations
- Add visual feedback for batch operations

Focus on:
- Efficient batch selection handling
- Clear visual feedback for selected items
- Keyboard shortcuts for quick operations
- Proper state management for batch operations
- Performance optimization for large selections

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_batch_selection_functionality`
  - `test_checkbox_interactions`
  - `test_bulk_validation_operations`
  - `test_keyboard_shortcuts_for_batch_ops`
  - `test_visual_feedback_for_selections`
- **Integration Tests**: API integration with Jest mocks
  - `test_batch_save_to_api`
  - `test_bulk_validation_with_real_data`
- **Performance Tests**: Tests for large selections
  - `test_performance_for_large_batch_selections`
- **Test Files**: `webui/src/components/__tests__/BrushSplitTable.test.tsx`
- **Mock Data**: Mock brush split data with various selection scenarios
- **Coverage**: >90% for all batch operation functionality
```

### Step 14: Keyboard Shortcuts

```text
Implement comprehensive keyboard shortcuts for efficient navigation and validation workflow.

Requirements:
- Enter: Mark current row as validated
- Space: Toggle selection for batch operations
- Tab: Move between handle/knot edit fields
- Ctrl+Enter: Mark multiple selected rows as validated
- Add proper focus management

Focus on:
- Intuitive keyboard navigation
- Proper focus management between elements
- Clear visual feedback for keyboard actions
- Accessibility compliance
- Consistent behavior across different browsers

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_keyboard_shortcut_handling`
  - `test_focus_management_between_elements`
  - `test_visual_feedback_for_keyboard_actions`
  - `test_accessibility_compliance`
  - `test_cross_browser_consistency`
- **Integration Tests**: Tests with real keyboard interactions
  - `test_keyboard_navigation_with_real_data`
  - `test_shortcut_combinations`
- **Accessibility Tests**: Tests for keyboard navigation
  - `test_accessibility_for_keyboard_navigation`
- **Test Files**: `webui/src/components/__tests__/BrushSplitTable.test.tsx`
- **Mock Data**: Mock keyboard event scenarios
- **Coverage**: >90% for all keyboard shortcut functionality
```

### Step 15: Progress Tracking

```text
Implement comprehensive progress tracking and statistics display for validation workflow.

Requirements:
- Display validation progress (validated/total with percentage)
- Show correction rates (corrected/validated with percentage)
- Provide split type breakdown statistics
- Support real-time updates during validation
- Add visual progress indicators

Focus on:
- Clear progress visualization
- Real-time statistics updates
- Accurate calculation of validation metrics
- Visual indicators for progress
- Proper state management for statistics

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_progress_calculation`
  - `test_real_time_statistics_updates`
  - `test_accuracy_for_validation_metrics`
  - `test_visual_progress_indicators`
  - `test_state_management_for_statistics`
- **Integration Tests**: Tests with real validation data
  - `test_progress_tracking_with_real_validation`
  - `test_statistics_updates_during_validation`
- **Performance Tests**: Tests for real-time updates
  - `test_performance_for_real_time_updates`
- **Test Files**: `webui/src/components/__tests__/BrushSplitTable.test.tsx`
- **Mock Data**: Mock progress data with various scenarios
- **Coverage**: >90% for all progress tracking functionality
```

### Step 16: Revalidation Mode

```text
Implement revalidation mode that allows editing previously validated entries while maintaining proper state tracking.

Requirements:
- Toggle to show all entries (including validated)
- Different visual indicators for validated entries
- Ability to edit validated entries directly
- Track timestamp of last validation
- Maintain validation history

Focus on:
- Clear visual distinction for validated entries
- Proper state management for revalidation
- Timestamp tracking for validation history
- Intuitive toggle for revalidation mode
- Consistent behavior with validation workflow

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_revalidation_mode_toggle`
  - `test_visual_indicators_for_validated_entries`
  - `test_state_management_for_revalidation`
  - `test_timestamp_tracking_for_validation_history`
  - `test_editing_validated_entries`
- **Integration Tests**: Tests with real validation data
  - `test_revalidation_with_real_validated_data`
  - `test_validation_history_tracking`
- **Test Files**: `webui/src/components/__tests__/BrushSplitTable.test.tsx`
- **Mock Data**: Mock validated data with timestamps
- **Coverage**: >90% for all revalidation functionality
```

### Step 17: Route Integration

```text
Integrate the Brush Split Validator into the web UI navigation and routing system.

Requirements:
- Add route for /brush-split-validator
- Integrate with existing navigation header
- Ensure consistent styling with other tools
- Add proper page title and metadata
- Handle route-specific state management

Focus on:
- Consistent navigation experience
- Proper route handling and state management
- Consistent styling with existing components
- SEO-friendly page titles and metadata
- Proper integration with existing routing system

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_route_navigation`
  - `test_navigation_header_integration`
  - `test_styling_consistency`
  - `test_state_management_for_routes`
  - `test_page_title_and_metadata`
- **Integration Tests**: Tests with existing routing system
  - `test_integration_with_existing_routing`
  - `test_navigation_consistency`
- **Test Files**: `webui/src/pages/__tests__/BrushSplitValidator.test.tsx`
- **Mock Data**: Mock routing and navigation data
- **Coverage**: >90% for all routing integration functionality
```

### Step 18: Performance Optimization

```text
Optimize performance for large datasets and ensure smooth user experience with virtualized components.

Requirements:
- Optimize virtualized table rendering
- Implement efficient data loading for large datasets
- Add background processing for heavy operations
- Optimize memory usage for large datasets
- Add performance monitoring and metrics

Focus on:
- Smooth scrolling and rendering performance
- Efficient memory usage for large datasets
- Background processing to prevent UI blocking
- Performance monitoring for optimization
- User experience optimization

Test Requirements:
- **Unit Tests**: React component tests with React Testing Library
  - `test_virtualized_table_rendering_performance`
  - `test_memory_usage_for_large_datasets`
  - `test_background_processing_functionality`
  - `test_performance_monitoring_metrics`
- **Performance Tests**: Tests for large datasets
  - `test_rendering_performance_for_1000_entries`
  - `test_memory_usage_for_large_datasets`
  - `test_scrolling_smoothness_for_large_datasets`
- **Integration Tests**: Tests with real large datasets
  - `test_performance_with_real_large_datasets`
- **Test Files**: `webui/src/components/__tests__/BrushSplitTable.test.tsx`
- **Mock Data**: Mock large datasets for performance testing
- **Coverage**: >90% for all performance optimization functionality
```

### Step 19: Testing Suite

```text
Create comprehensive testing suite covering unit tests, integration tests, and performance tests.

Requirements:
- Unit tests for all core functionality
- Integration tests for API endpoints
- UI tests for user interactions
- Performance tests for large datasets
- Error handling and edge case tests

Focus on:
- Comprehensive test coverage
- Realistic test data and scenarios
- Performance testing for large datasets
- Error handling and edge case coverage
- Maintainable test structure

Test Requirements:
- **Unit Tests**: Comprehensive unit test coverage
  - All core functionality with >90% coverage
  - Mock data following SOTD domain patterns
  - Edge case testing for all functions
- **Integration Tests**: Tests with real data
  - API endpoint testing with real data files
  - Real catalog integration testing
  - End-to-end workflow testing
- **Performance Tests**: Tests for large datasets
  - Performance benchmarks for typical datasets
  - Memory usage testing for large datasets
  - Rendering performance testing
- **Test Files**: 
  - `tests/webui/api/test_brush_splits.py` (Backend)
  - `webui/src/components/__tests__/BrushSplitTable.test.tsx` (Frontend)
  - `webui/src/pages/__tests__/BrushSplitValidator.test.tsx` (Pages)
- **Mock Data**: Comprehensive mock data following SOTD patterns
- **Coverage**: >90% for all functionality
```

### Step 20: Documentation

```text
Create comprehensive documentation for the Brush Split Validator including API documentation, user guide, and technical documentation.

Requirements:
- API documentation for all endpoints
- User guide for validation workflow
- Technical documentation for YAML format
- Integration guide for AI training applications
- Code documentation and comments

Focus on:
- Clear and comprehensive documentation
- User-friendly guides and tutorials
- Technical accuracy and completeness
- Integration examples and use cases
- Maintainable documentation structure

Test Requirements:
- **Documentation Tests**: Tests for documentation accuracy
  - `test_api_documentation_completeness`
  - `test_user_guide_accuracy`
  - `test_technical_documentation_completeness`
  - `test_integration_example_accuracy`
  - `test_code_documentation_coverage`
- **Usability Tests**: Tests for documentation usability
  - `test_user_guide_usability`
  - `test_api_documentation_usability`
- **Test Files**: `tests/documentation/test_brush_split_validator_docs.py`
- **Mock Data**: Mock documentation scenarios
- **Coverage**: >90% for all documentation functionality
```

## 🧠 Critical Analysis

### Plan Structure Assessment

This TDD implementation plan follows a logical progression from core data infrastructure to user interface features, ensuring each step builds upon the previous one. The plan is structured to minimize dependencies and maximize testability.

**Strengths:**
- Clear separation of concerns between backend and frontend
- Logical progression from data models to UI features
- Comprehensive testing strategy at each step with specific test type requirements
- Performance considerations built into the plan
- Integration with existing components and patterns
- Proper test file structure and naming conventions
- Mock data specifications for realistic testing

**Risk Mitigation:**
- Early data model definition prevents downstream issues
- Backend-first approach ensures API stability
- Incremental UI development allows for early feedback
- Performance testing integrated throughout the plan
- Error handling addressed early in the process
- Comprehensive test coverage prevents regressions

### Prompt Quality Analysis

Each prompt is designed to be:
- **Self-contained**: Includes all necessary context and requirements
- **Testable**: Clear test requirements with specific test types and file locations
- **Incremental**: Builds logically on previous steps
- **Focused**: Addresses specific functionality without scope creep
- **Actionable**: Provides clear implementation guidance
- **Test-Driven**: Includes comprehensive testing requirements following the priority hierarchy

### Implementation Safety

The plan ensures:
- No orphaned code through logical dependency chain
- Comprehensive testing at each step with >90% coverage
- Performance considerations throughout
- Error handling from the beginning
- Integration with existing patterns and components
- Proper test file structure and naming conventions
- Realistic mock data following SOTD domain patterns

### Buildability Assessment

The plan is designed to be:
- **Lean**: Each step is appropriately sized for implementation
- **Safe**: Comprehensive testing prevents regressions
- **Buildable**: Clear dependencies and logical progression
- **Maintainable**: Follows established patterns and conventions
- **Testable**: Includes specific test requirements for each step

This plan provides a solid foundation for implementing the Brush Split Validator using TDD methodology while ensuring high quality, performance, and maintainability with comprehensive testing coverage.

---

*This implementation plan follows the TDD Project Planning template and is ready for systematic execution using the Tracked Implementation Development Process.*
description:
globs:
alwaysApply: false
---

## Session Notes

### 2025-07-20: Data Analysis and Optimization Decision

**Data Analysis Findings:**
- **Actual Dataset Sizes**: ~2,500-3,000 records per month (not 1000+ as assumed)
- **File Sizes**: 2-15MB per month (very manageable)
- **Total Dataset**: ~100 months = ~250,000 total brush records
- **Performance Reality**: Sequential processing is faster than parallel (61% slower with parallelization)

**Key Decisions:**
1. **Removed DataProcessingPipeline**: Premature optimization for non-existent problem
2. **Updated Step 7**: Focus on actual needs (error handling, progress indicators)
3. **Leverage Existing Performance**: Sequential processing at ~1,064 records/sec is already excellent
4. **Focus on Real Problems**: Virtualized table foundation and error handling

**Lessons Applied:**
- Follow project's performance lessons: "Sequential processing remains fastest"
- Avoid premature optimization: "Record-level parallelization doesn't help"
- Use data-driven decisions: Actual dataset analysis revealed over-engineering

**Next Steps:**
- Proceed with Step 8 (Error Handling) and Step 10 (Virtualized Table Foundation)
- Keep simple, efficient approach that's already working
- Focus on user experience improvements rather than performance optimization

### 2025-07-20: Error Handling Correction

**Issue Identified:**
- Initial implementation used "graceful degradation" which masked internal errors
- This violated the project's "fail fast for internal errors" philosophy
- Error masking could hide important issues during development

**Correction Applied:**
- **Removed graceful degradation** for internal errors (validated splits loading)
- **Fail fast** for internal errors with clear error messages
- **Fail fast** if no months can be loaded (partial failures still allowed for external issues)
- **Fail fast** for validation errors instead of collecting them
- **Proper error categorization**: User errors (400) vs system errors (500)

**Philosophy Alignment:**
- Follow project's error handling rules: "Fail fast for internal errors"
- "Handle external failures gracefully" - only applies to external issues (missing files, network)
- Internal logic errors should fail immediately with clear stack traces
- No masking of errors that could indicate bugs or data corruption

**Result:**
- Better debugging experience during development
- Clearer error messages for users
- Proper separation of user errors vs system errors
- Maintains retry logic for external failures while failing fast for internal issues

### 2025-07-20: Step 10 Virtualized Table Foundation Complete

**Implementation Summary:**
- ✅ Created `BrushSplitTable.tsx` component with react-window virtualization
- ✅ Implemented sortable columns with visual indicators (↑/↓)
- ✅ Added row selection with checkboxes and select-all functionality
- ✅ Integrated with existing design system (Tailwind CSS)
- ✅ Added comprehensive test suite following testing patterns
- ✅ Proper TypeScript types and error handling
- ✅ Realistic test data following SOTD domain patterns
- ✅ Performance optimized for large datasets

**Testing Patterns Applied:**
- ✅ Followed test priority hierarchy (unit tests first)
- ✅ Used proper mocking patterns for react-window
- ✅ Implemented realistic test data mirroring SOTD domain
- ✅ Added comprehensive edge case testing
- ✅ Used React Testing Library best practices with userEvent
- ✅ Wrapped state updates in `act()` to prevent warnings
- ✅ Used flexible text matching for multi-element content
- ✅ All 19 tests passing with comprehensive coverage

**Key Technical Decisions:**
- Used react-window for virtualization (already installed)
- Implemented proper TypeScript interfaces for brush split data
- Added comprehensive error handling and null value support
- Used Tailwind CSS for consistent styling
- Followed existing component patterns and naming conventions

**Next Steps:**
- Ready to proceed with Step 11: Inline Editing
- Virtualized table foundation provides solid base for advanced features
- All tests passing and following established patterns

### 2025-07-20: Testing Patterns Alignment Update

**Updates Made:**
- ✅ Enhanced all steps with specific test type requirements (Unit/Integration/E2E)
- ✅ Added test file locations and naming conventions
- ✅ Specified mock data requirements for unit tests
- ✅ Added integration test data requirements for real data validation
- ✅ Included test coverage percentages (>90% for all functionality)
- ✅ Added specific test function names and scenarios
- ✅ Specified React Testing Library patterns for UI components
- ✅ Added API integration test requirements with Jest mocks
- ✅ Included performance test requirements for large datasets
- ✅ Added accessibility test requirements where applicable

**Testing Patterns Applied:**
- ✅ **Test Priority Hierarchy**: Unit tests (highest) → Integration tests (medium) → E2E tests (lowest)
- ✅ **Test File Structure**: Proper naming and location conventions
- ✅ **Mock Data Realism**: Following SOTD domain patterns
- ✅ **Comprehensive Coverage**: >90% coverage requirements
- ✅ **React Testing Library**: Proper patterns for UI component testing
- ✅ **API Testing**: Backend API tests with FastAPI TestClient
- ✅ **Integration Testing**: Real data validation requirements

**Key Improvements:**
- **Step 7**: Added specific unit and integration test requirements for data processing
- **Steps 11-16**: Enhanced with detailed React component testing requirements
- **All Steps**: Added test file locations and mock data specifications
- **Performance**: Added performance test requirements for large datasets
- **Accessibility**: Added accessibility test requirements for UI components

**Result:**
- Plan now fully aligns with testing patterns and principles
- Clear test requirements for each step with proper hierarchy
- Specific test file locations and naming conventions
- Realistic mock data requirements following SOTD patterns
- Comprehensive coverage requirements (>90%) for all functionality
