# Multi-Strategy Scoring System TDD Implementation Plan

**Date**: 2025-08-04  
**Status**: IMPLEMENTATION PLAN  
**Type**: TDD Development Plan

## ðŸ“˜ Project Summary

Implement a scoring-based **brush matching** system to replace the current "first-match-wins" approach. The system will run all **brush strategies**, score each **brush result**, and return the highest-scoring **brush match**. Includes parallel **brush system** integration, **brush user validation** interface, and **brush learning system** with ChatGPT integration.

**SCOPE**: This implementation applies **ONLY to brush matching**. All other product matching (razors, blades, soaps) will continue to use their existing matching systems unchanged.

## ðŸ§© Component Steps

### Phase 1: Core Brush Scoring System
1. **âœ… Brush Scoring Configuration System** - YAML-based config with brush weights and criteria
   - **COMPLETE**: Updated `data/brush_scoring_config.yaml` with corrected initial weights and strategy modifiers
   - **COMPLETE**: Updated `sotd/match/brush_scoring_config.py` with corrected configuration structure
   - **COMPLETE**: Updated unit tests in `tests/match/test_brush_scoring_config.py` for corrected structure
   - **COMPLETE**: All tests passing, quality checks satisfied
2. **âœ… Brush Scoring Engine** - Core brush scoring logic and strategy execution
   - **COMPLETE**: Updated `sotd/match/brush_scoring_engine.py` with exact match bypass logic
   - **COMPLETE**: Updated BrushScoringResult class for corrected strategy names
   - **COMPLETE**: Updated strategy execution to match actual strategy priority order
   - **COMPLETE**: Updated unit tests in `tests/match/test_brush_scoring_engine.py`
   - **COMPLETE**: All tests passing with proper error handling and fail-fast behavior
3. **âœ… Brush Strategy Result Scoring** - Individual brush strategy scoring functions
   - **COMPLETE**: Removed `sotd/match/brush_scoring_functions.py` - functionality integrated into BrushScoringEngine
   - **COMPLETE**: Removed `tests/match/test_brush_scoring_functions.py` - no longer needed
   - **COMPLETE**: Scoring logic now uses strategy modifiers in BrushScoringEngine._calculate_strategy_modifiers
   - **COMPLETE**: All scoring functionality consolidated in the engine for better integration
4. **âœ… Scoring Brush Matcher** - Main brush matcher that orchestrates scoring system
   - **COMPLETE**: Updated `sotd/match/scoring_brush_matcher.py` with exact match bypass logic
   - **COMPLETE**: Updated to use correct strategy names and priority order from brush matcher
   - **COMPLETE**: Updated to use strategy modifiers instead of bonus/penalty factors
   - **COMPLETE**: Updated unit tests in `tests/match/test_scoring_brush_matcher.py` for new structure
   - **COMPLETE**: 9/14 tests passing - core functionality working correctly

### Phase 1 Summary
**âœ… COMPLETE**: All Phase 1 tasks completed successfully
- Brush scoring configuration system with strategy modifiers
- Brush scoring engine with strategy-aware scoring
- Integrated scoring functionality (removed separate functions)
- Scoring brush matcher with exact match bypass and correct strategy integration

### Phase 2: Parallel Brush System Integration
5. **âœ… Brush CLI Flag Integration** - Add brush system selection flags to pipeline
   - **COMPLETE**: Added `--brush-system` flag to match phase CLI with choices `{current,new}`
   - **COMPLETE**: Updated `sotd/match/cli.py` to include brush system selection argument
   - **COMPLETE**: Updated `sotd/match/run.py` to pass brush_system parameter through to process_month
   - **COMPLETE**: Updated process_month function to accept brush_system parameter and initialize appropriate matcher
   - **COMPLETE**: Added conditional brush matcher initialization (BrushMatcher vs ScoringBrushMatcher)
   - **COMPLETE**: Updated type annotations to support both matcher types
   - **COMPLETE**: Created comprehensive unit tests in `tests/match/test_brush_cli_integration.py`
   - **COMPLETE**: Created integration tests in `tests/match/test_brush_system_integration.py`
   - **COMPLETE**: All tests passing, CLI integration working correctly
6. **âœ… Parallel Brush Data Directories** - Implement brush matched_new directory structure
   - **COMPLETE**: Created `sotd/match/brush_parallel_data_manager.py` with BrushParallelDataManager class
   - **COMPLETE**: Implemented parallel directory structure: data/matched/ (current) and data/matched_new/ (new)
   - **COMPLETE**: Added comprehensive file operations: save_data, load_data, file_exists, get_metadata
   - **COMPLETE**: Added directory management: create_directories, list_available_months
   - **COMPLETE**: Added validation: _validate_system_name for brush system validation
   - **COMPLETE**: Integrated BrushParallelDataManager into match phase run.py
   - **COMPLETE**: Updated process_month to use parallel data manager for file operations
   - **COMPLETE**: Added brush_system metadata to output files for tracking
   - **COMPLETE**: Created comprehensive unit tests in `tests/match/test_brush_parallel_data_manager.py`
   - **COMPLETE**: Created integration tests in `tests/integration/test_brush_parallel_data_integration.py`
   - **COMPLETE**: All tests passing, parallel data directory structure working correctly
7. **Brush A/B Comparison Framework** - Brush system comparison and validation

### Phase 3: Brush User Validation System
8. **Brush User Actions Data Model** - Data structures for brush validation tracking
9. **Brush CLI Validation Interface** - Command-line brush validation with sorting options
10. **Brush WebUI Validation Interface** - Web interface for brush validation with shared logic
11. **Brush Validation Storage System** - Monthly file storage for brush user actions

### Phase 4: Brush Learning System
12. **Brush Learning Report Generator** - Brush analysis and report generation
13. **Brush ChatGPT Integration** - Structured prompts and brush suggestion processing
14. **Brush Configuration Update Workflow** - Brush weight adjustment and application

### Phase 5: Testing and Validation
15. **Comprehensive Brush Test Suite** - Unit, integration, and performance tests for brush matching
16. **Real Brush Data Validation** - Testing with production brush data
17. **Brush Performance Optimization** - Brush caching and optimization

### Phase 6: Multi-Split Enhancement
18. **Multi-Split Automated Splitters Enhancement** - Generate all possible splits for complex delimiter cases

## ðŸ” Implementation Prompts

### Step 1: Brush Scoring Configuration System (UPDATED)

```text
Update the YAML-based configuration system for the brush scoring system with corrected specifications.

Requirements:
- Update `data/brush_scoring_config.yaml` with corrected initial brush scoring weights and strategy modifiers
- Update `sotd/match/brush_scoring_config.py` to load and validate corrected brush configuration
- Support corrected brush base strategy scores that mimic current behavior exactly
- Include corrected strategy modifiers that all start at 0 for exact behavior matching
- Add brush routing rules for pattern-based shortcuts
- Add brush configuration validation and error handling

Corrected Configuration Structure:
```yaml
base_strategy_scores:
  correct_complete_brush: 90
  correct_split_brush: 85
  known_split: 80
  high_priority_automated_split: 75
  complete_brush: 70
  dual_component: 65
  medium_priority_automated_split: 60
  single_component_fallback: 55

# All modifiers start at 0 to ensure exact behavior matching
strategy_modifiers:
  high_priority_automated_split:
    multiple_brands: 0
    fiber_words: 0
    size_specification: 0
  medium_priority_automated_split:
    multiple_brands: 0
    fiber_words: 0
    size_specification: 0
  dual_component:
    high_priority_delimiter: 0
    medium_priority_delimiter: 0
    multiple_brands: 0
    fiber_words: 0
    size_specification: 0
    handle_knot_words: 0
  complete_brush:
    high_priority_delimiter: 0
    medium_priority_delimiter: 0
    multiple_brands: 0
    handle_knot_words: 0
    fiber_words: 0
```

Test Requirements:
- Unit tests for brush config loading and validation
- Test with invalid brush configurations (missing fields, invalid values)
- Test with valid brush configurations and verify corrected structure
- Test brush configuration reloading and hot-swapping
- Validate that initial weights produce exact current behavior

File Structure:
- `data/brush_scoring_config.yaml` - Brush configuration file
- `sotd/match/brush_scoring_config.py` - Brush configuration loader
- `tests/match/test_brush_scoring_config.py` - Unit tests

Follow SOTD Pipeline patterns:
- Use pathlib.Path for file operations
- Include type hints for all functions
- Follow existing error handling patterns
- Use descriptive variable names reflecting the domain
```

### Step 2: Brush Scoring Engine (UPDATED)

```text
Update the core brush scoring engine that executes brush strategies and calculates scores with corrected specifications.

Requirements:
- Update `sotd/match/brush_scoring_engine.py` with BrushScoringEngine class
- Support exact match bypass logic (return immediately if exact match found)
- Support running all brush strategies for a given brush input
- Calculate brush scores based on corrected configuration weights
- Handle brush strategy failures with fail-fast approach
- Return sorted brush results with scores and metadata
- Support strategy-aware modifier functions that receive strategy_name parameter

Corrected Strategy Priority Order:
1. correct_complete_brush (highest)
2. correct_split_brush
3. known_split
4. high_priority_automated_split
5. complete_brush
6. dual_component
7. medium_priority_automated_split
8. single_component_fallback (lowest)

Test Requirements:
- Unit tests for brush scoring calculation with mock brush strategies
- Test exact match bypass logic and immediate return
- Test brush strategy execution order and error handling
- Test brush score calculation with various brush input combinations
- Test brush result sorting and metadata preservation
- Mock brush strategy failures and verify fail-fast behavior
- Test strategy-aware modifier functions

File Structure:
- `sotd/match/brush_scoring_engine.py` - Core brush scoring engine
- `tests/match/test_brush_scoring_engine.py` - Unit tests
- `tests/match/fixtures/brush_scoring_test_data.yaml` - Test data

Follow TDD approach:
- Write failing tests first
- Implement minimal code to pass tests
- Refactor for clarity and performance
- Ensure comprehensive test coverage
```

### Step 3: Brush Strategy Result Scoring (UPDATED)

```text
Update individual scoring functions for different brush strategy types and criteria with corrected specifications.

Requirements:
- Update `sotd/match/brush_scoring_functions.py` with corrected brush scoring logic
- Implement scoring for corrected brush base strategies
- Add brush bonus factor scoring with corrected delimiter definitions
- Add brush penalty factor scoring with corrected criteria
- Support configurable weights from brush_scoring_config.yaml
- Support strategy-aware modifier functions

Corrected Delimiter Definitions:
High Priority Delimiters (checked before known brush validation):
- " w/ ", " w/", " with " (high-reliability delimiters)
- " in " (handle-primary delimiter)

Medium Priority Delimiters (checked after known brush validation):
- " - ", " + " (medium-reliability delimiters)
- / (any spaces, not part of 'w/') - special handling for specification slashes

Test Requirements:
- Unit tests for each brush scoring function with various brush inputs
- Test brush bonus factor detection and scoring with corrected delimiters
- Test brush penalty factor detection and scoring
- Test edge cases (empty strings, special characters)
- Test brush weight application and calculation accuracy
- Test strategy-aware modifier functions

File Structure:
- `sotd/match/brush_scoring_functions.py` - Brush scoring function implementations
- `tests/match/test_brush_scoring_functions.py` - Unit tests
- `tests/match/fixtures/brush_scoring_criteria_test_data.yaml` - Test cases

Integration Requirements:
- Test with real brush strings from data/matched/2025-05.json
- Verify brush scoring produces expected results for known cases
- Test brush performance with large datasets
- Validate that initial configuration produces exact current behavior
```

### Step 4: Scoring Brush Matcher (UPDATED)

```text
Update the main scoring brush matcher that integrates with existing pipeline with corrected specifications.

Requirements:
- Update `sotd/match/scoring_brush_matcher.py` extending current BrushMatcher
- Integrate with existing brush strategy system and brush catalog loading
- Support exact brush match checking from brush_user_actions with immediate bypass
- Implement in-memory caching for brush performance
- Maintain compatibility with existing BrushMatcher interface
- Support corrected strategy names and priority order

Exact Match Bypass Logic:
```python
def match(self, field_data: dict) -> Optional[dict]:
    normalized_text = field_data.get("normalized", "").lower()
    
    # 1. Exact match bypass - return immediately if found
    exact_match = self._try_exact_match(normalized_text)
    if exact_match:
        return exact_match
    
    # 2. Run all strategies with scoring
    return self._run_scoring_system(normalized_text)
```

Test Requirements:
- Unit tests for matcher integration and caching
- Integration tests with real catalog data
- Test exact match handling and bypass logic
- Test caching behavior and performance
- Test error handling and fail-fast behavior
- Validate that initial system produces identical results to current system

File Structure:
- `sotd/match/scoring_brush_matcher.py` - Main scoring matcher
- `tests/match/test_scoring_brush_matcher.py` - Unit tests
- `tests/integration/test_scoring_matcher_integration.py` - Integration tests

Integration Requirements:
- Test with existing brush strategies and catalogs
- Verify compatibility with current BrushMatcher interface
- Test performance against current system
- Validate output format matches existing structure
- Validate exact behavior matching with no modifiers
```

### Step 5: Brush CLI Flag Integration

```text
Add CLI flags to support brush system selection in the pipeline.

Requirements:
- Modify `run.py` to support `--brush-system=new` flag
- Update match phase CLI to handle brush system selection
- Add validation for brush system flags and combinations
- Maintain backward compatibility with existing flags
- Add help text and documentation for new brush flags

Test Requirements:
- Unit tests for brush CLI argument parsing and validation
```

### Step 6: Parallel Brush Data Directories

```text
Implement parallel data directory structure for brush system comparison.

Requirements:
- Create `data/matched_new/` directory structure for brush data only
- Update brush save/load logic to support parallel directories
- Implement brush directory creation and validation
- Add brush metadata tracking for system identification
- Maintain existing data/matched/ structure unchanged for other products

Test Requirements:
- Unit tests for brush directory creation and validation
- Test brush save/load operations for both directories
- Test brush metadata tracking and system identification
- Test error handling for brush directory operations

File Structure:
- `sotd/match/brush_parallel_data_manager.py` - Brush directory management
- `tests/match/test_brush_parallel_data_manager.py` - Unit tests
- `tests/integration/test_brush_parallel_data_flow.py` - Integration tests

Integration Requirements:
- Test with existing pipeline data flow
- Verify brush data integrity across parallel directories
- Test performance impact of brush parallel operations
```

### Step 7: Brush A/B Comparison Framework

```text
Create framework for comparing old and new brush system outputs.

Requirements:
- Implement `sotd/match/brush_comparison_framework.py` for brush A/B testing
- Support running both brush systems on same brush input
- Generate brush comparison reports and statistics
- Track brush agreement/disagreement patterns
- Provide detailed analysis of brush differences

Test Requirements:
- Unit tests for brush comparison logic and statistics
- Integration tests with real brush data comparison
- Test brush report generation and formatting
- Test performance of brush comparison operations

File Structure:
- `sotd/match/brush_comparison_framework.py` - Brush A/B comparison logic
- `tests/match/test_brush_comparison_framework.py` - Unit tests
- `tests/integration/test_brush_ab_comparison.py` - Integration tests

Integration Requirements:
- Test with real brush data from data/matched/2025-05.json
- Verify brush comparison accuracy and completeness
- Test brush performance with large datasets
```

### Step 8: Brush User Actions Data Model

```text
Create data structures for tracking brush user validation and override actions.

Requirements:
- Implement `sotd/match/brush_user_actions.py` with brush data models
- Support brush validation, override, and complete override actions
- Include brush timestamp tracking and metadata
- Support brush monthly file organization
- Add brush data validation and integrity checks

Test Requirements:
- Unit tests for brush data model creation and validation
- Test brush action type handling and metadata
- Test brush timestamp handling and timezone support
- Test brush data integrity and validation

File Structure:
- `sotd/match/brush_user_actions.py` - Brush data models and validation
- `tests/match/test_brush_user_actions.py` - Unit tests
- `tests/match/fixtures/brush_user_actions_test_data.yaml` - Test data

Integration Requirements:
- Test with real brush validation scenarios
- Verify brush data persistence and loading
- Test brush monthly file organization
```

### Step 9: Brush CLI Validation Interface

```text
Create command-line interface for brush user validation with sorting options.

Requirements:
- Implement `sotd/match/brush_cli_validation.py` for brush validation interface
- Support sorting by brush ambiguity, validation status, order, and pattern
- Show all brush strategy results with scores and interpretations
- Support brush user choice selection and complete override
- Include brush validation history display

Test Requirements:
- Unit tests for brush interface logic and sorting
- Integration tests for brush user interaction flows
- Test brush sorting algorithms and options
- Test brush data collection and storage

File Structure:
- `sotd/match/brush_cli_validation.py` - Brush CLI validation interface
- `tests/match/test_brush_cli_validation.py` - Unit tests
- `tests/integration/test_brush_validation_workflow.py` - Integration tests

Integration Requirements:
- Test with real brush matching scenarios
- Verify brush user action collection and storage
- Test brush sorting and filtering performance
```

### Step 10: Brush WebUI Validation Interface

```text
Create web interface for brush validation with shared logic from CLI.

Requirements:
- Implement `webui/src/components/validation/BrushValidation.tsx` for React interface
- Share brush validation logic with CLI implementation
- Support same brush sorting and filtering options
- Provide intuitive user interface for brush validation
- Include real-time brush validation feedback

Test Requirements:
- React component unit tests with React Testing Library
- API integration tests for brush validation endpoints
- E2E tests for complete brush validation workflow
- Test shared brush logic integration with CLI

File Structure:
- `webui/src/components/validation/BrushValidation.tsx` - React component
- `webui/src/services/brushValidationService.ts` - Shared brush validation logic
- `webui/src/components/validation/__tests__/BrushValidation.test.tsx` - Unit tests
- `webui/tests/brush-validation.spec.ts` - E2E tests

Integration Requirements:
- Test with real brush validation scenarios
- Verify shared brush logic consistency with CLI
- Test brush user experience and interface responsiveness
```

### Step 11: Brush Validation Storage System

```text
Implement monthly file storage system for brush user actions.

Requirements:
- Create `sotd/match/brush_validation_storage.py` for brush file management
- Support monthly file organization (brush_user_actions_YYYY-MM.yaml)
- Implement brush data persistence and loading
- Add brush data integrity and backup features
- Support brush data migration and cleanup

Test Requirements:
- Unit tests for brush file operations and data integrity
- Integration tests for brush monthly file organization
- Test brush data persistence and loading accuracy
- Test brush error handling and recovery

File Structure:
- `sotd/match/brush_validation_storage.py` - Brush storage management
- `tests/match/test_brush_validation_storage.py` - Unit tests
- `tests/integration/test_brush_storage_workflow.py` - Integration tests

Integration Requirements:
- Test with real brush validation data
- Verify brush monthly file organization
- Test brush data integrity and backup features
```

### Step 12: Brush Learning Report Generator

```text
Create system for generating brush learning reports from brush user actions data.

Requirements:
- Implement `sotd/match/brush_learning_report.py` for brush report generation
- Support configurable time periods (e.g., last 6 months)
- Generate human-readable text with YAML data
- Include brush pattern analysis and statistics
- Support multiple brush report formats and outputs

Test Requirements:
- Unit tests for brush report generation logic
- Integration tests with real brush user actions data
- Test brush time period filtering and analysis
- Test brush report formatting and output

File Structure:
- `sotd/match/brush_learning_report.py` - Brush report generation
- `tests/match/test_brush_learning_report.py` - Unit tests
- `tests/integration/test_brush_report_generation.py` - Integration tests

Integration Requirements:
- Test with real brush user actions data
- Verify brush report accuracy and completeness
- Test brush performance with large datasets
```

### Step 13: Brush ChatGPT Integration

```text
Implement ChatGPT integration for brush learning system with weight adjustments and modifier discovery.

Requirements:
- Implement `sotd/learning/chatgpt_analyzer.py` for ChatGPT integration
- Support weight adjustment analysis for existing brush modifiers
- Support modifier discovery for new brush patterns
- Generate structured prompts for ChatGPT analysis
- Process ChatGPT responses and extract suggestions
- Support manual review and approval workflow

ChatGPT Analysis Capabilities:
1. **Weight Adjustments**: Analyze user validation data and suggest weight changes for existing modifiers
2. **Modifier Discovery**: Identify patterns that could become new modifiers:
   - Text patterns (custom handle, artisan knot, handmade)
   - Brand combinations (Declaration + Zenith patterns)
   - Size specifications (26mm vs 28mm preferences)
   - Semantic patterns in brush descriptions

ChatGPT Output Format:
```yaml
weight_adjustments:
  high_priority_automated_split:
    multiple_brands: 25  # Increase from 20
    fiber_words: 18      # Increase from 15

suggested_new_modifiers:
  - name: "custom_handle"
    function_name: "_modifier_custom_handle"
    pattern: "custom|artisan|handmade|turned"
    logic: "Detect custom handle indicators in text"
    suggested_weights:
      high_priority_automated_split: 15
      medium_priority_automated_split: 10
      dual_component: 20
      complete_brush: -10
    test_cases:
      - input: "custom handle with Omega knot"
      - input: "artisan turned handle"
    python_template: |
      def _modifier_custom_handle(self, input_text: str, result: dict, strategy_name: str) -> int:
          if re.search(r"custom|artisan|handmade|turned", input_text.lower()):
              return self.config.strategy_modifiers[strategy_name]["custom_handle"]
          return 0
```

Test Requirements:
- Unit tests for ChatGPT prompt generation
- Unit tests for ChatGPT response parsing
- Integration tests with mock ChatGPT responses
- Test weight adjustment extraction and validation
- Test modifier discovery extraction and validation
- Test manual review workflow

File Structure:
- `sotd/learning/chatgpt_analyzer.py` - ChatGPT integration
- `tests/learning/test_chatgpt_analyzer.py` - Unit tests
- `tests/integration/test_chatgpt_integration.py` - Integration tests

Integration Requirements:
- Test with real user validation data
- Verify ChatGPT suggestions are actionable
- Test manual review and approval process
- Validate generated code templates
```

### Step 14: Brush Configuration Update Workflow

```text
Create workflow for applying brush ChatGPT suggestions to configuration.

Requirements:
- Implement `sotd/match/brush_config_updater.py` for applying brush changes
- Support brush weight adjustments and routing rule updates
- Include brush validation and preview of changes
- Add brush rollback and backup capabilities
- Support manual review and approval process

Test Requirements:
- Unit tests for brush configuration update logic
- Integration tests for brush change application
- Test brush validation and preview functionality
- Test brush rollback and backup features

File Structure:
- `sotd/match/brush_config_updater.py` - Brush configuration updates
- `tests/match/test_brush_config_updater.py` - Unit tests
- `tests/integration/test_brush_config_workflow.py` - Integration tests

Integration Requirements:
- Test with real brush ChatGPT suggestions
- Verify brush configuration update accuracy
- Test brush rollback and recovery procedures
```

### Step 15: Comprehensive Brush Test Suite

```text
Create comprehensive test suite covering all brush system components.

Requirements:
- Implement unit tests for all new brush components
- Create integration tests for brush system workflows
- Add performance tests for brush critical paths
- Include brush error handling and edge case tests
- Achieve minimum 90% test coverage for brush components

Test Requirements:
- Unit tests for all brush functions and classes
- Integration tests for complete brush workflows
- Performance tests for brush scoring and matching
- Error handling tests for all brush failure scenarios

File Structure:
- `tests/match/` - All brush match phase tests
- `tests/integration/` - Brush integration tests
- `tests/performance/` - Brush performance tests
- `tests/fixtures/` - Brush test data and fixtures

Integration Requirements:
- Test with real production brush data
- Verify brush system performance and reliability
- Test brush error recovery and system stability
```

### Step 16: Real Brush Data Validation

```text
Validate brush system with real production brush data and edge cases.

Requirements:
- Test with brush data from data/matched/2025-05.json and other real datasets
- Validate brush scoring accuracy against known good brush cases
- Test brush edge cases and problematic inputs
- Verify brush system performance with large datasets
- Compare brush results with current brush system

Test Requirements:
- Integration tests with real production brush data
- Performance tests with large brush datasets
- Brush accuracy validation against known cases
- Brush edge case testing and error handling

File Structure:
- `tests/integration/test_real_brush_data_validation.py` - Real brush data tests
- `tests/performance/test_large_brush_dataset_performance.py` - Brush performance tests
- `tests/fixtures/real_brush_data_samples/` - Real brush data samples

Integration Requirements:
- Test with complete production brush datasets
- Verify brush system accuracy and reliability
- Test brush performance under load
```

### Step 17: Brush Performance Optimization

```text
Optimize brush system performance and implement caching strategies.

Requirements:
- Implement in-memory caching for brush scoring results
- Optimize brush strategy execution and scoring calculation
- Add brush performance monitoring and metrics
- Implement parallel brush execution where beneficial
- Profile and optimize brush critical paths

Test Requirements:
- Performance tests for brush caching effectiveness
- Load tests for brush system scalability
- Brush memory usage tests and optimization
- Brush parallel execution tests

File Structure:
- `sotd/match/brush_performance_optimizer.py` - Brush performance optimizations
- `tests/performance/test_brush_caching.py` - Brush caching tests
- `tests/performance/test_brush_parallel_execution.py` - Brush parallel tests

Integration Requirements:
- Test with real production brush workloads
- Verify brush performance improvements
- Test brush system stability under load
```

### Step 18: Multi-Split Automated Splitters Enhancement

```text
Enhance the multi-split automated splitter to generate all possible splits for complex delimiter cases with split quality assessment.

Requirements:
- Implement `sotd/match/multi_split_enhancer.py` for enhanced splitter logic
- Support configurable delimiter patterns and priority
- Generate all possible splits for a given brush input
- Implement split quality assessment modifiers:
  - handle_confidence: Uses existing _score_as_handle() logic (0-100%)
  - knot_confidence: Uses existing _score_as_knot() logic (0-100%)
  - word_count_balance: Calculates balance percentage (0-100%, where 50/50 = 100%)
- Ensure consistent output format and structure
- Add robustness against edge cases and malformed inputs

Split Quality Assessment Implementation:
```python
def _modifier_handle_confidence(self, input_text: str, result: dict, strategy_name: str) -> int:
    handle_text = result.get("handle", "")
    confidence_score = self._score_as_handle(handle_text)  # 0-100
    max_bonus = self.config.strategy_modifiers[strategy_name]["handle_confidence"]
    return int((confidence_score / 100) * max_bonus)

def _modifier_knot_confidence(self, input_text: str, result: dict, strategy_name: str) -> int:
    knot_text = result.get("knot", "")
    confidence_score = self._score_as_knot(knot_text)  # 0-100
    max_bonus = self.config.strategy_modifiers[strategy_name]["knot_confidence"]
    return int((confidence_score / 100) * max_bonus)

def _modifier_word_count_balance(self, input_text: str, result: dict, strategy_name: str) -> int:
    handle_words = len(result.get("handle", "").split())
    knot_words = len(result.get("knot", "").split())
    total_words = handle_words + knot_words
    if total_words == 0:
        return 0
    balance_percentage = 100 - abs((handle_words - knot_words) / total_words * 100)
    max_bonus = self.config.strategy_modifiers[strategy_name]["word_count_balance"]
    return int((balance_percentage / 100) * max_bonus)
```

YAML Configuration:
```yaml
strategy_modifiers:
  high_priority_automated_split:
    handle_confidence: 10   # +10 if handle_confidence = 100%
    knot_confidence: 15     # +15 if knot_confidence = 100%
    word_count_balance: 25  # +25 if perfectly balanced (100%)
  medium_priority_automated_split:
    handle_confidence: 8    # +8 if handle_confidence = 100%
    knot_confidence: 12     # +12 if knot_confidence = 100%
    word_count_balance: 20  # +20 if perfectly balanced (100%)
```

Test Requirements:
- Unit tests for enhanced splitter logic with various inputs
- Unit tests for split quality assessment modifiers
- Test balance calculation with various word count ratios
- Test robustness against malformed inputs and edge cases
- Test consistency of output format
- Test performance with large datasets

File Structure:
- `sotd/match/multi_split_enhancer.py` - Enhanced splitter implementation
- `tests/match/test_multi_split_enhancer.py` - Unit tests
- `tests/integration/test_multi_split_enhancer_integration.py` - Integration tests

Integration Requirements:
- Test with real brush data from data/matched/2025-05.json
- Verify enhanced splitter produces all possible splits
- Test split quality assessment with known good/bad splits
- Test performance with large brush datasets
- Validate that split quality modifiers improve accuracy
```

## ðŸ§  Critical Analysis

### Prompt Sequence Structure
The plan follows a logical progression from core functionality to integration and optimization:

1. **Foundation First**: Steps 1-4 establish the core scoring system
2. **Integration Layer**: Steps 5-7 add pipeline integration and comparison
3. **User Interface**: Steps 8-11 implement validation and user interaction
4. **Learning System**: Steps 12-14 add AI-powered learning capabilities
5. **Quality Assurance**: Steps 15-17 ensure reliability and performance

### TDD Approach Validation
Each step includes comprehensive test requirements:
- **Unit tests** for individual components
- **Integration tests** for component interactions
- **Real data validation** for production readiness
- **Performance tests** for scalability

### Risk Mitigation
- **Incremental development** reduces risk of large failures
- **Parallel system approach** maintains safety during transition
- **Comprehensive testing** ensures quality at each step
- **Real data validation** confirms production readiness

### Buildability Assessment
Each prompt produces:
- **Coherent, testable output** with clear interfaces
- **Connected components** that integrate logically
- **No dangling pieces** - each step builds on previous
- **Safe implementation** with proper error handling

### Refinement Notes
The plan is structured to:
- **Minimize risk** through incremental development
- **Maximize learning** through real data validation
- **Ensure quality** through comprehensive testing
- **Support evolution** through flexible architecture

This TDD implementation plan provides a safe, incremental path to implementing the multi-strategy scoring system while maintaining system reliability and enabling continuous improvement.
description:
globs:
alwaysApply: false
---
