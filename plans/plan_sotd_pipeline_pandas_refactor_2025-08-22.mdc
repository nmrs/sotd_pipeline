# SOTD Pipeline Pandas Refactor Plan

**Generated**: 2025-08-22  
**Status**: Planning Complete  
**Priority**: After TEST_SUITE_TODO.md completion  
**Scope**: Refactor both aggregators and table generators to use pandas operations instead of manual loops

## 📘 Project Summary

Refactor the SOTD Pipeline aggregators and table generators to use pandas operations throughout the data processing pipeline instead of manual Python loops. This will eliminate anti-patterns, improve performance, and make the code more maintainable while preserving the existing functionality.

**Current State**: 
- **Aggregators**: Use pandas operations but manually convert DataFrames to lists for JSON output
- **Table Generators**: Use manual Python loops for data transformation, validation, and rank formatting, then convert to pandas DataFrames only at the final rendering step

**Target State**: 
- **Aggregators**: Use pandas operations throughout and output JSON via pandas methods
- **Table Generators**: Work entirely with pandas DataFrames, using vectorized operations for all data processing, and return DataFrames directly for rendering with `to_markdown()`

## 🧩 Component Steps

### Phase 1: Aggregator Pandas JSON Refactor
1. **Refactor aggregator JSON output** - Replace manual list conversion with pandas to_dict() methods
2. **Update aggregator type handling** - Ensure proper type casting in pandas operations
3. **Test aggregator pandas JSON output** - Verify JSON serialization works correctly

### Phase 2: Foundation and Base Classes
4. **Create pandas-based base table generator** - Refactor BaseTableGenerator to use pandas operations
5. **Implement pandas data validation** - Replace manual validation loops with pandas operations
6. **Create pandas rank formatting utilities** - Replace manual rank formatting with pandas operations

### Phase 3: Core Table Generators
7. **Refactor standard product table generators** - Convert to pandas operations
8. **Refactor specialized table generators** - Convert data transformation loops to pandas operations
9. **Refactor cross-product table generators** - Convert to pandas operations

### Phase 4: Integration and Testing
10. **Update table generation pipeline** - Ensure pandas DataFrames flow through entire system
11. **Comprehensive testing** - Verify all table types work correctly with pandas operations
12. **Performance validation** - Ensure pandas operations improve performance

### Phase 5: Pipeline Data Flow Refactor
13. **Refactor match phase data flow** - Eliminate DataFrame ↔ List conversions in record processing
14. **Refactor enrich phase data flow** - Eliminate DataFrame ↔ List conversions in batch processing
15. **Update utility function signatures** - Change functions to accept/return DataFrames instead of lists
16. **Test pipeline data flow** - Verify DataFrames flow consistently from aggregators to final rendering

## 🔁 Implementation Prompts

### Step 1: Refactor aggregator JSON output

```text
Refactor the aggregator JSON output methods in `sotd/aggregate/aggregators/base_aggregator.py` to use pandas to_dict() methods instead of manual list conversion.

Key changes needed:
1. Replace the manual loop conversion in _sort_and_rank method:
   - Current: Manual loop creating list of dicts from DataFrame rows
   - Target: Use grouped.to_dict(orient='records') for output
2. Ensure proper type casting in pandas operations before JSON conversion:
   - Convert rank column to int: grouped['raw_rank'] = grouped['raw_rank'].astype(int)
   - Convert shaves column to int: grouped['shaves'] = grouped['shaves'].astype(int)
   - Convert unique_users column to int: grouped['unique_users'] = grouped['unique_users'].astype(int)
3. Clean up the DataFrame columns before conversion:
   - Drop temporary columns like 'temp_rank'
   - Ensure only final output columns remain
   - Rename 'raw_rank' to 'rank' for consistency
4. Maintain exact same output format for backward compatibility

Test requirements:
- Unit tests ensuring identical output format
- Performance tests comparing pandas vs manual conversion
- Integration tests with existing aggregator consumers
- Edge case testing (empty DataFrames, single row, etc.)
```

### Step 2: Update aggregator type handling

```text
Update aggregator type handling in `sotd/aggregate/aggregators/base_aggregator.py` to ensure proper type casting happens in pandas operations before JSON conversion.

Requirements:
1. Update the _sort_and_rank method to handle type casting in pandas:
   - Use df.astype() for integer conversions
   - Use df.rename() for column renaming
   - Ensure all numeric columns are properly typed
2. Update the _group_and_aggregate method to ensure proper types:
   - Verify shaves and unique_users are integers after aggregation
   - Handle any floating point results from pandas operations
3. Add type validation in pandas operations:
   - Check dtypes after aggregation
   - Convert any unexpected types to expected types
   - Ensure consistent output types across all aggregators
4. Maintain backward compatibility with existing output format

Test requirements:
- Unit tests for type handling in pandas operations
- Edge case testing with various data types
- Performance tests for type conversion operations
- Integration tests ensuring output format consistency
```

### Step 3: Test aggregator pandas JSON output

```text
Create comprehensive tests for the pandas-based aggregator JSON output to ensure all functionality works correctly.

Requirements:
1. Test pandas JSON conversion methods:
   - Test to_dict(orient='records') output format
   - Verify column ordering and naming
   - Test with various DataFrame sizes and structures
2. Test type handling:
   - Verify integer types for rank, shaves, unique_users
   - Test edge cases with missing or invalid data
   - Ensure consistent output types across all aggregators
3. Test performance improvements:
   - Benchmark pandas JSON conversion vs manual loops
   - Measure memory usage differences
   - Identify any performance regressions
4. Test backward compatibility:
   - Ensure identical output format to existing system
   - Verify all existing tests still pass
   - Test integration with downstream consumers

Test requirements:
- 100% test coverage for new pandas JSON methods
- Performance regression testing
- Integration testing with existing systems
- Edge case coverage for all aggregator types
```

### Step 4: Create pandas-based base table generator

```text
Refactor the BaseTableGenerator class in `sotd/report/table_generators/base.py` to use pandas operations instead of manual Python loops.

Key changes needed:
1. Import pandas and convert input data to DataFrames in __init__
2. Replace _validate_data_records method to use pandas operations:
   - Convert list of dicts to DataFrame
   - Use df.query() for filtering invalid records
   - Use df.dtypes for type validation
   - Return DataFrame instead of list
3. Replace _format_existing_ranks_with_proper_ties method to use pandas operations:
   - Use df['rank'].apply() for rank formatting
   - Use pandas vectorized operations for tie detection
   - Return DataFrame with updated rank column
4. Update all methods that currently work with lists to work with DataFrames
5. Ensure the generate_table method returns a pandas DataFrame

Maintain backward compatibility by ensuring the public interface returns DataFrames that can be used with to_markdown().

Test requirements:
- Unit tests for pandas-based validation
- Unit tests for pandas-based rank formatting
- Integration tests ensuring DataFrames flow correctly
- Performance tests comparing pandas vs manual loop performance
```

### Step 5: Implement pandas data validation

```text
Create a new pandas-based data validation system in `sotd/report/table_generators/base.py` to replace the manual validation loops.

Requirements:
1. Create a new method _validate_data_records_pandas that:
   - Takes a DataFrame as input
   - Uses df.query() for field presence validation
   - Uses df.dtypes for type validation
   - Uses df.loc[] for conditional filtering
   - Returns a validated DataFrame
2. Replace the existing _validate_data_records method to call the pandas version
3. Update validation logic to use pandas operations:
   - Field presence: df.query('field_name.notna()')
   - Type validation: df.select_dtypes(include=['int64', 'float64'])  # Numeric types
   - Range validation: df.query('shaves > 0')
4. Ensure validation preserves DataFrame structure and metadata

Test requirements:
- Unit tests for pandas validation methods
- Edge case testing (empty DataFrames, missing columns, invalid types)
- Performance comparison with manual validation
- Integration tests with existing table generators
```

### Step 6: Create pandas rank formatting utilities

```text
Refactor the rank formatting methods in `sotd/report/table_generators/base.py` to use pandas operations instead of manual loops.

Requirements:
1. Replace _format_ranks_with_ties method to work with pandas Series:
   - Use df['rank'].shift() for forward/backward tie detection
   - Use df['rank'].duplicated() for tie identification
   - Use df['rank'].apply() for formatting with tie indicators
2. Replace _format_existing_ranks_with_proper_ties method:
   - Use pandas operations for rank extraction and validation
   - Use vectorized operations for tie formatting
   - Return DataFrame with updated rank column
3. Ensure tie detection logic is mathematically correct:
   - Ranks [1, 1, 3, 3, 5] should format as ["1=", "1=", "3=", "3=", "5"]
   - Use pandas groupby operations for efficient tie detection
4. Maintain existing tie formatting behavior while improving performance

Test requirements:
- Unit tests for pandas rank formatting
- Comprehensive tie scenario testing
- Performance benchmarks vs manual loop approach
- Edge case testing (single ranks, all ties, no ties)
```

### Step 7: Refactor standard product table generators

```text
Refactor the standard product table generators in `sotd/report/table_generators/` to use pandas operations for data processing.

Focus on these generators:
1. StandardProductTableGenerator
2. ManufacturerTableGenerator
3. UserTableGenerator

Requirements:
1. Convert get_table_data methods to use pandas operations:
   - Use df.query() for filtering
   - Use df.assign() for column transformations
   - Use df.sort_values() for sorting (if needed)
   - Return DataFrames instead of lists
2. Replace manual data transformation loops with pandas operations:
   - Column mapping: df.assign(new_col=df['old_col'])
   - Conditional logic: df.loc[condition, 'column'] = value
   - Aggregations: df.groupby().agg() operations
3. Ensure delta calculations work with DataFrames
4. Maintain existing functionality while improving performance

Test requirements:
- Unit tests for pandas-based data processing
- Integration tests ensuring DataFrames flow correctly
- Performance comparison with manual loop approach
- Edge case testing with various data scenarios
```

### Step 8: Refactor specialized table generators

```text
Refactor the specialized table generators in `sotd/report/table_generators/specialized_tables.py` to use pandas operations for data transformation.

Focus on these generators:
1. GameChangerPlatesTableGenerator
2. BlackbirdPlatesTableGenerator
3. ChristopherBradleyPlatesTableGenerator
4. SuperSpeedTipsTableGenerator
5. StraightWidthsTableGenerator
6. StraightGrindsTableGenerator
7. StraightPointsTableGenerator

Requirements:
1. Convert get_table_data methods to use pandas operations:
   - Replace manual loops with df.assign() for column mapping
   - Use df.query() for filtering and validation
   - Use pandas operations for data transformation
   - Return DataFrames with correct structure
2. Replace manual data transformation patterns:
   - Field mapping: df.assign(plate=df['gap'])
   - Conditional logic: df.loc[df['field'].notna()]
   - Data filtering: df.query('shaves > 0')
3. Ensure rank preservation works correctly with pandas operations
4. Maintain existing functionality while eliminating manual loops

Test requirements:
- Unit tests for each specialized generator
- Integration tests ensuring correct data transformation
- Performance benchmarks vs manual loop approach
- Edge case testing with various data scenarios
```

### Step 9: Refactor cross-product table generators

```text
Refactor the cross-product table generators in `sotd/report/table_generators/cross_product_tables.py` to use pandas operations.

Focus on these generators:
1. RazorBladeCombinationsTableGenerator
2. HighestUseCountPerBladeTableGenerator

Requirements:
1. Convert get_table_data methods to use pandas operations:
   - Replace manual loops with pandas operations
   - Use df.assign() for column transformations
   - Use df.query() for filtering
   - Return DataFrames instead of lists
2. Replace manual data processing patterns:
   - Name combination: df.assign(name=df['razor'] + ' + ' + df['blade'])
   - Aggregations: df.groupby().agg() operations
   - Sorting: df.sort_values() operations
3. Ensure rank handling works correctly with pandas operations
4. Maintain existing functionality while improving performance

Test requirements:
- Unit tests for pandas-based data processing
- Integration tests ensuring correct cross-product generation
- Performance comparison with manual loop approach
- Edge case testing with various data scenarios
```

### Step 10: Update table generation pipeline

```text
Update the table generation pipeline in `sotd/report/table_generator.py` to ensure pandas DataFrames flow correctly through the entire system.

Requirements:
1. Update TableGenerator class to handle pandas DataFrames:
   - Ensure generate_table methods return DataFrames
   - Update enhanced table integration to work with DataFrames
   - Ensure comparison data handling works with DataFrames
2. Update the enhanced table system integration:
   - Ensure EnhancedTableGenerator works with DataFrames
   - Update parameter application to work with DataFrames
   - Ensure size limiting works with DataFrames
3. Update the final table rendering:
   - Ensure to_markdown() is called on DataFrames
   - Remove any final conversions back to lists/dicts
   - Ensure markdown output is identical to current system
4. Maintain backward compatibility for external interfaces

Test requirements:
- Integration tests for complete table generation pipeline
- Performance tests for pandas-based pipeline
- Output comparison tests ensuring identical markdown
- Edge case testing with various table types and parameters
```

### Step 11: Comprehensive testing

```text
Create comprehensive test coverage for the pandas-based table generator system to ensure all functionality works correctly.

Requirements:
1. Unit tests for all pandas operations:
   - Data validation methods
   - Rank formatting methods
   - Data transformation methods
2. Integration tests for table generation:
   - Standard product tables
   - Specialized tables
   - Cross-product tables
   - Enhanced table functionality
3. Performance tests:
   - Benchmark pandas operations vs manual loops
   - Memory usage comparison
   - Execution time comparison
4. Edge case testing:
   - Empty data scenarios
   - Missing field scenarios
   - Invalid data scenarios
   - Large dataset scenarios

Test requirements:
- 100% test coverage for new pandas methods
- Performance regression testing
- Integration testing with existing systems
- Edge case coverage for all table types
```

### Step 12: Performance validation

```text
Validate that the pandas-based refactor improves performance and maintains or improves functionality.

Requirements:
1. Performance benchmarking:
   - Measure execution time for various table types
   - Compare pandas operations vs manual loops
   - Measure memory usage differences
   - Identify any performance regressions
2. Functionality validation:
   - Ensure identical output for all table types
   - Verify rank formatting is mathematically correct
   - Confirm data validation works correctly
   - Test edge cases and error scenarios
3. Memory optimization:
   - Ensure pandas operations don't create unnecessary copies
   - Optimize DataFrame operations for memory efficiency
   - Profile memory usage patterns
4. Performance tuning:
   - Identify and optimize slow pandas operations
   - Use appropriate pandas methods for performance
   - Consider chunking for very large datasets

Test requirements:
- Performance benchmarks for all table types
- Memory usage profiling
- Functionality regression testing
- Load testing with large datasets
```

### Step 13: Refactor match phase data flow

```text
Refactor the match phase data flow in `sotd/match/run.py` to eliminate DataFrame ↔ List conversions and maintain pandas DataFrames throughout processing.

Key changes needed:
1. Update the main processing loop to work with DataFrames:
   - Convert input data to DataFrame at the start
   - Use df.apply() for vectorized record processing instead of manual loops
   - Maintain DataFrame structure throughout processing
2. Update the record conversion logic:
   - Replace manual MatchResult conversion loops with vectorized operations
   - Use df.assign() for adding new columns
   - Use df.drop() for removing unwanted columns
3. Update the output structure:
   - Ensure the final output maintains DataFrame format
   - Convert to list only at the very end for JSON serialization
4. Maintain existing functionality while improving performance

Test requirements:
- Unit tests for DataFrame-based record processing
- Integration tests ensuring match phase output is identical
- Performance tests comparing DataFrame vs manual loop processing
- Edge case testing with various record types and sizes
```

### Step 14: Refactor enrich phase data flow

```text
Refactor the enrich phase data flow in `sotd/enrich/registry.py` to eliminate DataFrame ↔ List conversions and maintain pandas DataFrames throughout processing.

Key changes needed:
1. Update the enrich_records method to work with DataFrames:
   - Convert input records to DataFrame at the start
   - Use df.apply() for vectorized enrichment instead of manual loops
   - Maintain DataFrame structure throughout processing
2. Update the enrich_record method:
   - Accept DataFrame row instead of dict
   - Return DataFrame row instead of dict
   - Use pandas operations for field filtering and enrichment
3. Update field filtering logic:
   - Use df.drop() for removing match-phase-specific fields
   - Use df.assign() for adding enriched data
   - Maintain DataFrame structure
4. Ensure backward compatibility with existing enrich phase consumers

Test requirements:
- Unit tests for DataFrame-based enrichment
- Integration tests ensuring enrich phase output is identical
- Performance tests comparing DataFrame vs manual loop processing
- Edge case testing with various record types and enrichment scenarios
```

### Step 15: Update utility function signatures

```text
Update utility function signatures throughout the codebase to accept and return pandas DataFrames instead of lists, eliminating unnecessary data type conversions.

Key changes needed:
1. Update validation utility functions in `sotd/utils/validation_utils.py`:
   - Change function signatures to accept pd.DataFrame instead of list[dict]
   - Return pd.DataFrame instead of list[dict]
   - Use pandas operations for validation logic
2. Update filtered entries utility functions in `sotd/utils/filtered_entries.py`:
   - Change function signatures to accept pd.DataFrame instead of list[str]
   - Return pd.DataFrame instead of list[str]
   - Use pandas operations for filtering logic
3. Update any other utility functions that process data:
   - Ensure consistent DataFrame input/output
   - Use vectorized operations instead of manual loops
   - Maintain existing functionality while improving performance
4. Update all calling code to pass DataFrames instead of converting

Test requirements:
- Unit tests for DataFrame-based utility functions
- Integration tests ensuring utility function output is identical
- Performance tests comparing DataFrame vs list processing
- Backward compatibility testing for any external consumers
```

### Step 16: Test pipeline data flow

```text
Create comprehensive tests for the unified pandas-based pipeline data flow to ensure DataFrames flow consistently from aggregators to final rendering.

Requirements:
1. Test end-to-end data flow:
   - Verify DataFrames flow from aggregators through all phases
   - Test with various data types and sizes
   - Ensure no unnecessary DataFrame ↔ List conversions
2. Test performance improvements:
   - Benchmark unified pipeline vs current mixed approach
   - Measure memory usage improvements
   - Identify any performance regressions
3. Test functionality preservation:
   - Ensure identical output for all pipeline phases
   - Verify data integrity throughout the pipeline
   - Test edge cases and error scenarios
4. Test integration points:
   - Verify aggregator → match phase integration
   - Verify match phase → enrich phase integration
   - Verify enrich phase → table generation integration
   - Verify final rendering works correctly

Test requirements:
- End-to-end pipeline integration tests
- Performance regression testing
- Functionality regression testing
- Edge case coverage for all pipeline phases
```

## 🧠 Critical Analysis

### Prompt Sequence Structure
The plan follows a logical progression from simpler to more complex components, building toward a unified pandas-based pipeline:
1. **Phase 1: Aggregator Refactor** - Simple pandas JSON output refactor (already using pandas operations)
2. **Phase 2: Foundation** - Establishes pandas-based base classes and utilities for table generators
3. **Phase 3: Implementation** - Refactors specific table generator types to use pandas operations
4. **Phase 4: Integration & Testing** - Ensures pandas DataFrames flow through the table generation system
5. **Phase 5: Pipeline Data Flow Refactor** - Eliminates DataFrame ↔ List conversions throughout the entire pipeline

### Safety and Buildability
- **Incremental approach**: Start with simpler aggregator refactor, then build table generator foundation, finally unify entire pipeline
- **Dependency order**: Aggregators first (simpler), then table generators (more complex), then pipeline integration (most complex)
- **Backward compatibility**: Maintains existing interfaces while improving internal implementation
- **Test-first approach**: Each step includes comprehensive testing requirements
- **Performance focus**: Includes performance validation to ensure improvements

### Risk Mitigation
- **Gradual migration**: Start with aggregators (already pandas-based), then move to table generators, finally unify pipeline
- **Comprehensive testing**: Ensure no functionality is lost during refactoring
- **Performance monitoring**: Catch any performance regressions early
- **Rollback capability**: Each step can be reverted if issues arise

### Dependencies
- **TEST_SUITE_TODO.md completion**: Must finish current test suite fixes first
- **Pandas expertise**: Requires understanding of pandas best practices
- **Test infrastructure**: Comprehensive testing framework must be in place
- **Performance baseline**: Current performance metrics must be established

### Success Criteria
- **Performance improvement**: Pandas operations should be faster than manual loops throughout the pipeline
- **Code quality**: Eliminate all manual loop anti-patterns in aggregators, table generators, and pipeline phases
- **Functionality preservation**: All existing functionality works identically
- **Maintainability**: Code should be easier to read and modify
- **Test coverage**: 100% coverage for new pandas-based methods
- **Architecture consistency**: Entire pipeline uses pandas throughout with no unnecessary data type conversions
- **Pipeline unification**: DataFrames flow consistently from aggregators through all phases to final rendering

### Benefits of New Phase Order
1. **Easier start**: Aggregator refactor is simpler (already using pandas operations)
2. **Better foundation**: Cleaner aggregator output makes table generator refactor easier
3. **Incremental progress**: Can demonstrate improvements early in the process
4. **Risk reduction**: Simpler changes first, complex changes later
5. **Dependency flow**: Table generators depend on aggregator output, so clean that first
6. **Pipeline unification**: Final phase creates a unified pandas-based pipeline with maximum performance benefits

### Scope Expansion Benefits
1. **End-to-end optimization**: Eliminates DataFrame ↔ List conversions throughout the entire pipeline
2. **Memory efficiency**: No unnecessary data copying between formats
3. **Performance consistency**: Vectorized operations from start to finish
4. **Architectural clarity**: Single data type (DataFrame) throughout the pipeline
5. **Developer experience**: Consistent pandas operations across all phases

This refactor will significantly improve the codebase quality while maintaining all existing functionality and improving performance. The expanded scope creates a unified pandas-based pipeline that eliminates all manual loop anti-patterns and unnecessary data type conversions, providing maximum performance and maintainability benefits.
description:
globs:
alwaysApply: false
---
