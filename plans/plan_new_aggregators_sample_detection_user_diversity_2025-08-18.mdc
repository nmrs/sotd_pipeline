# New Aggregators for Sample Detection and User Diversity - TDD Implementation Plan

**Date**: 2025-08-18  
**Status**: IMPLEMENTATION PLAN  
**Type**: TDD Development Plan  
**Priority**: HIGH  

## üìò Project Summary

Implement 10 new aggregators to enhance the SOTD Pipeline's analytical capabilities:

**Sample Aggregators (3)**: Leverage soap sample detection enrichment data to analyze sample usage patterns
**Soap Diversity Aggregators (2)**: Track user diversity in soap usage (brands and brand+scent combinations)  
**Hardware Diversity Aggregators (3)**: Track user diversity in hardware usage (razors, blades, brushes)
**Format Usage Aggregators (2)**: Track top users for specific product formats and fiber types

**Key Benefits**:
- Enable sample usage analysis and insights
- Provide user diversity metrics for community analysis
- Follow established aggregation patterns and architecture
- Integrate seamlessly with existing pipeline phases

## üß© Component Steps

**Data Source**: All aggregators read from the relevant month file in `data/enriched/YYYY-MM.json` (e.g., `data/enriched/2025-06.json`). This ensures consistent data access across all aggregators.

### Phase 1: Sample Aggregators Foundation
1. **Remove Existing SoapSampleAggregator** - Remove the general sample aggregator from the pipeline
2. **Create SoapSampleBrandAggregator** - Most sampled brands by total sample shaves
3. **Create SoapSampleBrandScentAggregator** - Most sampled brand+scent combinations by total sample shaves  
4. **Create SoapSampleUserAggregator** - Users by total sample shaves across all soaps

**Note**: The existing SoapSampleAggregator will be removed as part of this plan since the new specialized aggregators provide more focused and useful analysis.

### Phase 2: Soap Diversity Aggregators
5. **Create SoapBrandDiversityAggregator** - Users by distinct soap brands
6. **Create SoapBrandScentDiversityAggregator** - Users by distinct brand+scent combinations

### Phase 3: Hardware Diversity Aggregators
7. **Create RazorDiversityAggregator** - Users by distinct razor brand+model combinations
8. **Create BladeDiversityAggregator** - Users by distinct blade brand+model combinations
9. **Create BrushDiversityAggregator** - Users by distinct brush combinations (brand+model+knot+handle)

### Phase 4: Format Usage Aggregators
10. **Create RazorFormatUserAggregator** - Top users for each razor format (DE, Straight, GEM, AC, etc.)
11. **Create BrushFiberUserAggregator** - Top users for each brush fiber type (badger, boar, synthetic, etc.)

### Phase 5: Integration and Testing
12. **Processor Integration** - Add all aggregators to `sotd/aggregate/processor.py`
13. **Comprehensive Testing** - Unit and integration tests for all new aggregators
14. **Documentation Updates** - Update aggregate phase documentation and specifications

## üîÅ Implementation Prompts

### Step 1: Remove Existing SoapSampleAggregator

```text
Remove the existing SoapSampleAggregator from the pipeline as it will be replaced by more specialized aggregators. This involves:

1. Remove the import of `aggregate_soap_samples` from `sotd/aggregate/processor.py`
2. Remove the call to `aggregate_soap_samples(records)` from the `aggregate_all` function
3. Update the debug count from "24 aggregators" to "23 aggregators" (temporarily)
4. Remove the aggregator from the core aggregators module exports if needed
5. Update any tests that depend on the existing soap sample aggregation

The existing SoapSampleAggregator provides 3-dimensional grouping (sample_type + maker + scent) which is less useful than the new specialized aggregators that provide:
- Brand-focused sample analysis
- Brand+scent focused sample analysis  
- User-focused sample analysis

This removal will be replaced by the new specialized aggregators in the following steps.
```

### Step 2: Create SoapSampleBrandAggregator

```text
Create a new SoapSampleBrandAggregator class in `sotd/aggregate/aggregators/core/soap_sample_brand_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract sample data from soap.enriched.sample_type (only records with sample data)
3. Group by soap.matched.brand to count total sample shaves per brand
4. Return data with position, brand, shaves (sample shaves only), and unique_users fields
5. Sort by shaves desc, unique_users desc (following existing pattern)

The aggregator should:
- Only process records where soap.enriched.sample_type exists
- Extract brand from soap.matched.brand (successful matches only)
- Count total sample shaves (not regular shaves)
- Handle cases where sample data exists but brand matching failed

Output structure should match:
```json
{
  "position": 1,
  "brand": "Declaration Grooming",
  "shaves": 15,
  "unique_users": 8
}
```

Use the same patterns as existing aggregators for data extraction, validation, and output formatting.
```

### Step 3: Create SoapSampleBrandScentAggregator

```text
Create a new SoapSampleBrandScentAggregator class in `sotd/aggregate/aggregators/core/soap_sample_brand_scent_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract sample data from soap.enriched.sample_type (only records with sample data)
3. Group by soap.matched.brand + soap.matched.scent to count total sample shaves per brand+scent combination
4. Return data with position, name (brand + scent), shaves (sample shaves only), and unique_users fields
5. Sort by shaves desc, unique_users desc (following existing pattern)

The aggregator should:
- Only process records where soap.enriched.sample_type exists
- Extract brand and scent from soap.matched (successful matches only)
- Create composite name as "Brand - Scent" format
- Count total sample shaves (not regular shaves)
- Handle cases where sample data exists but brand/scent matching failed

Output structure should match:
```json
{
  "position": 1,
  "name": "Declaration Grooming - B2",
  "shaves": 8,
  "unique_users": 5
}
```

Use the same patterns as existing aggregators for composite name creation and output formatting.
```

### Step 4: Create SoapSampleUserAggregator

```text
Create a new SoapSampleUserAggregator class in `sotd/aggregate/aggregators/users/soap_sample_user_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract sample data from soap.enriched.sample_type (only records with sample data)
3. Group by author to count total sample shaves per user across all soaps
4. Return data with position, user, shaves (sample shaves only), and unique_users fields
5. Sort by shaves desc, unique_users desc (following existing pattern)

The aggregator should:
- Only process records where soap.enriched.sample_type exists
- Extract author from record.author
- Count total sample shaves per user (not regular shaves)
- Handle cases where sample data exists but author is missing

Output structure should match:
```json
{
  "position": 1,
  "user": "username123",
  "shaves": 12,
  "unique_users": 1
}
```

Use the same patterns as existing user aggregators for data extraction and output formatting.
```

### Step 5: Create SoapBrandDiversityAggregator

```text
Create a new SoapBrandDiversityAggregator class in `sotd/aggregate/aggregators/users/soap_brand_diversity_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract soap data from soap.matched.brand (successful matches only)
3. Group by author to count unique soap brands per user
4. Return data with position, user, unique_brands, and total_shaves fields
5. Sort by unique_brands desc, total_shaves desc (following existing pattern)

The aggregator should:
- Only process records where soap.matched.brand exists (successful matches)
- Extract author from record.author and brand from soap.matched.brand
- Count unique brands per user (not total shaves)
- Include total_shaves as secondary metric for tie-breaking

Output structure should match:
```json
{
  "position": 1,
  "user": "username123",
  "unique_brands": 8,
  "total_shaves": 25
}
```

Use the same patterns as existing user aggregators for data extraction and output formatting.
```

### Step 6: Create SoapBrandScentDiversityAggregator

```text
Create a new SoapBrandScentDiversityAggregator class in `sotd/aggregate/aggregators/users/soap_brand_scent_diversity_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract soap data from soap.matched.brand + soap.matched.scent (successful matches only)
3. Group by author to count unique brand+scent combinations per user
4. Return data with position, user, unique_combinations, and total_shaves fields
5. Sort by unique_combinations desc, total_shaves desc (following existing pattern)

The aggregator should:
- Only process records where soap.matched.brand and soap.matched.scent exist (successful matches)
- Extract author from record.author and brand+scent from soap.matched
- Create composite key as "Brand - Scent" for uniqueness counting
- Count unique combinations per user (not total shaves)
- Include total_shaves as secondary metric for tie-breaking

Output structure should match:
```json
{
  "position": 1,
  "user": "username123",
  "unique_combinations": 12,
  "total_shaves": 25
}
```

Use the same patterns as existing user aggregators for data extraction and output formatting.
```

### Step 7: Create RazorDiversityAggregator

```text
Create a new RazorDiversityAggregator class in `sotd/aggregate/aggregators/users/razor_diversity_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract razor data from razor.matched.brand + razor.matched.model (successful matches only)
3. Group by author to count unique razor brand+model combinations per user
4. Return data with position, user, unique_razors, and total_shaves fields
5. Sort by unique_razors desc, total_shaves desc (following existing pattern)

The aggregator should:
- Only process records where razor.matched.brand and razor.matched.model exist (successful matches)
- Extract author from record.author and brand+model from razor.matched
- Create composite key as "Brand Model" for uniqueness counting
- Count unique combinations per user (not total shaves)
- Include total_shaves as secondary metric for tie-breaking

Output structure should match:
```json
{
  "position": 1,
  "user": "username123",
  "unique_razors": 5,
  "total_shaves": 20
}
```

Use the same patterns as existing user aggregators for data extraction and output formatting.
```

### Step 8: Create BladeDiversityAggregator ‚úÖ COMPLETE

```text
Create a new BladeDiversityAggregator class in `sotd/aggregate/aggregators/users/blade_diversity_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract blade data from blade.matched.brand + blade.matched.model (successful matches only)
3. Group by author to count unique blade brand+model combinations per user
4. Return data with position, user, unique_blades, and total_shaves fields
5. Sort by unique_blades desc, total_shaves desc (following existing pattern)

The aggregator should:
- Only process records where blade.matched.brand and blade.matched.model exist (successful matches)
- Extract author from record.author and brand+model from blade.matched
- Create composite key as "Brand Model" for uniqueness counting
- Count unique combinations per user (not total shaves)
- Include total_shaves as secondary metric for tie-breaking

Output structure should match:
```json
{
  "position": 1,
  "user": "username123",
  "unique_blades": 7,
  "total_shaves": 20
}
```

Use the same patterns as existing user aggregators for data extraction and output formatting.
```

**Implementation Notes:**
- Created `sotd/aggregate/aggregators/users/blade_diversity_aggregator.py` with BladeDiversityAggregator class
- Implemented data extraction from blade.matched.brand and blade.matched.model
- Added comprehensive test coverage in `tests/aggregate/test_blade_diversity_aggregator.py`
- All tests passing - 10 test cases covering edge cases and main functionality
- Added to users `__init__.py` exports
- Committed as feat(aggregate): implement BladeDiversityAggregator for user blade diversity tracking
```

### Step 9: Create BrushDiversityAggregator ‚úÖ COMPLETE

```text
Create a new BrushDiversityAggregator class in `sotd/aggregate/aggregators/users/brush_diversity_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract brush data from multiple fields (successful matches only):
   - brush.matched.brand (top level brand)
   - brush.matched.model (top level model)
   - brush.matched.knot_brand (knot brand)
   - brush.matched.knot_model (knot model)
   - brush.matched.handle_brand (handle brand)
3. Group by author to count unique brush combinations per user
4. Return data with position, user, unique_brushes, and total_shaves fields
5. Sort by unique_brushes desc, total_shaves desc (following existing pattern)

The aggregator should:
- Only process records where brush.matched exists (successful matches)
- Extract author from record.author and all brush fields from brush.matched
- Create composite key combining all available fields (null values become "none" for grouping)
- Count unique combinations per user (not total shaves)
- Include total_shaves as secondary metric for tie-breaking
- Handle cases where some fields are null (treat as "none" for grouping)

Output structure should match:
```json
{
  "position": 1,
  "user": "username123",
  "unique_brushes": 4,
  "total_shaves": 18
}
```

Use the same patterns as existing user aggregators for data extraction and output formatting.
```

**Implementation Notes:**
- Created `sotd/aggregate/aggregators/users/brush_diversity_aggregator.py` with BrushDiversityAggregator class
- Implemented complex data extraction from multiple brush fields (brand, model, knot_brand, knot_model, handle_brand)
- Created sophisticated composite key generation that combines all available brush components
- Added comprehensive test coverage in `tests/aggregate/test_brush_diversity_aggregator.py`
- All tests passing - 12 test cases covering edge cases, partial data, and main functionality
- Added to users `__init__.py` exports
- Committed as feat(aggregate): implement BrushDiversityAggregator for complex brush component tracking
```

### Step 10: Create RazorFormatUserAggregator ‚úÖ COMPLETE

```text
Create a new RazorFormatUserAggregator class in `sotd/aggregate/aggregators/users/razor_format_user_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract razor format data from razor.matched.format (successful matches only)
3. Group by format to show top users for each razor format (DE, Straight, GEM, AC, etc.)
4. Return data with position, format, user, shaves, and unique_users fields
5. Sort by format asc, then shaves desc, then unique_users desc (format groups, then by usage within each format)

The aggregator should:
- Only process records where razor.matched.format exists (successful matches)
- Extract format from razor.matched.format and author from record.author
- Group by format first, then by user within each format
- Count total shaves per user per format
- Include unique_users as secondary metric for tie-breaking
- Handle cases where format is missing or invalid

Output structure should match:
```json
{
  "position": 1,
  "format": "DE",
  "user": "username123",
  "shaves": 25,
  "unique_users": 1
}
```

This aggregator will show which users are the top users for each razor format, providing insights into format preferences and usage patterns across the community.

Use the same patterns as existing user aggregators for data extraction and output formatting.
```

**Implementation Notes:**
- Created `sotd/aggregate/aggregators/users/razor_format_user_aggregator.py` with RazorFormatUserAggregator class
- Implemented format-first grouping logic that shows top users within each razor format category
- Created sophisticated sorting that groups by format alphabetically, then ranks users by shaves within each format
- Added comprehensive test coverage in `tests/aggregate/test_razor_format_user_aggregator.py`
- All tests passing - 11 test cases covering edge cases, multiple formats, and main functionality
- Added to users `__init__.py` exports
- Committed as feat(aggregate): implement RazorFormatUserAggregator for format-based user ranking
```

### Step 11: Create BrushFiberUserAggregator ‚úÖ COMPLETE

```text
Create a new BrushFiberUserAggregator class in `sotd/aggregate/aggregators/users/brush_fiber_user_aggregator.py` that follows the BaseAggregator pattern. This aggregator should:

1. Inherit from BaseAggregator
2. Extract brush fiber data from brush.matched.fiber (successful matches only)
3. Group by fiber type to show top users for each brush fiber (badger, boar, synthetic, etc.)
4. Return data with position, fiber, user, shaves, and unique_users fields
5. Sort by fiber asc, then shaves desc, then unique_users desc (fiber groups, then by usage within each fiber)

The aggregator should:
- Only process records where brush.matched.fiber exists (successful matches)
- Extract fiber from brush.matched.fiber and author from record.author
- Group by fiber first, then by user within each fiber
- Count total shaves per user per fiber type
- Include unique_users as secondary metric for tie-breaking
- Handle cases where fiber is missing or invalid
- Support common fiber types: badger, boar, synthetic, horse, mixed, etc.

Output structure should match:
```json
{
  "position": 1,
  "fiber": "badger",
  "user": "username123",
  "shaves": 30,
  "unique_users": 1
}
```

This aggregator will show which users are the top users for each brush fiber type, providing insights into fiber preferences and usage patterns across the community.

Use the same patterns as existing user aggregators for data extraction and output formatting.
```

**Implementation Notes:**
- Created `sotd/aggregate/aggregators/users/brush_fiber_user_aggregator.py` with BrushFiberUserAggregator class
- Implemented fiber-first grouping logic that shows top users within each brush fiber category
- Created sophisticated sorting that groups by fiber alphabetically, then ranks users by shaves within each fiber
- Added comprehensive test coverage in `tests/aggregate/test_brush_fiber_user_aggregator.py`
- All tests passing - 12 test cases covering edge cases, multiple fiber types, and main functionality
- Added to users `__init__.py` exports
- Committed as feat(aggregate): implement BrushFiberUserAggregator for fiber-based user ranking
```

### Step 12: Processor Integration

```text
Remove the existing SoapSampleAggregator and integrate all 10 new aggregators into the existing aggregate phase processor. Update `sotd/aggregate/processor.py` to:

1. Import all new aggregator functions:
   - aggregate_soap_sample_brands
   - aggregate_soap_sample_brand_scents
   - aggregate_soap_sample_users
   - aggregate_soap_brand_diversity
   - aggregate_soap_brand_scent_diversity
   - aggregate_razor_diversity
   - aggregate_blade_diversity
   - aggregate_brush_diversity
   - aggregate_razor_format_users
   - aggregate_brush_fiber_users

2. Remove the existing SoapSampleAggregator from the pipeline
3. Add all new aggregators to the aggregate_all function in the appropriate sections:
   - Sample aggregators in a new "Sample aggregations" section
   - Soap diversity aggregators in the "Software Categories" section
   - Hardware diversity aggregators in a new "User Diversity" section

4. Update the debug count from "24 aggregators" to "33 aggregators" (removed 1, added 10 = net +9)

5. Ensure proper dependency order (sample aggregators after soaps, diversity aggregators after core product aggregations)

6. Maintain the existing structure and organization of the processor

The integration should follow the same pattern as existing aggregators and maintain the current output structure.
```

### Step 13: Comprehensive Testing

```text
Create comprehensive test coverage for all 10 new aggregators. This includes:

1. **Unit Tests for Each Aggregator**:
   - Test data extraction logic
   - Test grouping and counting logic
   - Test sorting and ranking logic
   - Test edge cases (empty data, missing fields, null values)
   - Test output structure and field validation

2. **Integration Tests**:
   - Test aggregator integration in processor
   - Test complete data flow from enriched to aggregated
   - Test with real production data structures
   - Test error handling and edge cases

3. **Test Data Requirements**:
   - Mock enriched data with sample information
   - Mock enriched data with diversity information
   - Edge cases: missing fields, null values, empty records
   - Realistic data volumes and patterns

4. **Test File Organization**:
   - Sample aggregators: `tests/aggregate/test_core_aggregators.py`
   - User diversity aggregators: `tests/aggregate/test_user_aggregators.py`
   - Integration tests: `tests/aggregate/test_processor.py`

5. **Test Coverage Requirements**:
   - Minimum 90% line coverage for each aggregator
   - All edge cases and error conditions tested
   - Performance tests for large datasets
   - Validation that output matches expected structure

All tests should follow the project's testing patterns and ensure the aggregators work correctly in production scenarios.
```

### Step 14: Documentation Updates

```text
Update all relevant documentation to reflect the new aggregators. This includes:

1. **Aggregate Phase Specification** (`docs/aggregate_phase_spec.md`):
   - Add new aggregator categories to Core Categories section
   - Document sample aggregators and their data sources
   - Document user diversity aggregators and their metrics
   - Update output structure documentation with new fields

2. **Aggregate Phase Rules** (`.cursor/rules/aggregate-phase.mdc`):
   - Add new aggregator types to Core Categories section
   - Document sample data processing requirements
   - Document diversity calculation patterns
   - Update testing requirements for new aggregators

3. **Implementation Plan Updates**:
   - Mark all tasks as complete in this plan
   - Add lessons learned and implementation decisions
   - Document any deviations from original plan
   - Update status indicators and timestamps

4. **README and Usage Documentation**:
   - Update any README files that reference aggregator counts
   - Document new aggregator capabilities and use cases
   - Provide examples of new aggregation outputs

The documentation should maintain consistency with existing patterns and provide clear guidance for future development and maintenance.
```

## üß† Critical Analysis

**Architecture Strengths**:
- ‚úÖ Follows established BaseAggregator patterns for consistency
- ‚úÖ Proper separation of concerns (sample vs diversity aggregators)
- ‚úÖ Reuses proven data extraction and processing approaches
- ‚úÖ Integrates cleanly with existing pipeline phases
- ‚úÖ Maintains consistent output structure across all aggregators

**Implementation Considerations**:
- **Sample data dependency**: Requires completion of soap sample enrichment before these aggregators can be tested
- **Data source consistency**: ‚úÖ **All aggregators read from the same enriched data files** (`data/enriched/YYYY-MM.json`), ensuring consistent data access and structure
- **Field handling**: Brush diversity aggregator must handle multiple nullable fields gracefully (null values become "none" in composite keys)
- **Performance impact**: Replacing 1 general aggregator with 10 specialized aggregators increases processing time and memory usage (will increase from 24 to 33 total aggregators)

**Risk Mitigation**:
- **Incremental implementation**: Each aggregator can be built and tested independently
- **Test-first approach**: Comprehensive testing ensures reliability and prevents regressions
- **Pattern reuse**: Leveraging existing BaseAggregator patterns reduces implementation risk
- **Integration testing**: Validating complete data flow prevents phase misalignment

**Dependencies**:
- Soap sample detection enrichment must be complete
- BaseAggregator infrastructure (already exists)
- Aggregate phase processor (already exists)
- Testing framework (already exists)

**Success Criteria**:
- All 10 aggregators produce correct output following established patterns
- Sample aggregators correctly process enriched sample data
- Diversity aggregators correctly count unique combinations per user
- Razor format usage aggregator correctly shows top users per format
- Brush fiber usage aggregator correctly shows top users per fiber type
- Integration with existing processor maintains performance and reliability
- Comprehensive test coverage ensures long-term maintainability

This plan provides a clear, incremental path to implementing the new aggregators while maintaining the project's architectural principles and quality standards. Each step builds logically on the previous one, ensuring safe and reliable implementation.