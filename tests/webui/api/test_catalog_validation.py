#!/usr/bin/env python3
"""Tests for catalog validation functionality."""

import tempfile
from pathlib import Path
from typing import Dict, Any

import pytest
import yaml
import requests

from sotd.match.tools.managers.validate_correct_matches import ValidateCorrectMatches


class TestCatalogValidation:
    """Test catalog validation functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        # Create a temporary correct_matches.yaml file for testing
        temp_file = tempfile.NamedTemporaryFile(mode="w", suffix=".yaml", delete=False)
        yaml.dump({"brush": {}, "razor": {}, "blade": {}, "soap": {}}, temp_file)
        temp_file.close()
        self.temp_correct_matches = Path(temp_file.name)
        self.validator = ValidateCorrectMatches(correct_matches_path=self.temp_correct_matches)

    def create_temp_yaml(self, data: Dict[str, Any]) -> Path:
        """Create a temporary YAML file with test data (legacy single file format)."""
        temp_file = tempfile.NamedTemporaryFile(mode="w", suffix=".yaml", delete=False)
        yaml.dump(data, temp_file)
        temp_file.close()
        return Path(temp_file.name)

    def create_temp_correct_matches_dir(self, data: Dict[str, Any], tmp_path: Path) -> Path:
        """Create a temporary correct_matches directory structure with test data."""
        correct_matches_dir = tmp_path / "correct_matches"
        correct_matches_dir.mkdir()

        # Extract field-specific data and create separate files
        for field_name, field_data in data.items():
            field_file = correct_matches_dir / f"{field_name}.yaml"
            with field_file.open("w") as f:
                yaml.dump(field_data, f)

        return correct_matches_dir

    def _set_validator_data_dir(self, validator: ValidateCorrectMatches) -> None:
        """Set the data directory on a validator to point to the project's data directory."""
        validator._data_dir = Path.cwd() / "data"

    def test_valid_blade_data_passes_validation(self, tmp_path):
        """Test that valid blade data passes validation."""
        # Create valid blade data that matches current catalog patterns
        valid_blade_data = {
            "blade": {
                "DE": {
                    "Astra": {
                        "Superior Platinum (Green)": [
                            "astra green",
                            "astra platinum",
                            "astra sp green",
                        ]
                    },
                    "Feather": {"DE": ["feather", "feather (de)", "feather hi-stainless"]},
                }
            }
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(valid_blade_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation using the actual implemented method
        # This will use our temporary test data
        issues, expected_structure = validator.validate_field("blade")

        # Should be able to process the data without errors
        assert isinstance(issues, list)
        assert isinstance(expected_structure, dict)

    def test_corrupted_blade_data_fails_validation(self, tmp_path):
        """Test that corrupted blade data fails validation."""
        # Create corrupted blade data with invalid brand/model combinations
        corrupted_blade_data = {
            "blade": {
                "DE": {
                    "InvalidBrand": {  # This brand doesn't exist in blades.yaml
                        "InvalidModel": ["invalid blade entry"]
                    },
                    "Astra": {
                        "InvalidModel": [  # This model doesn't exist for Astra
                            "astra invalid model"
                        ]
                    },
                }
            }
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(corrupted_blade_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation
        issues, expected_structure = validator.validate_field("blade")

        # Should detect validation issues
        assert isinstance(issues, list)
        assert len(issues) > 0, "Should detect validation issues for corrupted data"
        assert isinstance(expected_structure, dict)

    def test_renamed_model_detection(self, tmp_path):
        """Test that renamed models are detected."""
        # Create blade data with a renamed model
        renamed_model_data = {
            "blade": {
                "DE": {
                    "Astra": {
                        "Superior Platinum (Green)": [
                            "astra green",
                            "astra platinum",
                        ],
                        "Old Model Name": ["old model pattern"],  # This model was renamed
                    }
                }
            }
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(renamed_model_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation
        issues, expected_structure = validator.validate_field("blade")

        # Should be able to process the data
        assert isinstance(issues, list)
        assert isinstance(expected_structure, dict)

    def test_api_endpoint_with_valid_data(self, tmp_path):
        """Test the API endpoint with valid data."""
        # Create valid blade data
        valid_blade_data = {
            "blade": {
                "DE": {"Astra": {"Superior Platinum (Green)": ["astra green", "astra platinum"]}}
            }
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(valid_blade_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation using the actual implemented method
        issues, expected_structure = validator.validate_field("blade")

        # Should be able to process the data without errors
        assert isinstance(issues, list)
        assert isinstance(expected_structure, dict)

    def test_api_endpoint_with_corrupted_data(self, tmp_path):
        """Test the API endpoint with corrupted data."""
        # Create corrupted blade data
        corrupted_blade_data = {
            "blade": {
                "DE": {
                    "InvalidBrand": {"InvalidModel": ["invalid blade entry"]},
                }
            }
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(corrupted_blade_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation
        issues, expected_structure = validator.validate_field("blade")

        # Should detect validation issues
        assert isinstance(issues, list)
        assert len(issues) > 0, "Should detect validation issues for corrupted data"
        assert isinstance(expected_structure, dict)

    def test_brush_validation_with_handle_knot_section(self, tmp_path):
        """Test brush validation with handle_knot section."""
        # Create brush data with handle_knot section
        brush_data = {
            "handle_knot": {
                "test brush pattern": {
                    "handle": {"brand": "Test Handle Brand", "model": "Test Handle Model"},
                    "knot": {"brand": "Test Knot Brand", "model": "Test Knot Model"},
                }
            }
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(brush_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation
        issues, expected_structure = validator.validate_field("brush")

        # Should be able to process the data
        assert isinstance(issues, list)
        assert isinstance(expected_structure, dict)

    def test_brush_validation_with_complete_brush_section(self, tmp_path):
        """Test brush validation with complete brush section."""
        # Create brush data with complete brush section
        brush_data = {"brush": {"Test Brand": {"Test Model": ["test brush pattern"]}}}

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(brush_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation
        issues, expected_structure = validator.validate_field("brush")

        # Should be able to process the data
        assert isinstance(issues, list)
        assert isinstance(expected_structure, dict)

    def test_api_brush_validation_with_temp_data(self, tmp_path):
        """Test API brush validation with temporary correct_matches.yaml data."""
        # Create test brush data
        test_brush_data = {"brush": {"Chisel & Hound": {"v26": ["chisel & hound v26", "c&h v26"]}}}

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(test_brush_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation
        issues, expected_structure = validator.validate_field("brush")

        # Should be able to process the data
        assert isinstance(issues, list)
        assert isinstance(expected_structure, dict)

    def test_api_brush_validation_with_version_mismatch(self, tmp_path):
        """Test API brush validation detects version mismatches."""
        # Create test brush data with version mismatch
        # Store v26 but pattern contains v27
        test_brush_data = {
            "brush": {
                "Chisel & Hound": {
                    "v26": ["chisel & hound v27", "c&h v27"]  # Stored as v26 but pattern is v27
                }
            }
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(test_brush_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation
        issues, expected_structure = validator.validate_field("brush")

        # Should detect version mismatch issues
        assert isinstance(issues, list)
        assert isinstance(expected_structure, dict)

        # Check if version mismatch was detected
        # The actual detection depends on the validator implementation
        # This test verifies the validator can process the data without errors

    def test_api_brush_validation_with_dinos_mores_version_mismatch(self, tmp_path):
        """Test API brush validation detects dinos'mores version mismatch."""
        # Create test brush data with dinos'mores version mismatch
        # Store v26 but pattern contains v27
        test_brush_data = {
            "brush": {
                "Chisel & Hound": {
                    "v26": [
                        "dinos'mores v27",
                        "dinos mores v27",
                    ]  # Stored as v26 but pattern is v27
                }
            }
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = tmp_path / "correct_matches.yaml"
        with correct_matches_file.open("w") as f:
            yaml.dump(test_brush_data, f)

        # Create a new validator instance for testing
        validator = ValidateCorrectMatches(correct_matches_path=correct_matches_file)

        # Set the data directory to point to the project's data directory
        self._set_validator_data_dir(validator)

        # Run validation
        issues, expected_structure = validator.validate_field("brush")

        # Should detect version mismatch issues
        assert isinstance(issues, list)
        assert isinstance(expected_structure, dict)

        # Filter issues for dinos'mores
        dinos_issues = [
            issue
            for issue in issues
            if "dinos" in str(issue.get("pattern", "")).lower()
            or "dinos" in str(issue.get("message", "")).lower()
        ]

        if len(dinos_issues) > 0:
            # Verify the issue details for complete brush validation
            for issue in dinos_issues:
                assert (
                    issue["type"] == "catalog_pattern_mismatch"
                ), f"Should be catalog pattern mismatch, got {issue['type']}"
                # The matcher matches patterns containing "chisel & hound" to the brand
                # The actual matched brand/model depends on what the matcher finds
                assert (
                    issue["matched_brand"] == "Chisel & Hound"
                ), f"Expected 'Chisel & Hound', got {issue['matched_brand']}"
                # The model might be v27 (from the pattern) or something else
                assert issue["matched_model"] is not None, "Matched model should not be None"
                assert (
                    issue["stored_brand"] == "Chisel & Hound"
                ), f"Expected 'Chisel & Hound', got {issue['stored_brand']}"
                assert (
                    issue["stored_model"] == "v26"
                ), f"Expected 'v26', got {issue['stored_model']}"

    # This test has been removed as it tests webui API logic,
    # not core pipeline validation
    # The core pipeline validation is tested by the other tests in this file


class TestCatalogValidationIntegration:
    """Integration tests for catalog validation with real API."""

    def create_temp_yaml(self, data: Dict[str, Any]) -> Path:
        """Create a temporary YAML file with test data."""
        temp_file = tempfile.NamedTemporaryFile(mode="w", suffix=".yaml", delete=False)
        yaml.dump(data, temp_file)
        temp_file.close()
        return Path(temp_file.name)

    @pytest.mark.integration
    def test_api_validation_with_temp_data(self):
        """Test API validation with temporary correct_matches.yaml data."""
        # This test requires the API server to be running
        # It will be skipped if not running in integration mode

        # Create test data
        test_data = {
            "blade": {
                "DE": {"Astra": {"Superior Platinum (Green)": ["astra green", "astra platinum"]}}
            }
        }

        # Create temporary file
        with tempfile.NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as f:
            yaml.dump(test_data, f)
            temp_file = Path(f.name)

        try:
            # Test API endpoint
            response = requests.post(
                "http://localhost:8000/api/analysis/validate-catalog",
                json={"field": "blade"},
                timeout=10,
            )

            if response.status_code == 200:
                data = response.json()
                print(
                    f"API Response: {data['total_entries']} entries, "
                    f"{len(data['issues'])} issues"
                )

                # API should return validation results (may have issues in real catalog)
                assert "total_entries" in data, "Response should include total_entries"
                assert "issues" in data, "Response should include issues"
                assert isinstance(data["issues"], list), "Issues should be a list"

                # If there are issues, they should have the expected structure
                for issue in data["issues"]:
                    assert "issue_type" in issue, "Each issue should have an issue_type"
                    assert "field" in issue, "Each issue should have a field"
                    assert "severity" in issue, "Each issue should have a severity"
            else:
                pytest.fail(f"API returned status code {response.status_code}: {response.text}")

        finally:
            # Clean up
            if temp_file.exists():
                temp_file.unlink()

    @pytest.mark.integration
    def test_api_validation_with_corrupted_data(self):
        """Test API validation with corrupted data."""
        # This test requires the API server to be running
        # It will be skipped if not running in integration mode

        # Test API endpoint
        response = requests.post(
            "http://localhost:8000/api/analysis/validate-catalog",
            json={"field": "blade"},
            timeout=10,
        )

        if response.status_code == 200:
            data = response.json()
            print(
                f"API Response: {data['total_entries']} entries, " f"{len(data['issues'])} issues"
            )

            # API should return validation results
            assert "total_entries" in data, "Response should include total_entries"
            assert "issues" in data, "Response should include issues"
            assert isinstance(data["issues"], list), "Issues should be a list"

    @pytest.mark.integration
    def test_api_brush_validation_with_temp_data(self):
        """Test API brush validation with temporary correct_matches.yaml data."""
        # This test requires the API server to be running
        # It will be skipped if not running in integration mode

        # Create test brush data
        test_brush_data = {"brush": {"Chisel & Hound": {"v26": ["chisel & hound v26", "c&h v26"]}}}

        # Create temporary file
        with tempfile.NamedTemporaryFile(mode="w", suffix=".yaml", delete=False) as f:
            yaml.dump(test_brush_data, f)
            temp_file = Path(f.name)

        try:
            # Test API endpoint
            response = requests.post(
                "http://localhost:8000/api/analysis/validate-catalog",
                json={"field": "brush"},
                timeout=10,
            )

            if response.status_code == 200:
                data = response.json()
                print(
                    f"API Response: {data['total_entries']} entries, "
                    f"{len(data['issues'])} issues"
                )

                # API should return validation results
                assert "total_entries" in data, "Response should include total_entries"
                assert "issues" in data, "Response should include issues"
                assert isinstance(data["issues"], list), "Issues should be a list"

                # If there are issues, they should have the expected structure
                for issue in data["issues"]:
                    assert "issue_type" in issue, "Each issue should have an issue_type"
                    assert "field" in issue, "Each issue should have a field"
                    assert "severity" in issue, "Each issue should have a severity"
            else:
                pytest.fail(f"API returned status code {response.status_code}: {response.text}")

        finally:
            # Clean up
            if temp_file.exists():
                temp_file.unlink()

    def test_api_issue_type_mapping(self, tmp_path):
        """Test that the API correctly maps issue types and fields from shared validator.

        This test verifies that:
        1. Issue types are properly populated
        2. Pattern fields are properly populated
        3. Message fields are mapped to details
        4. All required fields are present
        """
        # Create test data with known validation issues
        test_brush_data = {
            "brush": {"Test Brand": {"Test Model": ["test pattern that will cause matching error"]}}
        }

        # Create temporary correct_matches.yaml
        correct_matches_file = self.create_temp_yaml(test_brush_data)

        try:
            # Set up test environment
            test_project_root = tmp_path
            test_data_dir = test_project_root / "data"
            test_data_dir.mkdir()

            # Copy test data
            import shutil

            shutil.copy(correct_matches_file, test_data_dir / "correct_matches.yaml")

            # Create minimal catalog files (this will cause matching errors)
            brushes_file = test_data_dir / "brushes.yaml"
            with open(brushes_file, "w") as f:
                yaml.dump({"Test Brand": {"Test Model": {"patterns": []}}}, f)

            handles_file = test_data_dir / "handles.yaml"
            with open(handles_file, "w") as f:
                yaml.dump({"Test Brand": {"Unspecified": {"patterns": []}}}, f)

            knots_file = test_data_dir / "knots.yaml"
            with open(knots_file, "w") as f:
                yaml.dump({"Test Brand": {"Test Model": {"patterns": []}}}, f)

            # Create minimal brush scoring config
            brush_config = {
                "brush_scoring_weights": {
                    "base_strategies": {
                        "correct_complete_brush": 100.0,
                        "correct_split_brush": 95.0,
                        "known_split": 90.0,
                        "known_brush": 80.0,
                        "automated_split": 60.0,
                        "unified": 40.0,
                        "handle_only": 30.0,
                        "knot_only": 30.0,
                    },
                    "strategy_modifiers": {
                        "automated_split": {
                            "high_confidence": 15.0,
                            "multiple_brands": 30.0,
                            "fiber_words": 0.0,
                            "size_specification": 0.0,
                            "delimiter_confidence": 0.0,
                        }
                    },
                }
            }
            brush_config_file = test_data_dir / "brush_scoring_config.yaml"
            with open(brush_config_file, "w") as f:
                yaml.dump(brush_config, f)

            # Test the shared validator directly
            from webui.api.validators.catalog_validator import CatalogValidator

            validator = CatalogValidator(project_root=test_project_root)

            # Run validation
            issues = validator.validate_brush_catalog()

            # Should find validation issues
            assert len(issues) > 0, "Should detect validation issues"

            # Check that issue types are properly populated
            for issue in issues:
                assert issue["type"] is not None, "Issue type should not be null"
                assert issue["pattern"] is not None, "Issue pattern should not be null"
                assert issue["message"] is not None, "Issue message should not be null"

                # Verify issue structure
                assert "field" in issue, "Issue should have field"
                assert "stored_brand" in issue, "Issue should have stored_brand"
                assert "stored_model" in issue, "Issue should have stored_model"

                # For matching errors, should have error details
                if issue["type"] == "matching_error":
                    assert "error" in issue, "Matching error should have error field"
                    assert issue["error"] is not None, "Error field should not be null"

                # For catalog mismatches, should have matched fields
                elif issue["type"] == "catalog_pattern_mismatch":
                    assert "matched_brand" in issue, "Mismatch should have matched_brand"
                    assert "matched_model" in issue, "Mismatch should have matched_model"

        finally:
            # Clean up
            if "correct_matches_dir" in locals() and correct_matches_dir.exists():
                import shutil

                shutil.rmtree(correct_matches_dir)
            elif "correct_matches_file" in locals() and correct_matches_file.exists():
                correct_matches_file.unlink()


class TestMoveCatalogEntries:
    """Tests for move catalog entries functionality."""

    def create_temp_correct_matches_dir(self, data: Dict[str, Any], tmp_path: Path) -> Path:
        """Create a temporary correct_matches directory structure with test data."""
        correct_matches_dir = tmp_path / "correct_matches"
        correct_matches_dir.mkdir()

        # Extract field-specific data and create separate files
        for field_name, field_data in data.items():
            field_file = correct_matches_dir / f"{field_name}.yaml"
            with field_file.open("w") as f:
                yaml.dump(field_data, f)

        return correct_matches_dir

    @pytest.mark.asyncio
    async def test_move_data_mismatch_entry(self, tmp_path):
        """Test moving a data_mismatch entry (updating brand/model in same section)."""
        # Create initial correct_matches data
        initial_data = {"razor": {"Old Brand": {"Old Model": ["test razor pattern"]}}}

        correct_matches_dir = self.create_temp_correct_matches_dir(initial_data, tmp_path)

        # Import the move endpoint function
        import sys
        from pathlib import Path

        # Add project root to path for imports
        project_root = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(project_root))

        from webui.api.analysis import move_catalog_validation_entries, MoveCatalogEntriesRequest

        # Create request to move entry
        request = MoveCatalogEntriesRequest(
            field="razor",
            matches=[
                {
                    "correct_match": "test razor pattern",
                    "expected_brand": "Old Brand",
                    "expected_model": "Old Model",
                    "actual_brand": "New Brand",
                    "actual_model": "New Model",
                    "issue_type": "data_mismatch",
                    "actual_section": "razor",
                    "expected_section": "razor",
                }
            ],
        )

        # Mock project_root to point to tmp_path
        import webui.api.analysis as analysis_module

        original_project_root = getattr(analysis_module, "project_root", None)
        analysis_module.project_root = tmp_path

        try:
            # Execute move (await the async function)
            response = await move_catalog_validation_entries(request)

            # Verify response
            assert response.success is True
            assert response.removed_count == 1
            assert response.added_count == 1
            assert response.moved_count == 1

            # Verify the entry was removed from old location
            razor_file = correct_matches_dir / "razor.yaml"
            with razor_file.open("r") as f:
                razor_data = yaml.safe_load(f) or {}

            # Old brand/model should be gone or empty
            old_brand_data = razor_data.get("Old Brand", {})
            old_model_patterns = old_brand_data.get("Old Model", [])
            assert "test razor pattern" not in old_model_patterns

            # Verify the entry was added to new location
            new_brand_data = razor_data.get("New Brand", {})
            new_model_patterns = new_brand_data.get("New Model", [])
            assert "test razor pattern" in new_model_patterns

        finally:
            # Restore original project_root
            if original_project_root:
                analysis_module.project_root = original_project_root

    @pytest.mark.asyncio
    async def test_move_structural_change_handle_knot_to_brush(self, tmp_path):
        """Test moving a structural_change entry from handle_knot to brush."""
        # Create initial correct_matches data with handle and knot entries
        initial_data = {
            "handle": {"Handle Brand": {"Handle Model": ["test brush pattern"]}},
            "knot": {"Knot Brand": {"Knot Model": ["test brush pattern"]}},
        }

        correct_matches_dir = self.create_temp_correct_matches_dir(initial_data, tmp_path)

        # Import the move endpoint function
        import sys
        from pathlib import Path

        project_root = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(project_root))

        from webui.api.analysis import move_catalog_validation_entries, MoveCatalogEntriesRequest

        # Create request to move entry from handle_knot to brush
        request = MoveCatalogEntriesRequest(
            field="brush",
            matches=[
                {
                    "correct_match": "test brush pattern",
                    "expected_brand": "Handle Brand",
                    "expected_model": "Handle Model",
                    "actual_brand": "Brush Brand",
                    "actual_model": "Brush Model",
                    "issue_type": "structural_change",
                    "actual_section": "brush",
                    "expected_section": "handle_knot",
                    "expected_handle_match": {"brand": "Handle Brand", "model": "Handle Model"},
                    "expected_knot_match": {
                        "brand": "Knot Brand",
                        "model": "Knot Model",
                        "fiber": "synthetic",
                        "knot_size_mm": 26,
                    },
                }
            ],
        )

        # Mock project_root
        import webui.api.analysis as analysis_module

        original_project_root = getattr(analysis_module, "project_root", None)
        analysis_module.project_root = tmp_path

        try:
            # Execute move (await the async function)
            response = await move_catalog_validation_entries(request)

            # Verify response
            assert response.success is True
            assert response.removed_count >= 1  # Removed from handle and/or knot
            assert response.added_count == 1  # Added to brush

            # Verify the entry was added to brush section
            brush_file = correct_matches_dir / "brush.yaml"
            if brush_file.exists():
                with brush_file.open("r") as f:
                    brush_data = yaml.safe_load(f) or {}

                brush_brand_data = brush_data.get("Brush Brand", {})
                brush_model_patterns = brush_brand_data.get("Brush Model", [])
                assert "test brush pattern" in brush_model_patterns

    @pytest.mark.asyncio
    async def test_move_blade_with_format_preservation(self, tmp_path):
        """Test moving a blade entry while preserving format information."""
        # Create initial correct_matches data
        initial_data = {"blade": {"DE": {"Old Brand": {"Old Model": ["test blade pattern"]}}}}

        # Create correct_matches directory at tmp_path / "data" / "correct_matches"
        # (matching the structure expected by get_data_directory())
        data_dir = tmp_path / "data"
        data_dir.mkdir()
        correct_matches_dir = data_dir / "correct_matches"
        correct_matches_dir.mkdir()
        
        # Create blade.yaml file
        blade_file = correct_matches_dir / "blade.yaml"
        with blade_file.open("w") as f:
            yaml.dump(initial_data["blade"], f)

        # Import the move endpoint function
        import sys
        from pathlib import Path
        from unittest.mock import patch

        project_root = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(project_root))

        from webui.api.analysis import move_catalog_validation_entries, MoveCatalogEntriesRequest, get_data_directory

        # Create request to move blade entry
        request = MoveCatalogEntriesRequest(
            field="blade",
            matches=[
                {
                    "correct_match": "test blade pattern",
                    "expected_brand": "Old Brand",
                    "expected_model": "Old Model",
                    "actual_brand": "New Brand",
                    "actual_model": "New Model",
                    "issue_type": "data_mismatch",
                    "actual_section": "blade",
                    "expected_section": "blade",
                    "format": "DE",
                }
            ],
        )

        # Mock get_data_directory to return tmp_path / "data"
        with patch("webui.api.analysis.get_data_directory", return_value=data_dir):
            # Execute move (await the async function)
            response = await move_catalog_validation_entries(request)

            # Verify response
            assert response.success is True
            assert response.removed_count == 1
            assert response.added_count == 1

            # Verify format was preserved in the new entry
            blade_file = correct_matches_dir / "blade.yaml"
            with blade_file.open("r") as f:
                blade_data = yaml.safe_load(f) or {}

            de_section = blade_data.get("DE", {})
            new_brand_data = de_section.get("New Brand", {})
            new_model_patterns = new_brand_data.get("New Model", [])
            assert "test blade pattern" in new_model_patterns

    @pytest.mark.asyncio
    async def test_move_entry_not_found_error(self, tmp_path):
        """Test error handling when entry is not found in source location."""
        # Create empty correct_matches data
        initial_data = {"razor": {}}

        correct_matches_dir = self.create_temp_correct_matches_dir(initial_data, tmp_path)

        # Import the move endpoint function
        import sys
        from pathlib import Path

        project_root = Path(__file__).parent.parent.parent.parent
        sys.path.insert(0, str(project_root))

        from webui.api.analysis import move_catalog_validation_entries, MoveCatalogEntriesRequest

        # Create request to move non-existent entry
        request = MoveCatalogEntriesRequest(
            field="razor",
            matches=[
                {
                    "correct_match": "non-existent pattern",
                    "expected_brand": "Old Brand",
                    "expected_model": "Old Model",
                    "actual_brand": "New Brand",
                    "actual_model": "New Model",
                    "issue_type": "data_mismatch",
                    "actual_section": "razor",
                    "expected_section": "razor",
                }
            ],
        )

        # Mock project_root
        import webui.api.analysis as analysis_module

        original_project_root = getattr(analysis_module, "project_root", None)
        analysis_module.project_root = tmp_path

        try:
            # Execute move (await the async function)
            response = await move_catalog_validation_entries(request)

            # Should still succeed but with warnings
            # Entry not found should be logged but not cause failure
            assert response.removed_count == 0  # Nothing to remove
            # May or may not add depending on implementation

        finally:
            # Restore original project_root
            if original_project_root:
                analysis_module.project_root = original_project_root
