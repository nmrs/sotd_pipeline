---
alwaysApply: true
---

# SOTD Pipeline - Core Development Rules
# Shave of the Day Data Processing Pipeline

## Project Overview
This is a Python 3.11 data processing pipeline that extracts, processes, and analyzes "Shave of the Day" posts from Reddit's r/wetshaving community. The pipeline consists of 6 sequential phases: fetch, extract, match, enrich, aggregate, and report.

## Pipeline --force Rule (MANDATORY)
- **When running any pipeline step, ALWAYS use the `--force` flag unless the user explicitly says NOT to use `--force`.**
- This ensures fresh data processing, avoids cached results, and guarantees that all code changes are actually tested.
- If you want to run without --force, specify that explicitly in your request.

## YAML File Update Restriction (MANDATORY)
- **NEVER update YAML files without explicit user permission.**
- **YAML files are data files, not code files, and should only be modified by the user.**
- **If YAML changes are needed, suggest them to the user or ask for permission first.**
- **This applies to all YAML files in the `data/` directory and any other YAML configuration files.**
- **Exception**: Only update YAML files when the user explicitly requests it or gives permission.

## Development Environment
- **Python Version**: 3.11 (enforced by pyrightconfig.json)
- **Virtual Environment**: Use `.venv` directory
- **Virtual Environment Activation (MANDATORY)**: **ALWAYS activate the virtual environment before installing any packages or running any commands.** Use `source .venv/bin/activate` or ensure the virtual environment is active before any pip install, make commands, or development operations. This prevents package conflicts and ensures consistent development environment.
- **Package Manager**: pip with requirements.txt/requirements-dev.txt
- **Code Style**: Black (100 char line length)
- **Linting**: Ruff (E, F, I rules)
- **Type Checking**: Pyright in standard mode
- **Testing**: pytest with coverage via pytest-cov

## Architecture Patterns
- **Phase Structure**: Each phase follows the pattern: `run.py` (CLI), core logic modules, `save.py` (I/O)
- **Matcher Strategy**: Use BaseMatcher as base class for all product matchers
- **YAML Catalogs**: Store product data in YAML files under `data/` directory
- **Data Flow**: Each phase reads from previous phase output, writes to `data/{phase}/YYYY-MM.json`

## Business Logic Architecture

### **MANDATORY**: Backend Business Logic Implementation
- **Business logic MUST be implemented in the backend (Python pipeline or API), not in the frontend UI**
- **Shared logic between CLI and API should be implemented in shared library components**
- **API-specific logic should be implemented in the API layer, not duplicated in the UI**
- **UI should perform minimal processing and focus on presentation and user interaction**

### Implementation Guidelines
- **Shared Components**: Create reusable modules in `sotd/utils/` or `sotd/shared/` for logic used by both CLI and API
- **API Layer**: Implement business logic in FastAPI endpoints or service classes, not in React components
- **UI Responsibilities**: Frontend should handle data formatting, user input validation, and display logic only
- **Data Processing**: All data transformation, aggregation, and business rules must be handled server-side

### Examples
```python
# ✅ CORRECT - Business logic in backend API
@app.post("/api/brush/validate")
async def validate_brush(brush_data: dict):
    # Business logic for brush validation
    validation_result = brush_validator.validate(brush_data)
    return validation_result

# ❌ WRONG - Business logic in frontend
const validateBrush = (brushData) => {
    # Complex validation logic in React component
    if (brushData.brand && brushData.model) {
        # Business rules implemented in UI
    }
}
```

### Rationale
- **Maintainability**: Business logic changes require backend updates only
- **Consistency**: Same logic applied across CLI, API, and future interfaces
- **Testing**: Backend logic can be thoroughly tested with Python testing tools
- **Performance**: Server-side processing avoids client-side computation overhead
- **Security**: Business rules cannot be bypassed by client-side manipulation

## Code Style Rules
- Use descriptive variable names that reflect the domain (e.g., `soap_matcher`, `blade_patterns`, `sotd_comment`)
- Follow existing naming conventions: snake_case for functions/variables, PascalCase for classes
- Use type hints for all function parameters and return values
- Line length: 100 characters maximum (Black setting)
- Use pathlib.Path for file system operations, not os.path
- Prefer f-strings over .format() or % formatting
- **File Size Preference**: Prefer smaller, focused files with clear responsibilities over large monolithic files. Aim for files under 300-400 lines when possible. Split large files into logical modules with single responsibilities. This improves readability, maintainability, and makes testing easier.

## Error Handling
- **Fail fast for internal errors**: Use minimal try/except for interactive development
- **Handle external failures gracefully**: Reddit API failures, missing files, network issues
- **Use specific exception types**: Never use bare except clauses
- **Validate early**: Check configuration and input data at startup, fail immediately on issues

## Development Workflow Rules
- **Development Commands**: Use `make all` for complete development workflow
- **Testing**: Run `make test` before committing
- **Formatting**: Run `make format` to apply Black and Ruff formatting
- **Type Checking**: Run `make typecheck` to validate types with Pyright
- **Individual Phases**: Test individual phases with specific month data
- **Pre-Commit Validation**: **MANDATORY**: Run `make format lint typecheck test` before considering any task complete or committing changes. All checks must pass.
- **Documentation Synchronization**: **MANDATORY**: Any code, workflow, or process change MUST be reflected in all relevant documentation and Cursor rules. Documentation and rules must be updated as part of the same commit(s) as the code or process change.
- **Git Backup Strategy**: **MANDATORY**: Rely on git for backups of YAML files and artifacts. Do not create backup files in tools unless the specification explicitly calls for it. Git provides version control, history tracking, and rollback capabilities that are superior to manual backup files. This applies to all data files, configuration files, and pipeline artifacts.
- **Production Data Protection**: **MANDATORY**: **NEVER write to production data files during testing or development.** ALWAYS use temporary files (tmp_path) for file-writing tests. ALWAYS use test-specific data for integration tests. NEVER modify data/brush_splits.yaml, data/brushes.yaml, etc. in tests. ALWAYS verify test isolation before committing any test changes.
- **MDC Plan File Updates**: **MANDATORY**: When working on any task that involves an MDC plan file (in `plans/` directory), you MUST automatically update the relevant MDC file to reflect progress, completion status, lessons learned, or any changes to the plan. You do not need permission to update it - update it yourself **automatically** and **immediately** as part of completing the task. The agent never needs to ask permission to update the plan file (MDC) when completing or progressing a task. This is always required and should be done automatically. This includes:
  - Marking completed tasks as done
  - Adding notes about implementation decisions
  - Documenting any deviations from the original plan
  - Recording lessons learned for future reference
  - Updating status indicators (TODO, IN_PROGRESS, COMPLETE, etc.)
  - Adding timestamps for major milestones
  - **TIMING**: Update MDC plan files **BEFORE** showing completion summaries to the user, not after
  - **WORKFLOW STEP**: After completing any task, **immediately** update the relevant MDC plan file to mark tasks as complete and add session notes
  - **VALIDATION**: **ALWAYS** verify that MDC plan files are updated before considering any task complete or moving to the next task
  - **CONTENT**: Include completion status, lessons learned, implementation decisions, deviations from plan, and timestamps for major milestones
- **Playwright Test Automation**: **MANDATORY**: When running Playwright tests, ALWAYS use background mode to avoid blocking the conversation. Use `npm run test:e2e:background` or `./scripts/auto-test.sh` instead of direct `npx playwright test` commands. This ensures tests run in the background while allowing the conversation to continue. Monitor progress with `tail -f playwright-auto.log` and stop tests with `pkill -f playwright` if needed.
- **Development Server Background Mode**: **MANDATORY**: When starting development servers (Vite, npm run dev, uvicorn, etc.), ALWAYS use background mode to avoid blocking the conversation. Use `is_background: true` in run_terminal_cmd or start servers in background processes. This allows the conversation to continue while servers run. Monitor server status with `ps aux | grep -E "(vite|uvicorn|npm)" | grep -v grep` and test endpoints with `curl` commands.
- **Playwright Test Background Mode**: **MANDATORY**: When running Playwright tests, ALWAYS use background mode to avoid blocking the conversation. Use `npm run test:e2e:background` or `./scripts/auto-test.sh` instead of direct `npx playwright test` commands. This ensures tests run in the background while allowing the conversation to continue. Monitor progress with `tail -f playwright-auto.log` and stop tests with `pkill -f playwright` if needed.

## Testing Requirements for Plan Writing (MANDATORY)
When creating implementation plans, you MUST follow the testing principles from `@testing-patterns.mdc`:

### **MANDATORY**: Test Type Priority Hierarchy in Plans
All implementation plans MUST specify testing requirements following the priority order from `@testing-patterns.mdc`:

1. **Unit Tests** - Fast, isolated tests with mock dependencies (HIGHEST PRIORITY)
   - **REQUIRED** - All plans must include unit test requirements
   - Follow patterns from `@testing-patterns.mdc` for mock data and test structure

2. **Integration Tests** - Tests using real production data (MEDIUM PRIORITY)
   - **REQUIRED** - All plans must include integration test requirements
   - Follow patterns from `@testing-patterns.mdc` for real data validation

3. **End-to-End (E2E) Tests** - Full system tests (LOWEST PRIORITY)
   - **OPTIONAL** - Only include when testing complete user workflows is necessary
   - Follow patterns from `@testing-patterns.mdc` for E2E testing

### **MANDATORY**: Plan Testing Requirements
Every implementation plan MUST include:

1. **Unit Test Specifications**:
   - List specific functions/methods to be tested
   - Specify edge cases and error conditions to test
   - Define mock data requirements
   - Include test file locations and naming conventions

2. **Integration Test Specifications**:
   - Specify real data files to use for testing
   - Define end-to-end workflow test scenarios
   - Include catalog validation requirements
   - Specify test data management approach

3. **Test Coverage Requirements**:
   - Define minimum test coverage percentages
   - Specify critical paths that must be tested
   - Include performance testing requirements where applicable
   - Define error handling test scenarios

4. **WebUI Testing Requirements** (when applicable):
   - React component unit tests with React Testing Library
   - API integration tests with Jest mocks
   - E2E tests with Playwright (only when necessary)
   - Component rendering and user interaction tests

### **MANDATORY**: Plan Testing Validation
Before considering any plan complete, verify:

1. **Unit tests are specified** for all new functionality
2. **Integration tests are specified** for real data validation
3. **Test coverage requirements** are clearly defined
4. **Error handling scenarios** are included in test specifications
5. **Performance testing** is specified where applicable
6. **WebUI testing** is specified for React components
7. **Test file locations** and naming conventions are defined
8. **Mock data requirements** are specified for unit tests
9. **Real data requirements** are specified for integration tests
10. **Test execution commands** are included in the plan

### Why Testing Requirements in Plans Matter
- **Ensures comprehensive testing** from the start of development
- **Prevents testing gaps** by requiring test specifications upfront
- **Improves code quality** by defining testing requirements before implementation
- **Facilitates TDD approach** by specifying tests before writing code
- **Reduces technical debt** by ensuring all functionality is properly tested
- **Enables faster development** by providing clear testing guidance

## Domain-Specific Rules
- **Product Catalogs**: Maintain consistent structure in YAML files (`data/brushes.yaml`, `data/handles.yaml`, `data/razors.yaml`, `data/blades.yaml`, `data/soaps.yaml`)
- **Brand Normalization**: Follow established patterns for product brand/model separation
- **Brush Matching**: Use strategy pattern for complex brush matching scenarios with handle/knot splitting
- **Date Ranges**: Support both individual months and date ranges in CLI
- **Manual Overrides**: Provide clear validation for manual thread includes/excludes
- **Catalog Data Preservation**: All matchers must preserve complete catalog specifications (e.g., straight razor grind, width, point) in match output, not just basic brand/model/format fields
- **No Backward Compatibility Required**: Since we own the entire pipeline and can rerun it at any point, backward compatibility is not a concern. Focus on correct data representation and optimal functionality.

## Brush Matching Specifics
- **See `.cursor/rules/match-phase.mdc` for detailed brush matching implementation and strategy patterns**
- **Key principles**: Use strategy pattern, handle/knot splitting, preserve complete specifications

## Common Patterns to Follow
- Use `Path` objects for file system operations
- Compile regex patterns once, use many times  
- Validate data early with clear error messages for malformed input
- Include metadata in all output files
- Use descriptive variable names that reflect the shaving domain
- Follow the existing error handling patterns for external APIs
- Always use underscore naming for internal fields (e.g., `handle_maker`, not `handle maker`)

## File Organization
- Main YAML catalogs: `data/*.yaml` (brushes, handles, razors, blades, soaps)
- Test files mirror source structure: `tests/{module}/test_{file}.py`
- Strategy implementations: `sotd/match/{product}_matching_strategies/`
- Utilities shared across phases: `sotd/utils/`

## Pandas and Linting
- When using pandas, if linter (Ruff) warnings are triggered by idiomatic pandas code that is not easily fixable, prefer using per-line `# noqa` disables.
- If per-line disables do not work or would be excessive, use a file-level `# noqa` at the top of the file.
- Do not spend excessive time making pandas code perfectly lint-free if it would harm readability or maintainability.
- Prioritize code clarity and correctness over strict linter compliance for complex pandas operations.

## Match Phase Rules
- **See `.cursor/rules/match-phase.mdc` for comprehensive match phase rules and implementation details**
- **Key principles**: Check correct_matches.yaml first, preserve complete catalog specifications, use normalized field for matching

## Plan File Organization and Naming (MANDATORY)
- **Directory Structure**: `plans/[category]/[date]/` where:
  - `[category]` is one of: `features`, `bugs`, `refactoring`, `specs`, `optimization`, `testing`, `documentation`
  - `[date]` is ISO 8601 format (YYYY-MM-DD) using actual current date
- **Current Date Rule**: **ALWAYS** use the actual current date when creating plan files
- **Command**: Use `date +%Y-%m-%d` to get the actual current date, never assume or guess
- **File Format**: `{type}_{plan_name}.mdc` (no date suffix in filename)
- **Type Prefixes**:
  - `plan_` - Implementation plans and development roadmaps
  - `spec_` - Specifications and requirements documents
- **Examples**:
  - ✅ **Correct**: `plans/features/2025-09-02/plan_brush_table_specialized_component.mdc`
  - ✅ **Correct**: `plans/specs/2025-09-02/spec_webui_react_analyzer.mdc`
  - ✅ **Correct**: `plans/bugs/2025-09-02/plan_validation_fix.mdc`
  - ❌ **Wrong**: `plans/plan_brush_table_2025-09-02.mdc` (old structure)
- **Process**: 
  1. Run `date +%Y-%m-%d` to get actual current date
  2. Create directory: `plans/[category]/[date]/`
  3. Create file: `{type}_{plan_name}.mdc` in that directory
- **Why This Matters**: Better organization by category and date, easier navigation, cleaner filenames, improved autocomplete

## Completed Plan Organization (MANDATORY)
- **ALL completed plans** must be moved to `plans/completed/[category]/[date]/` with date-based subfolder organization
- **Use `git mv`** instead of `mv` to preserve file history and show as rename operations
- **File format**: `{type}_{plan_name}.mdc` (no date suffix in filename)
- **Directory structure**: `plans/completed/[category]/[date]/` where:
  - `[category]` is one of: `features`, `bugs`, `refactoring`, `specs`, `optimization`, `testing`, `documentation`, `data-recovery`, `performance`, `process-optimization`, `research`, `investigation`, `webui`
  - `[date]` is the original creation date (YYYY-MM-DD) from the plan file
- **Process for completing plans**:
  1. Update plan with final completion status and summary
  2. Extract date from original plan filename or use creation date
  3. Create directory: `plans/completed/[category]/[date]/`
  4. Use `git mv` to move: `git mv plans/[category]/[date]/plan_name.mdc plans/completed/[category]/[date]/plan_name.mdc`
  5. Commit with descriptive message: `docs(plan): mark {plan_name} complete and move to completed/{category}/{date}`
- **Why This Matters**: Single source of truth for all completed work, easy discovery by category and date, consistent organization, historical tracking