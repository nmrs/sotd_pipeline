# Testing Patterns for SOTD Pipeline

## Testing Strategy and Requirements

### **MANDATORY**: Test Type Priority Hierarchy
When adding or modifying any functionality in the SOTD pipeline, follow this priority order for test types:

1. **Unit Tests** - Fast, isolated tests with mock dependencies (HIGHEST PRIORITY)
   - Use mock catalogs and external services
   - Test individual functions and methods in isolation
   - Focus on logic validation and edge cases
   - Located in `tests/{module}/test_{filename}.py` (Python) or `src/**/*.{test,spec}.{ts,tsx}` (React)
   - **Use by default** - provides fastest feedback and best debugging

2. **Integration Tests** - Tests using real production data (MEDIUM PRIORITY)
   - Use actual YAML catalog files (`data/*.yaml`)
   - Test end-to-end workflows with real data
   - Validate that catalog changes don't break functionality
   - Located in `tests/integration/`
   - **Use when necessary** - for validating real data compatibility

3. **End-to-End (E2E) Tests** - Full system tests (LOWEST PRIORITY)
   - Test complete user workflows and system interactions
   - Use Playwright for web UI testing
   - Located in `webui/tests/` and `tests/integration/`
   - **Use only when necessary** - most expensive and slowest feedback

### **MANDATORY**: Unit and Integration Test Coverage
When adding or modifying any functionality in the SOTD pipeline, you MUST provide both:

1. **Unit Tests** - Fast, isolated tests with mock dependencies
   - Use mock catalogs and external services
   - Test individual functions and methods in isolation
   - Focus on logic validation and edge cases
   - Located in `tests/{module}/test_{filename}.py` (Python) or `src/**/*.{test,spec}.{ts,tsx}` (React)

2. **Integration Tests** - Tests using real production data
   - Use actual YAML catalog files (`data/*.yaml`)
   - Test end-to-end workflows with real data
   - Validate that catalog changes don't break functionality
   - Located in `tests/integration/`

### Testing Strategy Examples
- **New product matcher**: Add unit tests for regex patterns + integration tests with real catalog
- **API changes**: Add unit tests with mocked APIs + integration tests with real services
- **Data processing logic**: Add unit tests for edge cases + integration tests with sample data
- **Configuration changes**: Add unit tests for validation + integration tests for real config files
- **React components**: Add unit tests with React Testing Library + integration tests with real API data
- **UI interactions**: Add unit tests for user interactions + E2E tests for complete workflows

### Why This Priority Order
- **Unit tests (Priority 1)**: Catch logic bugs, provide fastest feedback, enable isolated debugging, lowest cost
- **Integration tests (Priority 2)**: Catch production issues, validate real data compatibility, prevent regressions, moderate cost
- **E2E tests (Priority 3)**: Validate complete user workflows, catch system-level issues, highest cost and slowest feedback

### When to Use Each Test Type
- **Start with unit tests** - they provide the best feedback loop for development
- **Add integration tests** when you need to validate real data compatibility
- **Add E2E tests** only when testing complete user workflows is necessary
- **Never skip unit tests** - they're the foundation of reliable development

## WebUI Testing Strategy

### **MANDATORY**: React Component Testing with React Testing Library
For all React components in the webui, follow this testing approach:

1. **Component Unit Tests** - Test individual React components (HIGHEST PRIORITY)
   - Use React Testing Library for component testing
   - Mock external dependencies (APIs, services)
   - Test component rendering, user interactions, and state changes
   - Located in `webui/src/**/*.{test,spec}.{ts,tsx}`
   - **Use by default** - provides fastest feedback for UI development

2. **API Integration Tests** - Test API interactions with Jest mocks (MEDIUM PRIORITY)
   - Use Jest mocking to mock API responses
   - Test API integration without real server
   - Validate error handling and loading states
   - Located in `webui/src/**/*.api.test.{ts,tsx}`
   - **Use when necessary** - for validating API integration

3. **E2E Tests** - Test complete user workflows (LOWEST PRIORITY)
   - Use Playwright for browser-based testing
   - Test complete user journeys and cross-browser compatibility
   - Located in `webui/tests/`
   - **Use only when necessary** - for complete workflow validation

### React Testing Library Patterns
```typescript
// webui/src/components/__tests__/BrushTable.test.tsx
import React from 'react';
import { render, screen } from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import BrushTable from '../BrushTable';

describe('BrushTable', () => {
  test('should render brush data correctly', () => {
    render(<BrushTable data={mockBrushData} />);
    
    expect(screen.getByText('Simpson Chubby 2')).toBeInTheDocument();
    expect(screen.getByText('Declaration B15')).toBeInTheDocument();
  });

  test('should handle user interactions', async () => {
    const user = userEvent.setup();
    render(<BrushTable data={mockBrushData} />);
    
    const filterInput = screen.getByPlaceholderText(/filter/i);
    await user.type(filterInput, 'Simpson');
    
    expect(screen.getByText('Simpson Chubby 2')).toBeInTheDocument();
    expect(screen.queryByText('Declaration B15')).not.toBeInTheDocument();
  });
});
```

### Jest Mocking Patterns
```typescript
// webui/src/components/__tests__/ApiIntegration.test.tsx
import React from 'react';
import { render, screen, waitFor } from '@testing-library/react';
import { MemoryRouter } from 'react-router-dom';
import Dashboard from '../../pages/Dashboard';

// Mock the API service
jest.mock('../../services/api', () => ({
  getAvailableMonths: jest.fn(),
  getMonthData: jest.fn(),
  getCatalogs: jest.fn(),
  checkHealth: jest.fn(),
}));

// Import the mocked function
import { getAvailableMonths, checkHealth } from '../../services/api';

describe('API Integration', () => {
  beforeEach(() => {
    (getAvailableMonths as jest.Mock).mockClear();
    (checkHealth as jest.Mock).mockClear();
  });

  test('should handle API error state', async () => {
    // Mock health check to pass
    (checkHealth as jest.Mock).mockResolvedValue(true);
    // Mock API to fail
    (getAvailableMonths as jest.Mock).mockRejectedValue(new Error('API Error'));

    render(
      <MemoryRouter>
        <Dashboard />
      </MemoryRouter>
    );

    // Should handle error gracefully
    await waitFor(() => {
      expect(screen.getByText(/checking system status/i)).toBeInTheDocument();
    });
  });

  test('should handle API timeout', async () => {
    // Mock slow API response
    (getAvailableMonths as jest.Mock).mockImplementation(() => 
      new Promise(resolve => setTimeout(() => resolve(['2024-01']), 100))
    );

    render(
      <MemoryRouter>
        <Dashboard />
      </MemoryRouter>
    );

    // Should show loading state
    expect(screen.getByText(/checking system status/i)).toBeInTheDocument();
  });
});
```

### WebUI Testing Commands
```bash
# Unit tests (fastest feedback)
npm test

# Watch mode for development
npm test -- --watch

# Coverage report
npm test -- --coverage

# E2E tests (slowest, complete workflows)
npm run test:e2e:background
```

## API Testing Strategy

### **MANDATORY**: API Testing Hierarchy
When testing APIs in the SOTD pipeline, follow this testing hierarchy:

1. **Backend API Tests** - Test FastAPI endpoints directly (HIGHEST PRIORITY)
   - Use FastAPI TestClient to test actual API endpoints
   - Test with real data files and catalogs
   - Located in `webui/api/test_*.py`
   - **Use by default** - provides fastest feedback for API development

2. **Frontend API Integration Tests** - Test React components with real API calls (MEDIUM PRIORITY)
   - Use real API endpoints (not mocks) for integration testing
   - Test actual API responses and error handling
   - Located in `webui/src/**/*.integration.test.{ts,tsx}`
   - **Use when necessary** - for validating frontend-backend integration

3. **Frontend Unit Tests** - Test React components with mocked APIs (LOWEST PRIORITY)
   - Use Jest mocks for fast component testing
   - Test component behavior in isolation
   - Located in `webui/src/**/*.{test,spec}.{ts,tsx}`
   - **Use for development** - provides fastest feedback for UI development

### Backend API Testing Patterns
```python
# webui/api/test_files.py
import pytest
from fastapi.testclient import TestClient
from main import app

@pytest.fixture
def client():
    """Create test client."""
    return TestClient(app)

def test_get_available_months_success(client, temp_data_dir):
    """Test successful retrieval of available months."""
    with patch("files.get_data_directory", return_value=temp_data_dir):
        response = client.get("/api/files/available-months")
        
        assert response.status_code == 200
        data = response.json()
        assert "months" in data
        assert data["total_months"] == 2
```

### Frontend API Integration Testing Patterns
```typescript
// webui/src/services/__tests__/api.integration.test.ts
/**
 * Tools used:
 * - Jest (test runner)
 * - React Testing Library (testing utilities)
 * - Axios (HTTP client - already used in api.ts)
 * - Real API endpoints (no mocking)
 */

import { getAvailableMonths, checkHealth, getCatalogs } from '../api';

describe('API Integration (Real Endpoints)', () => {
  // These tests use the same tools as unit tests but make real API calls
  // No mocking - we're testing actual API integration
  
  test('should connect to health endpoint', async () => {
    const health = await checkHealth();
    expect(health).toBe(true);
  }, 10000); // Longer timeout for real API calls

  test('should fetch available months from real API', async () => {
    const months = await getAvailableMonths();
    expect(Array.isArray(months)).toBe(true);
    // Should contain actual month data if available
    if (months.length > 0) {
      expect(months[0]).toMatch(/^\d{4}-\d{2}$/); // YYYY-MM format
    }
  }, 10000);
});
```

### API Testing Commands
```bash
# Backend API tests (FastAPI endpoints)
cd webui/api && python -m pytest test_*.py -v

# Frontend integration tests (real API calls)
npm test -- --testPathPattern=integration

# Frontend unit tests (mocked APIs)
npm test -- --testPathPattern=test.tsx

# All API-related tests
cd webui/api && python -m pytest test_*.py -v && cd .. && npm test
```

## Test File Structure and Naming
- Test files: `test_{module_name}.py` (Python) or `*.{test,spec}.{ts,tsx}` (React)
- Test functions: `test_{functionality}_when_{condition}_then_{expected}`
- Mock classes: `Mock{ServiceName}` (e.g., `MockSubmission`, `MockPRAW`)
- Mirror source structure in `tests/` directory

```python
# tests/fetch/test_reddit.py
import pytest
from unittest.mock import Mock, patch, MagicMock

from sotd.fetch.reddit import RedditAPI

class TestRedditAPI:
    """Test Reddit API functionality."""
    
    def test_fetch_comments_when_valid_thread_then_returns_comments(self):
        """Test that valid thread returns expected comments."""
        pass
    
    def test_fetch_comments_when_api_error_then_returns_empty_list(self):
        """Test graceful handling of API errors."""
        pass
```

## Mock Object Patterns
Create realistic mocks that reflect actual Reddit post patterns:

```python
class MockSubmission:
    """Mock Reddit submission for testing."""
    def __init__(self, id: str, title: str, created_utc: int = 1640995200):
        self.id = id
        self.title = title
        self.created_utc = created_utc
        self.num_comments = 5
        self.permalink = f"/r/wetshaving/comments/{id}/"

class MockComment:
    """Mock Reddit comment for testing."""
    def __init__(self, id: str, body: str = "Test shave", is_root: bool = True):
        self.id = id
        self.body = body
        self.is_root = is_root
        self.created_utc = 1640995200
        self.author = Mock()
        self.author.name = "test_user"
```

## Fixture Patterns
```python
@pytest.fixture
def sample_sotd_comment():
    """Sample SOTD comment for testing."""
    return {
        "id": "test123",
        "author": "test_user", 
        "body": "Razor: Karve CB\nBlade: Feather\nBrush: Stirling\nSoap: Declaration Grooming",
        "created_utc": 1640995200,
        "url": "https://reddit.com/r/wetshaving/comments/test123"
    }

@pytest.fixture
def mock_yaml_catalog():
    """Mock product catalog for testing."""
    return {
        "Test Brand": {
            "patterns": ["test.*brand"],
            "scents": {
                "Test Scent": {
                    "patterns": ["test.*scent"]
                }
            }
        }
    }
```

## Parameterized Testing for Product Matching
Test product matchers with comprehensive input variations:

```python
@pytest.mark.parametrize("input_text,expected_brand,expected_model", [
    ("Karve Christopher Bradley", "Karve", "Christopher Bradley"),
    ("Merkur 34C", "Merkur", "34C"),
    ("Gillette Tech", "Gillette", "Tech"),
])
def test_razor_matching(input_text, expected_brand, expected_model):
    """Test razor pattern matching with various inputs."""
    matcher = RazorMatcher()
    result = matcher.match(input_text)
    
    assert result["matched"]["brand"] == expected_brand  
    assert result["matched"]["model"] == expected_model
```

## Mocking External APIs
Mock Reddit API with proper error handling:

```python
@patch('sotd.fetch.reddit.praw.Reddit')
def test_fetch_with_rate_limit_error(mock_reddit):
    """Test handling of Reddit API rate limits."""
    mock_reddit.return_value.subreddit.return_value.submissions.side_effect = \
        praw.exceptions.APIException("RATE_LIMIT")
        
    api = RedditAPI()
    result = api.fetch_submissions("2025-01")
    
    assert result == []  # Should return empty list on API error
```

## Testing Coverage Requirements
- **Regex Patterns**: Test all product matching regex patterns
- **Error Handling**: Test all exception paths
- **Data Validation**: Test input validation and edge cases
- **API Integration**: Mock external services extensively
- **End-to-End**: Include integration tests for complete workflows
- **React Components**: Test rendering, user interactions, and state changes
- **UI Interactions**: Test form submissions, filtering, and navigation

## Performance Testing
```python
@pytest.mark.performance
def test_regex_compilation_performance():
    """Test that regex compilation is efficient."""
    patterns = ["test"] * 1000  # Large pattern list
    
    start_time = time.time()
    matcher = SoapMatcher(patterns)
    compilation_time = time.time() - start_time
    
    assert compilation_time < 1.0  # Should compile in under 1 second
```

## Error Case Testing
Always test invalid input handling:

```python
def test_match_with_invalid_regex_pattern():
    """Test handling of invalid regex patterns in catalog."""
    invalid_catalog = {
        "Test Brand": {
            "patterns": ["[invalid regex"]  # Unclosed bracket
        }
    }
    
    # Should not raise exception, should log warning and continue
    matcher = SoapMatcher(catalog_data=invalid_catalog)
    assert len(matcher.patterns) == 0  # Invalid pattern excluded
```

## Brush Matching Test Patterns
Test brush matching strategies with specific patterns:

```python
@pytest.fixture
def brush_test_catalog():
    """Comprehensive brush test catalog."""
    return {
        "known_brushes": {
            "Simpson": {
                "Chubby 2": {
                    "fiber": "Badger",
                    "knot_size_mm": 27,
                    "patterns": ["simp.*chubby\\s*2"]
                }
            }
        },
        "other_brushes": {
            "Elite": {
                "default": "Badger",
                "patterns": ["elite"]
            }
        }
    }

def test_brush_strategy_priority(matcher):
    """Test that strategies are tried in correct priority order."""
    # Known brushes should match before other_brushes
    result = matcher.match("Simpson Chubby 2")
    assert result["matched"]["_matched_by_strategy"] == "KnownBrushMatchingStrategy"

def test_fiber_strategy_detection(matcher):
    """Test fiber strategy detection (user_input vs yaml vs default)."""
    # User input matches catalog
    result = matcher.match("Elite 26mm Boar")
    assert result["matched"]["fiber_strategy"] == "user_input"
    
    # User input conflicts with catalog
    result = matcher.match("Simpson Chubby 2 Synthetic")  # Catalog says Badger
    assert result["matched"]["fiber_strategy"] == "yaml"
    assert result["matched"]["fiber_conflict"] == "Synthetic"

def test_handle_knot_splitting(matcher):
    """Test handle/knot splitting with various delimiters."""
    test_cases = [
        ("Elite handle w/ Declaration knot", "Elite", "Declaration"),
        ("WW with 26mm knot", "Wolf Whiskers", None),
        ("Handle / Knot description", "Handle Maker", "Knot Brand")
    ]
    
    for input_text, expected_handle, expected_brand in test_cases:
        result = matcher.match(input_text)
        if expected_handle:
            assert result["matched"]["handle_maker"] == expected_handle
        if expected_brand:
            assert result["matched"]["brand"] == expected_brand
```

## Return Structure Validation
Always validate complete return structure:

```python
def test_consistent_return_structure(matcher):
    """Test that all matches return consistent structure."""
    test_cases = ["Simpson Chubby 2", "Unknown brush", "Elite handle"]
    
    for test_case in test_cases:
        result = matcher.match(test_case)
        
        # Required top-level keys
        assert "original" in result
        assert "matched" in result  # Can be None
        assert "match_type" in result  # Can be None
        assert "pattern" in result  # Can be None
        
        # If matched, validate structure
        if result["matched"]:
            required_fields = ["brand", "model", "fiber", "knot_size_mm", 
                             "handle_maker", "_matched_by_strategy"]
            for field in required_fields:
                assert field in result["matched"]
```

## Integration Test Patterns
Integration tests validate functionality with real production data:

```python
# tests/integration/test_real_catalog_integration.py
class TestRealCatalogIntegration:
    """Integration tests using actual production YAML catalogs."""
    
    def test_real_catalog_loads_successfully(self):
        """Test that real catalogs load without errors."""
        matcher = BrushMatcher()  # Uses default paths to real files
        assert matcher.catalog_data is not None
        assert len(matcher.strategies) > 0
    
    def test_known_patterns_work_with_real_catalog(self):
        """Test known patterns work with production catalog."""
        matcher = BrushMatcher()
        test_cases = [
            ("Simpson Chubby 2", "Simpson"),
            ("Declaration B15", "Declaration Grooming"),
        ]
        
        for input_text, expected_brand in test_cases:
            result = matcher.match(input_text)
            if result.get("matched"):
                assert result["matched"]["brand"] == expected_brand
    
    def test_catalog_files_exist(self):
        """Test that all expected catalog files exist."""
        catalog_files = ["data/brushes.yaml", "data/handles.yaml", "data/soaps.yaml"]
        for catalog_file in catalog_files:
            path = Path(catalog_file)
            assert path.exists(), f"Catalog file {catalog_file} does not exist"
            assert path.stat().st_size > 0, f"Catalog file {catalog_file} is empty"
```

## Test Data Management

> **Test Data Realism:**
> All enrich phase tests **must** use realistic, user-like extracted strings for the `extracted_field` argument (e.g., `"Astra SP (3)", "Simpson Chubby 2 26mm boar"`). In registry and integration tests, all `*_extracted` fields **must** be strings, not booleans. Assertions should be updated to match the expected enrichment output for the new, realistic extracted values.

Use temporary files for test catalogs:

```python
@pytest.fixture
def temp_catalog(tmp_path):
    """Create temporary catalog file for testing."""
    catalog_data = {"Test Brand": {"patterns": ["test"]}}
    catalog_file = tmp_path / "test_catalog.yaml"
    
    with catalog_file.open("w") as f:
        yaml.dump(catalog_data, f)
    
    return catalog_file

def test_with_temp_catalog(temp_catalog):
    """Test using temporary catalog file."""
    matcher = BrushMatcher(catalog_path=temp_catalog)
    result = matcher.match("test input")
    # Test with isolated catalog data
```

## Development Workflow Integration
Follow the test priority hierarchy during development:

```bash
# 1. Unit tests (fastest feedback loop) - START HERE
make test-fast  # Python unit tests
npm test  # React unit tests

# 2. Integration tests (when needed for real data validation)
python -m pytest tests/integration/ -v  # Python integration tests
npm run test  # React integration tests

# 3. E2E tests (only when testing complete user workflows)
npm run test:e2e:background  # For web UI testing

# All tests before committing (includes unit + integration)
python -m pytest tests/ -v  # All Python tests
npm run test  # All React tests
```

### Development Priority
1. **Write unit tests first** - they provide the best development feedback
2. **Add integration tests** when you need to validate real data compatibility
3. **Add E2E tests** only when testing complete user workflows is necessary
4. **Never skip unit tests** - they're the foundation of reliable development

### WebUI Development Priority
1. **Write React component unit tests first** - fastest feedback for UI development
2. **Add API integration tests with Jest mocks** when testing API interactions
3. **Add E2E tests** only when testing complete user workflows
4. **Use React Testing Library by default** - provides best debugging and feedback
